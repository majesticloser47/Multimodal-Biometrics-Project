{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc432ad6",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import constants\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.cm as cm\n",
    "import scipy.io as sp\n",
    "import json\n",
    "import pprint as pp\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import trapezoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize, linewidth=300, suppress=True)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9c783",
   "metadata": {},
   "source": [
    "## Data Visualization and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa355f76",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "dataset_path = os.getenv('DATASET_PATH')\n",
    "\n",
    "def get_dataset_files_and_user_ids(data_category = constants.GENUINE, data_type = constants.TRAIN):\n",
    "    user_ids = []\n",
    "    files_csv = []\n",
    "    files_mat = []\n",
    "\n",
    "    # Get training and testing data\n",
    "    data_split = pd.read_csv(os.path.join(dataset_path, \"Identification_split.csv\"))\n",
    "    training_data_files = data_split[data_split.set == constants.TRAIN].filename.str.rsplit('.', n=1).str[0]\n",
    "    # print(training_data_files) # only for debugging\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        if os.path.basename(root) == constants.GENUINE == data_category:\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    files_csv.append(os.path.join(root, file))\n",
    "                elif file.endswith('.mat'):\n",
    "                    files_mat.append(os.path.join(root, file))\n",
    "        elif os.path.basename(root) == constants.FORGED == data_category:\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    files_csv.append(os.path.join(root, file))\n",
    "                elif file.endswith('.mat'):\n",
    "                    files_mat.append(os.path.join(root, file))\n",
    "        if os.path.basename(root) != constants.GENUINE and os.path.basename(root) != constants.FORGED and os.path.basename(root) != 'SignEEGv1.0':\n",
    "            user_ids.append(os.path.basename(root))\n",
    "    files_csv = sorted(files_csv, key=lambda x: int(x.split('_')[3].split(\".\")[0]))\n",
    "    files_mat = sorted(files_mat, key=lambda x: int(x.split('_')[3]))\n",
    "    return files_csv, files_mat, user_ids\n",
    "\n",
    "# print(\"Genuine MAT files:\")\n",
    "# pprint(get_genuine_csv_mat_files())\n",
    "# print(\"Forged MAT files:\")\n",
    "# pprint(get_forged_csv_mat_files())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ff10b",
   "metadata": {},
   "source": [
    "### Get List of UserIDs from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ids = []\n",
    "# def get_list_of_user_ids():\n",
    "#     for root, dir, files in os.walk(dataset_path):\n",
    "#         if os.path.basename(root) != 'Genuine' and os.path.basename(root) != 'Forged' and os.path.basename(root) != 'SignEEGv1.0':\n",
    "#             user_ids.append(os.path.basename(root))\n",
    "#     # print(len(user_ids))\n",
    "#     return user_ids\n",
    "\n",
    "# print(\"User IDs:\")\n",
    "# pprint(get_list_of_user_ids())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe5a53",
   "metadata": {},
   "source": [
    "### Clean up Signature CSV data and reset column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e500c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_csv_sign_data_cleaned(user_sign_data_csv): #Provide file name of the csv file\n",
    "    content = pd.read_csv(user_sign_data_csv, skiprows=1, header=None)\n",
    "    content.drop\n",
    "    content.columns = [c.strip() for c in content.iloc[0]] #gettting rid of extra space in column names\n",
    "    content = content.iloc[1:]\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98fc39",
   "metadata": {},
   "source": [
    "### Plot signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153cca9f",
   "metadata": {},
   "source": [
    "#### Uncomment in case images of signatures need to be generated again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csv_data, _ = get_genuine_csv_mat_files()\n",
    "# print(csv_data)\n",
    "# user_id = '000000001045402'\n",
    "# user_match = [data for data in csv_data if user_id in data]\n",
    "# print(\"Users matched with user_id '{}':\".format(user_match))\n",
    "# count=0\n",
    "# for file in user_match:\n",
    "#     count+=1\n",
    "#     content = get_user_csv_sign_data_cleaned(file)\n",
    "#     x, y, _, press, _, _ = normalize_sign_data(content)\n",
    "#     # cmap = cm.Blues\n",
    "#     # colors = cmap(press)\n",
    "#     # # colors[:, 3] = press\n",
    "#     # # plt.scatter(sign_coords['X'], sign_coords['Y'], c=colors, s=50)\n",
    "#     # plt.scatter(x, y, c=colors, s=50)\n",
    "#     # plt.title('Sign Coordinates')\n",
    "#     # plt.xlabel('X')\n",
    "#     # plt.ylabel('Y')\n",
    "#     # plt.show()\n",
    "\n",
    "#     min_linewidth = 0\n",
    "#     max_linewidth = 5.0\n",
    "#     linewidths = min_linewidth + press * (max_linewidth - min_linewidth)\n",
    "\n",
    "#     plt.figure(figsize=(8, 4))\n",
    "#     for i in range(len(x) - 1):\n",
    "#         plt.plot(\n",
    "#             x[i:i+2], y[i:i+2],\n",
    "#             linewidth=linewidths[i],\n",
    "#             color='black',\n",
    "#             solid_capstyle='round'\n",
    "#         )\n",
    "#     # plt.axis('equal')  # Keep aspect ratio square\n",
    "#     plt.axis('off')    # Hide axes for cleaner look\n",
    "#     # plt.show() # uncomment only for debug processes, uncommenting will make plt.savefigure() save blank images\n",
    "\n",
    "#     plt.savefig(\"SignImages\\\\\"+user_id+\"-\"+str(count)+\".jpeg\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11db1a",
   "metadata": {},
   "source": [
    "### Signature Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caaef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sign_data(data):\n",
    "    x = np.array(data['X']).astype(int)\n",
    "    y = np.array(data['Y']).astype(int)\n",
    "    t = np.array(data['T']).astype(int)\n",
    "    pressure = np.array(data['Pressure']).astype(int)\n",
    "    azimuth = np.array(data['Azimuth']).astype(int)\n",
    "    altitude = np.array(data['Altitude']).astype(int)\n",
    "    # normalize signature data\n",
    "    norm_x = x / np.max(x)\n",
    "    norm_y = y / np.max(y)\n",
    "    norm_pressure = pressure / np.max(pressure)\n",
    "    norm_azimuth = azimuth / np.max(azimuth)\n",
    "    norm_altitude = altitude / np.max(altitude)\n",
    "    return norm_x, norm_y, t, norm_pressure, norm_azimuth, norm_altitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ea280",
   "metadata": {},
   "source": [
    "### EEG Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, mat_data, user_ids = get_dataset_files_and_user_ids()\n",
    "# print(mat_data)\n",
    "def get_user_mat_data(user_id=None):\n",
    "    if user_id is None:\n",
    "        user_id = user_ids[0]  # Default to the first user if none specified\n",
    "    user_files = [x for x in mat_data if user_id in x]\n",
    "    user_files_sorted = pd.Series(user_files)\n",
    "    user_files_sorted.sort_values(key=lambda x: x.str.split('_').str[3].astype(int), inplace=True)\n",
    "    user_files_reset = user_files_sorted.reset_index(drop=True)\n",
    "    # print(user_files_reset)\n",
    "    return user_files_reset\n",
    "\n",
    "# Fetch matlab data\n",
    "mat_files_sorted = get_user_mat_data()\n",
    "mat_content = sp.loadmat(mat_files_sorted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71dff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing using z-score\n",
    "\n",
    "def normalize_eeg_data(eeg_input):\n",
    "    norm_eeg_data = []  \n",
    "    for channel in eeg_input:\n",
    "        mean = np.mean(channel)\n",
    "        std = np.std(channel)\n",
    "        norm_channel = (channel - mean)/std\n",
    "        norm_eeg_data.append(norm_channel)\n",
    "    norm_eeg_array = np.array(norm_eeg_data)\n",
    "    # print(norm_eeg_data)\n",
    "    return norm_eeg_array\n",
    "\n",
    "# normalize_eeg_data(eeg_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a03aab",
   "metadata": {},
   "source": [
    "### EEG Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eeg_data(eeg_data):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    offset = 500\n",
    "    colors = ['b', 'g', 'r', 'c', 'y']\n",
    "    for idx, col in enumerate(eeg_columns):\n",
    "        plt.plot(eeg_data[col] + idx * offset, color=colors[idx % len(colors)], label=col)\n",
    "    plt.title('EEG Signal Data (with vertical offset)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude + Offset')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca78353",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189dbe",
   "metadata": {},
   "source": [
    "### Signature data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4db187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign_data = get_user_csv_sign_data_cleaned('D:\\\\KCL Final Year Individual Project\\\\Implementation\\\\Project Implementation\\\\Dataset\\\\SignEEGv1.0\\\\SignEEGv1.0\\\\000000000200894\\\\Genuine\\\\000000000200894_Genuine_000000000200894_1.csv')\n",
    "# sign_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de594ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data, mat_data, user_ids = get_dataset_files_and_user_ids()\n",
    "def get_signature_feature_vector(path):\n",
    "    user_id = [id for id in user_ids if id in path][0]\n",
    "    sign_data = get_user_csv_sign_data_cleaned(path)\n",
    "    x, y, t, pressure, azimuth, altitude = normalize_sign_data(sign_data)\n",
    "\n",
    "    # Calculate pen velocity\n",
    "    dt = 1 / (4 / 1000)\n",
    "    vx = np.gradient(x, dt)\n",
    "    vy = np.gradient(y, dt)\n",
    "    v = np.sqrt(vx**2 + vy**2)\n",
    "    \n",
    "    # Calculate pen acceleration\n",
    "    ax = np.gradient(vx, dt)\n",
    "    ay = np.gradient(vy, dt)\n",
    "    a = np.sqrt(ax**2 + ay**2)\n",
    "\n",
    "    # Calculate number of pen lifts\n",
    "    # Do a logical & betwen the values of the array(except for the last) are > 0 and the values for which (except the first element) > 0\n",
    "    pen_lifts = np.sum((pressure[:-1] > 0) & (pressure[1:] == 0))\n",
    "    # print(pen_lifts)\n",
    "\n",
    "    # Calculate stroke duration\n",
    "    is_pen_down = pressure > 0 \n",
    "    stroke_durations = []\n",
    "    start = None\n",
    "    stroke_count = 0\n",
    "\n",
    "    for i in range(len(pressure)):\n",
    "        if is_pen_down[i]:\n",
    "            if start is None:\n",
    "                start = i\n",
    "        else:\n",
    "            if start is not None:\n",
    "                duration = t[i-1] - t[start]\n",
    "                stroke_durations.append(int(duration))\n",
    "                start = None\n",
    "\n",
    "    # Handle case where the last stroke goes to the end\n",
    "    if start is not None:\n",
    "        duration = t[-1] - t[start]\n",
    "        stroke_durations.append(int(duration))\n",
    "\n",
    "    # Calculate average stroke duration\n",
    "    avg_stroke_duration = np.average(stroke_durations)\n",
    "    \n",
    "    # Calculate number of strokes\n",
    "    stroke_count = len(stroke_durations)\n",
    "\n",
    "    # Sign centroid\n",
    "    pen_down = pressure > 0\n",
    "    x_down = x[pen_down]\n",
    "    y_down = y[pen_down]\n",
    "    centroid_x = np.mean(x_down)\n",
    "    centroid_y = np.mean(y_down)\n",
    "    sign_centroid = [centroid_x, centroid_y]\n",
    "    # print(sign_centroid)\n",
    "    \n",
    "    sign_feature_data = np.concatenate([x, y, pressure, azimuth, altitude, v, a, stroke_durations, sign_centroid, [pen_lifts, avg_stroke_duration, stroke_count]])\n",
    "\n",
    "    return sign_feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_feature_vector = get_signature_feature_vector(csv_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ab844",
   "metadata": {},
   "source": [
    "### Misc - for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_data_roi = eeg_input[roi_idx[0]:roi_idx[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(eeg_data_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mat_files_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285cb2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_eeg_data(eeg_data_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43701b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pp.pprint(eeg_data)\n",
    "# Side note: Can be used for sign data as well, reduces dependency on CSV data\n",
    "# plot_eeg_data(eeg_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ee375",
   "metadata": {},
   "source": [
    "### Extract EEG Frequency Weighted Power Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_power_spectral_density(norm_eeg_signal, sampling_freq):\n",
    "#     freqs, psd = welch(norm_eeg_signal, fs = sampling_freq, nperseg = sampling_freq * 2) # window = 'hann' by default\n",
    "#     # print(\"Frequencies: \", freqs)\n",
    "#     # print(\"Power distribution: \", psd)\n",
    "\n",
    "#     band_psd = {}\n",
    "#     for band, [low, high] in freq_bands.items():\n",
    "#         idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "#         band_psd[band] = np.mean(psd[:, idx_band], axis = 1) if psd[:, idx_band].size > 0 else np.zeros(norm_eeg_signal.shape[0])\n",
    "#     print(\"Band Powers: \", band_psd)\n",
    "#     return band_psd\n",
    "# psd_data = calculate_power_spectral_density(norm_eeg_data, 128)\n",
    "\n",
    "\n",
    "def compute_freq_weighted_power_per_channel(channel, samp_freq, band):\n",
    "    freqs, psd = welch(channel, fs=samp_freq, nperseg=len(channel))\n",
    "    idx = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    freqs = freqs[idx]\n",
    "    psd = psd[idx]\n",
    "    return np.sum(freqs * psd) / np.sum(psd) if np.sum(psd) > 0 else 0\n",
    "\n",
    "def get_freq_weighted_feature(signal, samp_freq, window = 2, overlap = 1, normalize = False):\n",
    "\n",
    "    # over different frequency bands, calculate power\n",
    "    # standard bands used for EEG - gamma (20-50 Hz), beta (13-20 Hz), alpha (8-13 Hz), theta (4-8 Hz), delta (0.5-4 Hz)\n",
    "    # also takign windows of 2seconds witgh 1 second overlap\n",
    "    # windows made using Hann window\n",
    "    freq_bands = {\n",
    "        'delta': [0.5, 4],\n",
    "        'theta': [4, 8],\n",
    "        'alpha': [8, 13],\n",
    "        'beta': [113, 20],\n",
    "        'gamma': [20, 50]\n",
    "    }\n",
    "    \n",
    "    n_channels, n_samples = signal.shape\n",
    "    window_len = int(samp_freq * window)\n",
    "    step = int(samp_freq * overlap)\n",
    "    n_windows = (n_samples - window_len) // step + 1\n",
    "    features = []\n",
    "    for w in range(n_windows):\n",
    "        start = w * step\n",
    "        end = start + window_len\n",
    "        window_features = []\n",
    "        for channel in range(n_channels):\n",
    "            segment = signal[channel, start:end]\n",
    "            freqs, psd = welch(segment, fs = samp_freq, nperseg = window_len)\n",
    "            for band_range in freq_bands.values():\n",
    "                idx = (freqs >= band_range[0]) & (freqs <= band_range[1])\n",
    "                bp = trapezoid(psd[idx], freqs[idx])\n",
    "                window_features.append(bp)\n",
    "            fwp = compute_freq_weighted_power_per_channel(segment, samp_freq=samp_freq, band = (0.5, 50))\n",
    "            window_features.append(fwp)\n",
    "        features.append(window_features)\n",
    "    features = np.array(features)\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.mean(features, axis = 0)\n",
    "        std = np.std(features, axis = 0)\n",
    "        std[std == 0] = 1e-6\n",
    "        features = (features - mean) / std\n",
    "    return features\n",
    "\n",
    "# print(get_freq_weighted_feature(norm_eeg_data, 128, normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7abab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_eeg_features(mat_file):\n",
    "\n",
    "    # mat_files_sorted = get_user_mat_data(user_id)\n",
    "    mat_content = sp.loadmat(mat_file)\n",
    "    \n",
    "    # For debugging issues\n",
    "    # to_print = mat_content['subject']\n",
    "    # print(to_print)\n",
    "\n",
    "    # converting ICA_EEG data into np structured array\n",
    "    # eeg_columns = [i for i in mat_content['subject']['EEGHeader'][0][0][0].split(\", \")]\n",
    "    eeg_data_list = [i.tolist() for i in mat_content['subject']['ICA_EEG'][0][0]]\n",
    "\n",
    "    # print(eeg_data_list)\n",
    "    # eeg_input = pd.DataFrame(eeg_data_list).T\n",
    "    # eeg_input.columns = eeg_columns\n",
    "\n",
    "    norm_eeg_data = normalize_eeg_data(eeg_data_list)\n",
    "    eeg_features_vector = get_freq_weighted_feature(norm_eeg_data, 128, normalize = True)\n",
    "    return eeg_features_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99134257",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_feature_vector = get_eeg_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sign_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ba5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectors_for_all_users():\n",
    "    csv_files, mat_files, user_ids = get_dataset_files_and_user_ids()\n",
    "    sign_features_for_all_users = {}\n",
    "    eeg_features_for_all_users = {}\n",
    "    for user in user_ids:\n",
    "        sign_features_for_all_users[user] = []\n",
    "        eeg_features_for_all_users[user] = []\n",
    "        user_csv_raw = [file for file in csv_files if user in file]\n",
    "        user_mat_raw = [file for file in mat_files if user in file]\n",
    "        # for debugging only\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"User ID: \", user)\n",
    "        # print(\"CSV Data: \")\n",
    "        # pp.pprint(user_csv_raw)\n",
    "        # print(\"\\n\")\n",
    "        # print(\"MAT Data:\")\n",
    "        # pp.pprint(user_mat_raw)\n",
    "\n",
    "        for csv_file in user_csv_raw:\n",
    "            sign_feature_vector = get_signature_feature_vector(csv_file)\n",
    "            print(\"Extracting sign features for file: \", csv_file)\n",
    "            # print(\"Sign feature vector: \")\n",
    "            # pp.pprint(sign_feature_vector)\n",
    "            sign_features_for_all_users[user].append(sign_feature_vector)\n",
    "\n",
    "        for mat_file in user_mat_raw:\n",
    "            eeg_feature_vector = get_eeg_features(mat_file)\n",
    "            print(\"Extracting EEG features for file: \", mat_file)\n",
    "            eeg_features_for_all_users[user].append(eeg_feature_vector)\n",
    "    return sign_features_for_all_users, eeg_features_for_all_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_features_final, eeg_features_final = get_feature_vectors_for_all_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1ed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
