{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be6e58c6",
      "metadata": {
        "id": "be6e58c6"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "xkA1YQ7W-MUl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkA1YQ7W-MUl",
        "outputId": "e7924ad3-fcc8-42c5-c62a-eadb5b9bee84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "odgwpcFd-NGU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odgwpcFd-NGU",
        "outputId": "8d14d06d-28c0-4680-c1fb-a091ae313d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install python-dotenv\n",
        "!pip install scipy\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install scikit-learn\n",
        "!pip install shap\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "853f3b96",
      "metadata": {
        "id": "853f3b96"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import constants\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import scipy.io as sp\n",
        "import pprint as pp\n",
        "from scipy.signal import welch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import shap\n",
        "import json\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8c2fe3aa",
      "metadata": {
        "id": "8c2fe3aa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize, linewidth=300, suppress=True)\n",
        "pd.set_option('display.max_colwidth', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a4bc15",
      "metadata": {
        "id": "97a4bc15"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd2b9b4c",
      "metadata": {
        "id": "dd2b9b4c"
      },
      "outputs": [],
      "source": [
        "# some calculations\n",
        "# for the dataset, 10 seconds = 1280 frames. 1 second = 128 frames. We can sue this to find the number of seconds that were taken to record the signature.\n",
        "\n",
        "recording_samp_rate = 128 # per second\n",
        "per_phase_frames = 1280 # seconds\n",
        "max_seq_len_for_data = 3000 # frames\n",
        "# desampling_factor = 1 # reducing sequences by this size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91ee960",
      "metadata": {
        "id": "c91ee960"
      },
      "source": [
        "# Fetching raw data (Sign + EEG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0358fbdd",
      "metadata": {
        "id": "0358fbdd"
      },
      "source": [
        "## Processing raw files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6301463",
      "metadata": {
        "id": "d6301463"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "# dataset_path = os.getenv('DATASET_PATH')\n",
        "dataset_path = '/content/drive/MyDrive/dataset-final-project/SignEEGv1.0'\n",
        "\n",
        "def get_dataset_files_and_user_ids(data_category, data_type = constants.TRAIN, task = constants.IDENTIFY):\n",
        "    user_ids = []\n",
        "    labels = []\n",
        "    files_mat = []\n",
        "\n",
        "    # Get training and testing data\n",
        "    data_split = pd.read_csv(os.path.join(dataset_path, \"Identification_split.csv\" if task == constants.IDENTIFY else \"Verification_split.csv\"))\n",
        "    data_categories = [constants.GENUINE, constants.FORGED] if data_category == constants.ALL else [data_category]\n",
        "    files_for_task = list(data_split[data_split.set == data_type].filename)\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        if os.path.basename(root) in data_categories:\n",
        "            for file in files:\n",
        "                if file.endswith('.mat') and file in files_for_task:\n",
        "                    files_mat.append(os.path.join(root, file))\n",
        "                    labels.append(os.path.basename(root))\n",
        "        if os.path.basename(root) != constants.GENUINE and os.path.basename(root) != constants.FORGED and os.path.basename(root) != 'SignEEGv1.0':\n",
        "            user_ids.append(os.path.basename(root))\n",
        "\n",
        "    return files_mat, user_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6154f6d9",
      "metadata": {
        "id": "6154f6d9"
      },
      "outputs": [],
      "source": [
        "# small note: np.delete(axis = 1) will delete a column, axis = 0 will delete a row. be careful"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69bfe1d",
      "metadata": {
        "id": "c69bfe1d"
      },
      "source": [
        "## Getting list of sign data, eeg data and label for each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "85c4f11d",
      "metadata": {
        "id": "85c4f11d"
      },
      "outputs": [],
      "source": [
        "def get_sig_eeg_raw_data(mat_files, labels, desampling_factor = 1):\n",
        "    raw_data_list = []\n",
        "    for mat_file, label in zip(mat_files, labels):\n",
        "        mat_content = sp.loadmat(mat_file)\n",
        "        user_id = str(mat_content['subject']['SubjectID'][0][0][0])\n",
        "        sig_data = mat_content['subject']['SignWacom'][0][0]\n",
        "        eeg_ica_data = mat_content['subject']['ICA_EEG'][0][0].T\n",
        "        sig_data = torch.from_numpy(np.delete(sig_data, 0, axis=1)).to(dtype=torch.float32)\n",
        "\n",
        "        # getting part of eeg data during which signature was recorded (ROI)\n",
        "        roi_frames_start = -(eeg_ica_data.shape[0] % per_phase_frames) if per_phase_frames > 0 else 0\n",
        "        eeg_ica_data = torch.from_numpy(eeg_ica_data[roi_frames_start:]).to(dtype=torch.float32)\n",
        "\n",
        "        # desampling the data\n",
        "        if desampling_factor > 1:\n",
        "            sig_data = sig_data[::desampling_factor, :]\n",
        "            eeg_ica_data = eeg_ica_data[::desampling_factor, :]\n",
        "\n",
        "        if sig_data.shape[0] > max_seq_len_for_data:\n",
        "            # print(\"Caught you!!!\")\n",
        "            # print(\"User ID: \", user_id)\n",
        "            # print(\"File: \", mat_file)\n",
        "            continue # Skip these files because it's too long, outlier\n",
        "        raw_data_list.append({\n",
        "            'sign_data': sig_data,\n",
        "            'eeg_data': eeg_ica_data,\n",
        "            'user_id': user_id,\n",
        "            'label': 0 if label == constants.GENUINE else 1,\n",
        "            'file': mat_file\n",
        "        })\n",
        "\n",
        "    return raw_data_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4a9078",
      "metadata": {
        "id": "0a4a9078"
      },
      "source": [
        "# Augmenting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6ac35e70",
      "metadata": {
        "id": "6ac35e70"
      },
      "outputs": [],
      "source": [
        "def augment_sign_data(sign_data, noise_std=0.01, scale_range=(0.95, 1.05), rotation_deg=5):\n",
        "    augmented = sign_data.clone()\n",
        "    augmented[:, 2:] += torch.randn_like(augmented[:, 2:]) * noise_std\n",
        "    scale = random.uniform(*scale_range)\n",
        "    augmented[:, 2] *= scale\n",
        "    augmented[:, 3] *= scale\n",
        "\n",
        "    # Random rotation (x, y)\n",
        "    theta = math.radians(random.uniform(-rotation_deg, rotation_deg))\n",
        "    x = augmented[:, 2].clone()\n",
        "    y = augmented[:, 3].clone()\n",
        "    augmented[:, 2] = x * math.cos(theta) - y * math.sin(theta)\n",
        "    augmented[:, 3] = x * math.sin(theta) + y * math.cos(theta)\n",
        "\n",
        "    return augmented\n",
        "\n",
        "def augment_eeg_data(eeg_data, noise_std=0.01, scale_range=(0.95, 1.05), time_shift_max=10):\n",
        "    augmented = eeg_data.clone()\n",
        "    augmented += torch.randn_like(augmented) * noise_std\n",
        "    scale = random.uniform(*scale_range)\n",
        "    augmented *= scale\n",
        "    shift = random.randint(-time_shift_max, time_shift_max)\n",
        "    if shift > 0:\n",
        "        augmented = torch.cat([augmented[shift:], torch.zeros_like(augmented[:shift])], dim=0)\n",
        "    elif shift < 0:\n",
        "        augmented = torch.cat([torch.zeros_like(augmented[shift:]), augmented[:shift]], dim=0)\n",
        "\n",
        "    return augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d478c1",
      "metadata": {
        "id": "10d478c1"
      },
      "source": [
        "# Sign Data Classification Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ccb8429",
      "metadata": {
        "id": "6ccb8429"
      },
      "source": [
        "## Sign data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "59a2b561",
      "metadata": {
        "id": "59a2b561"
      },
      "outputs": [],
      "source": [
        "def normalize_sign_data_dict(sign_data):\n",
        "\n",
        "    mean = torch.mean(sign_data[:, 2:], dim=0)\n",
        "    std = torch.std(sign_data[:, 2:], dim=0)\n",
        "    std = torch.where(std == 0, torch.tensor(1.0, dtype=torch.float32), std)\n",
        "    normalized = (sign_data[:, 2:] - mean) / std\n",
        "    normalized = torch.cat([sign_data[:, 0:2], normalized], dim=1).to(dtype=torch.float32)\n",
        "    return normalized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b972dd",
      "metadata": {
        "id": "f1b972dd"
      },
      "source": [
        "## Sign Data Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5eadc841",
      "metadata": {
        "id": "5eadc841"
      },
      "outputs": [],
      "source": [
        "def get_sign_data_features(sign_data):\n",
        "    normalized_sign_data = normalize_sign_data_dict(sign_data)\n",
        "    x = sign_data[:, 2]\n",
        "    y = sign_data[:, 3]\n",
        "\n",
        "    normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
        "    norm_x = normalized_sign_data[:, 2]\n",
        "    norm_y = normalized_sign_data[:, 3]\n",
        "    vx = torch.gradient(norm_x)[0]\n",
        "    vy = torch.gradient(norm_y)[0]\n",
        "    velocity = torch.sqrt(vx**2 + vy**2)\n",
        "    ax = torch.gradient(vx)[0]\n",
        "    ay = torch.gradient(vy)[0]\n",
        "    acceleration = torch.sqrt(ax**2 + ay**2)\n",
        "\n",
        "    avg_vx = torch.mean(vx)\n",
        "    avg_vy = torch.mean(vy)\n",
        "    avg_ax = torch.mean(ax)\n",
        "    avg_ay = torch.mean(ay)\n",
        "\n",
        "    # log curvature radius\n",
        "    dt = 1\n",
        "    dx = torch.gradient(norm_x, spacing=(dt,))[0]\n",
        "    dy = torch.gradient(norm_y, spacing=(dt,))[0]\n",
        "    v_t = torch.sqrt(dx ** 2 + dy ** 2)\n",
        "    v_t = torch.where(v_t == 0, torch.tensor(1e-10, dtype=v_t.dtype), v_t)\n",
        "    theta = torch.atan2(dy, dx)\n",
        "    dtheta = torch.gradient(theta, spacing=(dt,))[0]\n",
        "    dtheta = torch.where(dtheta == 0, torch.tensor(1e-10, dtype=dtheta.dtype), dtheta)\n",
        "    log_curv_radius = torch.log(torch.abs(v_t / dtheta) + 1e-10)\n",
        "    # print(\"Log Curve Radius shape: \", log_curv_radius.shape)\n",
        "    # getting static features\n",
        "    pendown_frames = normalized_sign_data[:, 1] == 1\n",
        "    num_strokes = torch.unique(normalized_sign_data[pendown_frames][:, 0]).shape[0]\n",
        "    x_down = normalized_sign_data[pendown_frames][:, 2]\n",
        "    y_down = normalized_sign_data[pendown_frames][:, 3]\n",
        "    sign_centroid = torch.tensor([torch.mean(x_down), torch.mean(y_down)], dtype=torch.float32)\n",
        "    if y_down.shape[0] > 0:\n",
        "        sign_height = torch.max(y_down) - torch.min(y_down)\n",
        "    else:\n",
        "        sign_height = 0\n",
        "    if x_down.shape[0] > 0:\n",
        "        sign_width = torch.max(x_down) - torch.min(x_down)\n",
        "    else:\n",
        "        sign_width = 0\n",
        "    height_width_ratio = sign_height / sign_width if sign_width != 0 else torch.tensor(0.0, dtype=torch.float32)\n",
        "\n",
        "    # new time dependent feature - jerk\n",
        "    jerk = torch.sqrt(torch.gradient(vx)[0]**2 + torch.gradient(vy)[0]**2)\n",
        "\n",
        "    pressure = sign_data[pendown_frames][:, 4]\n",
        "    azimuth = sign_data[pendown_frames][:, 5]\n",
        "    altitude = sign_data[pendown_frames][:, 6]\n",
        "    avg_pressure = torch.mean(pressure)\n",
        "    avg_azimuth = torch.mean(azimuth)\n",
        "    avg_altitude = torch.mean(altitude)\n",
        "    max_pressure = torch.max(pressure) if pressure.numel() > 0 else torch.tensor(0.0, dtype=torch.float32)\n",
        "    sign_duration = sign_data.shape[0] / recording_samp_rate\n",
        "    cls_token = torch.tensor([\n",
        "        num_strokes, sign_height, sign_width, height_width_ratio, sign_centroid[0], sign_centroid[1], avg_pressure, avg_azimuth, avg_altitude, avg_vx, avg_vy, avg_ax, avg_ay, max_pressure, sign_duration], dtype=torch.float32)\n",
        "    sign_data_aug = torch.cat([normalized_sign_data, velocity.unsqueeze(1), acceleration.unsqueeze(1), log_curv_radius.unsqueeze(1), jerk.unsqueeze(1)], dim=1)\n",
        "\n",
        "    return sign_data_aug, cls_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75128f7a",
      "metadata": {
        "id": "75128f7a"
      },
      "source": [
        "## Prepare sign dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0eb40603",
      "metadata": {
        "id": "0eb40603"
      },
      "outputs": [],
      "source": [
        "def attach_attention_tokens_and_padding(data, max_len):\n",
        "    # print(\"EEG Data shape: \", data.shape)\n",
        "    if data.shape[0] == 0:\n",
        "        feat_dim = data.shape[1] if data.ndim == 2 else 1\n",
        "        return torch.zeros((max_len, feat_dim), dtype=torch.float32), torch.zeros(max_len, dtype=torch.float32)\n",
        "    seq_len, feat_dim = data.shape\n",
        "    pad_width = (0, max_len - seq_len)\n",
        "    padded_data = torch.nn.functional.pad(data, (0, 0, 0, pad_width[1]), mode='constant', value=0)\n",
        "    attention_mask = torch.zeros(max_len + 1, dtype=torch.float32)\n",
        "    attention_mask[:seq_len + 1] = 1  # +1 for cls_token\n",
        "    return padded_data, attention_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6c62d30c",
      "metadata": {
        "id": "6c62d30c"
      },
      "outputs": [],
      "source": [
        "# # For single data\n",
        "\n",
        "# sign_dict_sample, eeg_dict_sample, label = get_sig_eeg_data_dicts([files_mat_appended[0]], [1])\n",
        "# # print(sign_dict_sample['000000000200894'][0].shape)\n",
        "# normalized_sign_data_sample = normalize_sign_data_dict(sign_dict_sample)\n",
        "# sign_with_features = get_sign_data_features(normalized_sign_data_sample)\n",
        "# # print()\n",
        "# final_sign_data = sign_attach_attention_tokens_and_labels(sign_with_features, label)\n",
        "# final_sign_dataset = prepare_sign_dataset_with_all_parts(final_sign_data)\n",
        "# # print(\"Max len: \", get_sign_max_seq_len(sign_with_features))\n",
        "# # print(final_sign_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db33ebbb",
      "metadata": {
        "id": "db33ebbb"
      },
      "source": [
        "## Sign Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eedde36e",
      "metadata": {
        "id": "eedde36e"
      },
      "outputs": [],
      "source": [
        "# num_classes will be 2 (0 = unauthenticated, 1 = authenticated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d20fc0",
      "metadata": {
        "id": "d3d20fc0"
      },
      "outputs": [],
      "source": [
        "''' current data format:\n",
        "\n",
        "Just for reference, so that I don't forget later\n",
        "\n",
        "original data:\n",
        "\n",
        "{\n",
        "    user_id: string,\n",
        "    data: [ [ [], [], [] ... ], [ [], [], [] ... ] ...  ], size: (30 * 1200 * 7) = (num_samples_per_user * time_series_len * num_features)\n",
        "}\n",
        "\n",
        "extracted data:\n",
        "\n",
        "{\n",
        "    cls_tokens: tensor([ , , , , ... ], [ , , , ,  ....], [ , , , , ...] ... ), size: (total_num_samples * num_features),\n",
        "    data: tensor([ [], [], [] ... ], [ [], [], [] ... ] ...), size: (total_num_samples * time_series_len * num_features),\n",
        "    attention_masks: tensor([1, 1, 1, ...], [1, 1,1, ...] ... ), size: (total_num_samples * time_series_len),\n",
        "    labels: tensor([1, 0, 1, 0 ...]), size: (total_num_samples, )\n",
        "}\n",
        "'''\n",
        "\n",
        "class SignatureDataset(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        self.seq_len = input_data['sign_data'][0].shape[0]\n",
        "        self.ts_dim = input_data['sign_data'][0].shape[1]\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.x_ts = input_data['sign_data']\n",
        "        self.cls_token = input_data['sign_cls_tokens']\n",
        "        self.labels = input_data['labels']\n",
        "        self.attention_mask = input_data['sign_attention_masks']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'x_ts': self.x_ts[idx],\n",
        "            'cls_token': self.cls_token[idx],\n",
        "            'labels': self.labels[idx],\n",
        "            'attention_mask': self.attention_mask[idx]\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451ebf92",
      "metadata": {
        "id": "451ebf92"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len + 1, d_model)\n",
        "        position = torch.arange(0, max_len + 1, dtype = torch.float).unsqueeze(1)\n",
        "        divterm = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # Credits to hkproj@github for this as https://github.com/hkproj/pytorch-transformer/blob/main/model.py\n",
        "        pe[:, 0::2] = torch.sin(position * divterm)\n",
        "        pe[:, 1::2] = torch.cos(position * divterm)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "014ab58f",
      "metadata": {
        "id": "014ab58f"
      },
      "outputs": [],
      "source": [
        "class SignatureTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, cls_dim, d_model, num_classes, num_heads, num_layers, max_seq_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_len)\n",
        "        self.cls_proj = nn.Linear(cls_dim, d_model)\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dropout = dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers = num_layers)\n",
        "        # uncomment for single modality\n",
        "        self.classifier = nn.Sequential(nn.Linear(d_model, d_model), nn.ReLU(), nn.Linear(d_model, num_classes))\n",
        "\n",
        "    def forward(self, x_ts, cls_token, attn_mask = None):\n",
        "        x_ts = torch.nan_to_num(x_ts, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        cls_token = torch.nan_to_num(cls_token, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        batch_size, t, feat_dim = x_ts.shape\n",
        "        x_proj = self.input_projection(x_ts)\n",
        "        cls_proj = self.cls_proj(cls_token).unsqueeze(1)\n",
        "        # print(\"x_proj size: \", x_proj.shape)\n",
        "        # print(\"cls_proj size: \", cls_proj.shape)\n",
        "        x = torch.cat([cls_proj, x_proj], dim=1)\n",
        "        # print(\"x_proj and cls_proj concatenated size: \", x.shape)\n",
        "        x = x + self.positional_encoding(x)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask == 0 # True = ignore the value, False = include it!!!!!!!!!!\n",
        "            # cls_mask = torch.zeros((batch_size, 1), dtype=torch.bool, device=attn_mask.device)\n",
        "            full_mask = torch.cat([attn_mask], dim=1)  # [batch_size, t+1]\n",
        "        else:\n",
        "            full_mask = None\n",
        "        # print(\"Mask shape: \", full_mask.shape)\n",
        "        x = self.transformer(x, src_key_padding_mask=full_mask)\n",
        "        cls_output = x[:, 0, :]\n",
        "        # uncomment for single modality transformer\n",
        "        # logits = self.classifier(cls_output)\n",
        "        # return logits\n",
        "\n",
        "        # uncomment for multimodal transformer\n",
        "        return cls_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a0fc6b",
      "metadata": {
        "id": "17a0fc6b"
      },
      "source": [
        "## Training Sign Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbbdd6a0",
      "metadata": {
        "id": "bbbdd6a0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def sign_training_loop(model, dataloader, optimizer, loss_fn, device, num_epochs=10):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    model_path = os.getenv(\"MODEL_PATH\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        total_samples = 0\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        for i, batch in enumerate(tqdm(dataloader, desc=\"Training\", leave=False)):\n",
        "            x_ts = batch['x_ts'].to(device)\n",
        "            cls_token = batch['cls_token'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_ts, cls_token, attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN loss detected!\")\n",
        "                print(\"Labels:\", labels)\n",
        "                print(\"Logits:\", logits)\n",
        "                break\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x_ts.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            total_samples += x_ts.size(0)\n",
        "\n",
        "        avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "        rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "        print(f\"Loss: {avg_loss:.4f} | Acc: {acc:.4f} | Prec: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
        "    torch.save(model.state_dict(), os.path.join(model_path, f\"model{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5b8f2a",
      "metadata": {
        "id": "1f5b8f2a"
      },
      "source": [
        "## Sign Data Feed to Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e7649a",
      "metadata": {
        "id": "d2e7649a"
      },
      "outputs": [],
      "source": [
        "input_data = {\n",
        "    'sign_data': sign_data,\n",
        "    'eeg_data': eeg_data,\n",
        "    'sign_attention_masks': sign_attention_masks,\n",
        "    'eeg_attention_masks': eeg_attention_masks,\n",
        "    'sign_cls_tokens': sign_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_cls_tokens,\n",
        "    'labels': labels,\n",
        "}\n",
        "ts_dim = input_data['sign_data'][0].size(1)\n",
        "cls_dim = input_data['sign_cls_tokens'][0].size(0)\n",
        "d_model = 64\n",
        "num_classes = 2\n",
        "seq_len = max([data.shape[0] for data in input_data['sign_data']])\n",
        "batch_size = 8\n",
        "\n",
        "dataset = SignatureDataset(input_data, num_classes)\n",
        "# dataset.__getitem__(0)['x_ts'].shape\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "sign_model = SignatureTransformer(input_dim=ts_dim, cls_dim=cls_dim, d_model=d_model, num_classes=num_classes, num_heads=4, num_layers=2, max_seq_len=seq_len)\n",
        "optimizer = optim.Adam(sign_model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "sign_training_loop(sign_model, dataloader, optimizer, loss_fn, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a51e3b",
      "metadata": {
        "id": "08a51e3b"
      },
      "source": [
        "## Sign - Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c8245b",
      "metadata": {
        "id": "46c8245b"
      },
      "outputs": [],
      "source": [
        "# # print(len(final_signature_data['002108410100044']['cls_tokens']))\n",
        "# # print(len(final_signature_data['002108410100044']['data']))\n",
        "# # print(len(final_signature_data['002108410100044']['attention_masks']))\n",
        "\n",
        "# # print(final_signature_data['002108410100044']['cls_tokens'][0].shape)\n",
        "# # print(final_signature_data['002108410100044']['data'][0].shape)\n",
        "# # print(final_signature_data['002108410100044']['attention_masks'][0].shape)\n",
        "\n",
        "\n",
        "# print(len(final_sign_dataset_for_all_users['cls_tokens']))\n",
        "# print(len(final_sign_dataset_for_all_users['data']))\n",
        "# print(len(final_sign_dataset_for_all_users['attention_masks']))\n",
        "# print(len(final_sign_dataset_for_all_users['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec3dd28",
      "metadata": {
        "id": "1ec3dd28"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# print(len(final_sign_dataset_for_all_users['cls_tokens']))\n",
        "# print(len(final_sign_dataset_for_all_users['data']))\n",
        "# print(len(final_sign_dataset_for_all_users['attention_masks']))\n",
        "\n",
        "# print(final_sign_dataset_for_all_users['cls_tokens'][0].shape)\n",
        "# print(final_sign_dataset_for_all_users['data'][0].shape)\n",
        "# print(final_sign_dataset_for_all_users['attention_masks'][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93df9de",
      "metadata": {
        "id": "a93df9de"
      },
      "outputs": [],
      "source": [
        "# print(normalized_sign_data_dict['000000000200894'][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432f8149",
      "metadata": {
        "id": "432f8149"
      },
      "outputs": [],
      "source": [
        "# normalized_sign_data_dict = normalize_sign_data_dict(sign_data_dict)\n",
        "# # print(sign_data_dict['000000000200894'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4fc84a",
      "metadata": {
        "id": "4e4fc84a"
      },
      "outputs": [],
      "source": [
        "# print(len(sign_times_for_users))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21ab25fe",
      "metadata": {
        "id": "21ab25fe"
      },
      "source": [
        "# EEG Data Classification Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a6fe1a5",
      "metadata": {
        "id": "6a6fe1a5"
      },
      "source": [
        "## EEG Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e12b2c96",
      "metadata": {
        "id": "e12b2c96"
      },
      "outputs": [],
      "source": [
        "def normalize_eeg_data_dict(eeg_data_dict):\n",
        "    normalized_eeg_data_dict = {}\n",
        "    for user_id, eeg_list in eeg_data_dict.items():\n",
        "        normalized_eeg_data_dict[user_id] = []\n",
        "        for eeg_data in eeg_list:\n",
        "            mean = eeg_data.mean(dim=0, keepdim=True)\n",
        "            std = eeg_data.std(dim=0, keepdim=True)\n",
        "            std = torch.where(std == 0, torch.tensor(1.0, dtype=std.dtype, device=std.device), std)\n",
        "            normalized = (eeg_data - mean) / std\n",
        "            normalized_eeg_data_dict[user_id].append(normalized)\n",
        "    return normalized_eeg_data_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c86c80",
      "metadata": {
        "id": "18c86c80"
      },
      "source": [
        "## EEG Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "613e78d8",
      "metadata": {
        "id": "613e78d8"
      },
      "outputs": [],
      "source": [
        "def extract_fft_features(eeg_data, fs=128, epoch_length_sec=1): # taking 1s instead of 30s because the signal duration is short\n",
        "    n_samples, n_channels = eeg_data.shape\n",
        "    epoch_len = int(epoch_length_sec * fs)\n",
        "    n_epochs = n_samples // epoch_len\n",
        "    features = []\n",
        "    for i in range(n_epochs):\n",
        "        epoch = eeg_data[i*epoch_len:(i+1)*epoch_len, :]\n",
        "        epoch_features = []\n",
        "        for ch in range(n_channels):\n",
        "            fft_vals = np.fft.rfft(epoch[:, ch])\n",
        "            fft_power = np.abs(fft_vals)\n",
        "            epoch_features.extend(np.abs(fft_vals).flatten())\n",
        "        features.append(epoch_features)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9c6685fb",
      "metadata": {
        "id": "9c6685fb"
      },
      "outputs": [],
      "source": [
        "def get_nth_difference_mean_for_signal(input_signal, n):\n",
        "    input_signal = torch.as_tensor(input_signal)\n",
        "    diff = torch.abs(input_signal[n:] - input_signal[:-n])\n",
        "    res = torch.sum(diff) / (input_signal.shape[0] - n)\n",
        "    return res\n",
        "\n",
        "def normalize_for_eeg_related_data(data):\n",
        "    data = torch.as_tensor(data, dtype=torch.float32)\n",
        "    mean = torch.mean(data, dim=0)\n",
        "    std = torch.std(data, dim=0)\n",
        "    std = torch.where(std == 0, torch.tensor(1.0, dtype=std.dtype, device=std.device), std)\n",
        "    norm = (data - mean) / std\n",
        "    return norm\n",
        "\n",
        "def get_eeg_data_features(eeg_data, fs=recording_samp_rate):\n",
        "\n",
        "    signal_mean = torch.mean(eeg_data)\n",
        "    signal_std = torch.std(eeg_data)\n",
        "\n",
        "    first_difference_sample_mean_absolute_difference_raw_signal = get_nth_difference_mean_for_signal(eeg_data, 1)\n",
        "    second_difference_sample_mean_absolute_difference_raw_signal = get_nth_difference_mean_for_signal(eeg_data, 2)\n",
        "\n",
        "    normalized_signal = normalize_for_eeg_related_data(eeg_data)\n",
        "    first_difference_sample_mean_absolute_difference_normalized_signal = get_nth_difference_mean_for_signal(normalized_signal, 1)\n",
        "    second_difference_sample_mean_absolute_difference_normalized_signal = get_nth_difference_mean_for_signal(normalized_signal, 2)\n",
        "    fw_powers = []\n",
        "    eeg_data = torch.as_tensor(eeg_data, dtype=torch.float32)\n",
        "    for ch in range(normalized_signal.shape[1]):\n",
        "        # Welch returns numpy arrays, so convert to torch\n",
        "        f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
        "        f = torch.from_numpy(f).to(normalized_signal.device)\n",
        "        Pxx = torch.from_numpy(Pxx).to(normalized_signal.device)\n",
        "        fw_power = torch.sum(f * Pxx) / torch.sum(Pxx) if torch.sum(Pxx) > 0 else torch.tensor(0.0, device=normalized_signal.device)\n",
        "        fw_powers.append(fw_power)\n",
        "    fw_power_arr = torch.stack(fw_powers).unsqueeze(0)\n",
        "    # cls_token = torch.cat([signal_mean, signal_std, first_difference_sample_mean_absolute_difference_raw_signal, second_difference_sample_mean_absolute_difference_raw_signal, first_difference_sample_mean_absolute_difference_normalized_signal, second_difference_sample_mean_absolute_difference_normalized_signal])\n",
        "    # cls_token = torch.stack(fw_power_arr)\n",
        "    fft_features = extract_fft_features(normalized_signal.cpu().numpy(), fs=fs) # because we are using np.fft.rfft\n",
        "    features = [signal_mean, signal_std, first_difference_sample_mean_absolute_difference_raw_signal, second_difference_sample_mean_absolute_difference_raw_signal, first_difference_sample_mean_absolute_difference_normalized_signal, second_difference_sample_mean_absolute_difference_normalized_signal]\n",
        "    # for epoch_feat in fft_features:\n",
        "    #     features.extend(epoch_feat)\n",
        "    features.extend(fw_power_arr.squeeze(0).tolist())\n",
        "    cls_token = torch.tensor(features, dtype=torch.float32)\n",
        "    # uncomment if fft_features as eeg_data fails\n",
        "    # return normalized_signal, cls_token\n",
        "    fft_features = torch.tensor(fft_features, dtype=torch.float32)\n",
        "    fft_features = torch.nan_to_num(fft_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    return normalized_signal, fft_features, cls_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36432dfd",
      "metadata": {
        "id": "36432dfd"
      },
      "source": [
        "## EEG Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bf5a48",
      "metadata": {
        "id": "86bf5a48"
      },
      "outputs": [],
      "source": [
        "# # All EEG Data\n",
        "\n",
        "# files_mat_genuine, user_ids_genuine, genuine_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE)\n",
        "# files_mat_forged, user_ids_forged, forged_labels = get_dataset_files_and_user_ids(data_category=constants.FORGED)\n",
        "\n",
        "# files_mat_genuine.extend(files_mat_forged)\n",
        "# files_mat_appended = files_mat_genuine\n",
        "# genuine_labels.extend(forged_labels)\n",
        "# labels_appended = genuine_labels\n",
        "\n",
        "# # shuffling to prevent overfitting\n",
        "# files_all = np.array(files_mat_appended)\n",
        "# labels_all = np.array(labels_appended)\n",
        "\n",
        "# indices = np.arange(len(files_all))\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# files_mat_appended = files_all[indices]\n",
        "# labels_appended = labels_all[indices]\n",
        "\n",
        "# sign_data_dict, eeg_data_dict, labels = get_sig_eeg_raw_data(files_mat_appended, labels_appended)\n",
        "# normalized_eeg_data_dict = normalize_eeg_data_dict(eeg_data_dict)\n",
        "# eeg_data_with_features = get_eeg_data_features(normalized_eeg_data_dict)\n",
        "# eeg_final_data = eeg_attach_attention_tokens_and_labels(eeg_data_with_features, labels)\n",
        "# eeg_final_dataset = prepare_eeg_dataset_with_all_parts(eeg_final_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f06a7c4",
      "metadata": {
        "id": "8f06a7c4"
      },
      "outputs": [],
      "source": [
        "# input_data = eeg_final_dataset\n",
        "# ts_dim = input_data['data'][0].size(1)\n",
        "# cls_dim = input_data['cls_tokens'][0].size(0)\n",
        "# d_model = 64\n",
        "# num_classes = 2\n",
        "# seq_len = get_eeg_max_seq_len(eeg_data_with_features)\n",
        "# batch_size = 8\n",
        "\n",
        "# dataset = SignatureDataset(input_data, num_classes)\n",
        "# # dataset.__getitem__(0)['x_ts'].shape\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# eeg_model = SignatureTransformer(input_dim=ts_dim, cls_dim=cls_dim, d_model=d_model, num_classes=num_classes, num_heads=4, num_layers=4, max_seq_len=seq_len)\n",
        "# optimizer = optim.Adam(eeg_model.parameters(), lr=1e-4)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# sign_training_loop(eeg_model, dataloader, optimizer, loss_fn, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07f624e0",
      "metadata": {
        "id": "07f624e0"
      },
      "source": [
        "# Sign + EEG Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f15581d",
      "metadata": {
        "id": "9f15581d"
      },
      "source": [
        "## Getting the EEG and Sign data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Rq5Omt1IBc1z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq5Omt1IBc1z",
        "outputId": "0f767f12-b825-4e66-ed1b-615c464c081b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files:  583\n",
            "Test files:  201\n",
            "Val files:  187\n"
          ]
        }
      ],
      "source": [
        "train_files, user_ids, train_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type = constants.TRAIN, task = constants.IDENTIFY)\n",
        "test_files, _, test_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.TEST, task = constants.IDENTIFY)\n",
        "val_files, _, val_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.VALIDATION)\n",
        "\n",
        "print(\"Train files: \", len(train_files))\n",
        "print(\"Test files: \", len(test_files))\n",
        "print(\"Val files: \", len(val_files))\n",
        "\n",
        "# user_ids_master_list_path = os.getenv('USER_IDS_MASTER_LIST_PATH')\n",
        "user_ids_master_list_path = \"/content/\"\n",
        "\n",
        "# user_id_to_num_map = {user_id: i for i, user_id in enumerate(set(user_ids))} # for debugging, just to check mismatches in user_id order\n",
        "\n",
        "user_ids_master_list_file = os.path.join(user_ids_master_list_path, \"user_ids_master_list.json\")\n",
        "if not os.path.exists(user_ids_master_list_file):\n",
        "    user_id_to_num_map = {user_id: i for i, user_id in enumerate(user_ids)}\n",
        "    with open(user_ids_master_list_file, 'w') as f:\n",
        "        json.dump(user_id_to_num_map, f)\n",
        "else:\n",
        "    with open(user_ids_master_list_file, 'r') as f:\n",
        "        user_id_to_num_map = json.load(f)\n",
        "user_id_to_num_map = user_id_to_num_map[0]\n",
        "\n",
        "raw_train_data = get_sig_eeg_raw_data(train_files, train_labels)\n",
        "raw_test_data = get_sig_eeg_raw_data(test_files, test_labels)\n",
        "raw_val_data = get_sig_eeg_raw_data(val_files, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "rknxwX8NFdaj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rknxwX8NFdaj",
        "outputId": "973ed514-4655-491b-d35e-b31fc876fa79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(os.path.exists(os.path.join(user_ids_master_list_path, \"user_ids_master_list.json\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ooSmpG3dZw0U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooSmpG3dZw0U",
        "outputId": "e510b5eb-474a-4c5d-8a9c-301147258cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'001810111230005': 0, '000000802810034': 1, '002108410100007': 2, '002108410300034': 3, '002008410100015': 4, '002108410100036': 5, '002008410100016': 6, '002108410200051': 7, '002008410100050': 8, '002108410100061': 9, '002008410100044': 10, '002108410100051': 11, '002108410100040': 12, '002108410100047': 13, '002108410300017': 14, '002008410100018': 15, '002108410100003': 16, '002108410100018': 17, '002108410100017': 18, '002008410100013': 19, '000000001941061': 20, '002008410300021': 21, '002108410100016': 22, '002108410200018': 23, '000000003150143': 24, '000000000200894': 25, '002108410200006': 26, '002108410100038': 27, '002108410300030': 28, '002108410300041': 29, '002108410100005': 30, '002108410200016': 31, '002108410100008': 32, '002108410200049': 33, '002008410100040': 34, '002008410100011': 35, '002108410100046': 36, '002108410300039': 37, '002108410200037': 38, '002108410100011': 39, '002108410300042': 40, '002108410100006': 41, '002108410100010': 42, '000000814510023': 43, '002108410100044': 44, '000140809082110': 45, '002108410100002': 46, '002108410100048': 47, '002108410200021': 48, '002108410300028': 49, '002108410100012': 50, '002108410100013': 51, '002108410100041': 52, '000000001045402': 53, '002008410100052': 54, '002108410100020': 55, '002108410300006': 56, '002008410100008': 57, '002108410100030': 58, '002008410100025': 59, '002108410300001': 60, '002108410100037': 61, '002008410100030': 62, '000000001046474': 63, '001810111230006': 64, '002108410100001': 65, '002108410100045': 66, '002008410100024': 67, '002008410100065': 68, '002108410100043': 69}\n"
          ]
        }
      ],
      "source": [
        "print(user_id_to_num_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71dc59a",
      "metadata": {
        "id": "c71dc59a"
      },
      "source": [
        "## Processing Test and Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "314126b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "314126b2",
        "outputId": "f7b49ebf-433f-49bd-fb4a-c7e959d86b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-9-1646318677.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
            "/tmp/ipython-input-14-4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 197, using nperseg = 197\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "/tmp/ipython-input-14-4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 203, using nperseg = 203\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "/tmp/ipython-input-14-4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 136, using nperseg = 136\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n"
          ]
        }
      ],
      "source": [
        "# for debugging only\n",
        "# print(\"EEG Data seq len: \", [data['eeg_data'].shape[0] for data in raw_data])\n",
        "\n",
        "augmented_raw_data = []\n",
        "num_augments = 20\n",
        "\n",
        "for sample in raw_train_data:\n",
        "    augmented_raw_data.append(sample)\n",
        "    for _ in range(num_augments):\n",
        "        aug_sample = sample.copy()\n",
        "        aug_sample['sign_data'] = augment_sign_data(sample['sign_data'])\n",
        "        aug_sample['eeg_data'] = augment_eeg_data(sample['eeg_data'])\n",
        "        augmented_raw_data.append(aug_sample)\n",
        "\n",
        "raw_train_data = augmented_raw_data\n",
        "# shuffling to prevent overfitting\n",
        "random.shuffle(raw_train_data)\n",
        "\n",
        "for i in range(len(raw_train_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_train_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_train_data[i]['eeg_data'])\n",
        "    # print(\"EEG Feature data shape: \", eeg_data_with_features.shape)\n",
        "    raw_train_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_train_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_train_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_train_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "    raw_train_data[i]['user_id'] = user_id_to_num_map[raw_train_data[i]['user_id']]\n",
        "\n",
        "for i in range(len(raw_test_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_test_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_test_data[i]['eeg_data'])\n",
        "    raw_test_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_test_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_test_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_test_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "    raw_test_data[i]['user_id'] = user_id_to_num_map[raw_test_data[i]['user_id']]\n",
        "\n",
        "# sign_max_seq_len = max([data['sign_data'].shape[0] for data in raw_data])\n",
        "# eeg_max_seq_len = max([data['eeg_data'].shape[0] for data in raw_data])\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = 10\n",
        "\n",
        "for i in range(len(raw_train_data)):\n",
        "    sign_data = raw_train_data[i]['sign_data']\n",
        "    eeg_data = raw_train_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_train_data[i]['sign_data'] = sign_data\n",
        "    raw_train_data[i]['eeg_data'] = eeg_data\n",
        "    raw_train_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_train_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "for i in range(len(raw_test_data)):\n",
        "    sign_data = raw_test_data[i]['sign_data']\n",
        "    eeg_data = raw_test_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_test_data[i]['sign_data'] = sign_data\n",
        "    raw_test_data[i]['eeg_data'] = eeg_data\n",
        "    raw_test_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_test_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "sign_train_data = [data['sign_data'] for data in raw_train_data]\n",
        "eeg_train_data = [data['eeg_data'] for data in raw_train_data]\n",
        "sign_train_attention_masks = [data['sign_attention_mask'] for data in raw_train_data]\n",
        "eeg_train_attention_masks = [data['eeg_attention_mask'] for data in raw_train_data]\n",
        "sign_train_cls_tokens = [data['sign_cls_token'] for data in raw_train_data]\n",
        "eeg_train_cls_tokens = [data['eeg_cls_token'] for data in raw_train_data]\n",
        "labels_train = [data['user_id'] for data in raw_train_data]\n",
        "files_train = [data['file'] for data in raw_train_data]\n",
        "\n",
        "sign_test_data = [data['sign_data'] for data in raw_test_data]\n",
        "eeg_test_data = [data['eeg_data'] for data in raw_test_data]\n",
        "sign_test_attention_masks = [data['sign_attention_mask'] for data in raw_test_data]\n",
        "eeg_test_attention_masks = [data['eeg_attention_mask'] for data in raw_test_data]\n",
        "sign_test_cls_tokens = [data['sign_cls_token'] for data in raw_test_data]\n",
        "eeg_test_cls_tokens = [data['eeg_cls_token'] for data in raw_test_data]\n",
        "labels_test = [data['user_id'] for data in raw_test_data]\n",
        "files_test = [data['file'] for data in raw_test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "794909ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "794909ef",
        "outputId": "2dda910b-159b-4965-86cf-3764b4e1250c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sign train data type:  <class 'list'>\n",
            "EEG train data type:  <class 'list'>\n",
            "Sign train data type:  <class 'torch.Tensor'>\n",
            "EEG train data type:  <class 'torch.Tensor'>\n",
            "Sign train cls tokens type:  <class 'torch.Tensor'>\n",
            "EEG train cls tokens type:  <class 'torch.Tensor'>\n",
            "Sign train data shape:  torch.Size([3000, 11])\n",
            "EEG train data shape:  torch.Size([10, 325])\n",
            "Sign train attention mask shape:  torch.Size([3001])\n",
            "EEG train attention mask shape:  torch.Size([11])\n",
            "Train labels length:  12222\n",
            "Test labels length:  201\n",
            "Train labels:  [64, 11, 21, 12, 0, 69, 18, 54, 10, 48]\n",
            "Test labels:  [7, 7, 7, 10, 10, 10, 10, 59, 31, 31]\n"
          ]
        }
      ],
      "source": [
        "print(\"Sign train data type: \", type(sign_train_data))\n",
        "print(\"EEG train data type: \", type(eeg_train_data))\n",
        "print(\"Sign train data type: \", type(sign_train_attention_masks[0]))\n",
        "print(\"EEG train data type: \", type(eeg_train_attention_masks[0]))\n",
        "print(\"Sign train cls tokens type: \", type(sign_train_cls_tokens[0]))\n",
        "print(\"EEG train cls tokens type: \", type(eeg_train_cls_tokens[0]))\n",
        "\n",
        "print(\"Sign train data shape: \", sign_train_data[0].shape)\n",
        "print(\"EEG train data shape: \", eeg_train_data[0].shape)\n",
        "print(\"Sign train attention mask shape: \", sign_train_attention_masks[0].shape)\n",
        "print(\"EEG train attention mask shape: \", eeg_train_attention_masks[0].shape)\n",
        "print(\"Train labels length: \", len(labels_train))\n",
        "print(\"Test labels length: \", len(labels_test))\n",
        "print(\"Train labels: \", labels_train[:10])\n",
        "print(\"Test labels: \", labels_test[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f88540e7",
      "metadata": {
        "id": "f88540e7"
      },
      "outputs": [],
      "source": [
        "sign_ts_dim = sign_train_data[0].size(1)\n",
        "sign_cls_dim = sign_train_cls_tokens[0].size(0)\n",
        "sign_seq_len = sign_train_data[0].size(0)\n",
        "eeg_ts_dim = eeg_train_data[0].size(1)\n",
        "eeg_cls_dim = eeg_train_cls_tokens[0].size(0)\n",
        "eeg_seq_len = eeg_train_data[0].size(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755c6a5e",
      "metadata": {
        "id": "755c6a5e"
      },
      "source": [
        "## Redesigning the Transformer model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "eeec2cc5",
      "metadata": {
        "id": "eeec2cc5"
      },
      "outputs": [],
      "source": [
        "class SignatureEEGDataset(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        sign_attention_masks = input_data['sign_attention_masks']\n",
        "        eeg_attention_masks = input_data['eeg_attention_masks']\n",
        "        sign_cls_tokens = input_data['sign_cls_tokens']\n",
        "        eeg_cls_tokens = input_data['eeg_cls_tokens']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "        self.sign_cls_token = sign_cls_tokens\n",
        "        self.sign_attention_mask = sign_attention_masks\n",
        "        self.sign_seq_len = sign_data[0].shape[0]\n",
        "        self.sign_ts_dim = sign_data[0].shape[1]\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "        self.eeg_cls_token = eeg_cls_tokens\n",
        "        self.eeg_attention_mask = eeg_attention_masks\n",
        "        self.eeg_seq_len = eeg_data[0].shape[0]\n",
        "        self.eeg_ts_dim = eeg_data[0].shape[1]\n",
        "\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            'sign_cls_token': self.sign_cls_token[idx],\n",
        "            'sign_attention_mask': self.sign_attention_mask[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            'eeg_cls_token': self.eeg_cls_token[idx],\n",
        "            'eeg_attention_mask': self.eeg_attention_mask[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "61162a58",
      "metadata": {
        "id": "61162a58"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len + 1, d_model)\n",
        "        position = torch.arange(0, max_len + 1, dtype = torch.float).unsqueeze(1)\n",
        "        divterm = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # Credits to hkproj@github for this as https://github.com/hkproj/pytorch-transformer/blob/main/model.py\n",
        "        pe[:, 0::2] = torch.sin(position * divterm)\n",
        "        pe[:, 1::2] = torch.cos(position * divterm)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f1d21068",
      "metadata": {
        "id": "f1d21068"
      },
      "outputs": [],
      "source": [
        "class SignatureEEGTransformer(nn.Module):\n",
        "    def __init__(self, sign_input_dim, sign_cls_dim, eeg_input_dim, eeg_cls_dim, d_model, num_classes, num_heads, num_layers, sign_max_seq_len, eeg_max_seq_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.sign_transfomer = SignatureTransformer(sign_input_dim, sign_cls_dim, d_model, num_classes, num_heads, num_layers, sign_max_seq_len, dropout)\n",
        "        self.eeg_transformer = SignatureTransformer(eeg_input_dim, eeg_cls_dim, d_model, num_classes, num_heads, num_layers, eeg_max_seq_len, dropout)\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Linear(d_model * 2, d_model), nn.ReLU(), nn.Linear(d_model, num_classes))\n",
        "\n",
        "    def forward(self, sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attn_mask = None, eeg_attn_mask = None):\n",
        "        sign_cls = self.sign_transfomer(sign_x_ts, sign_cls_token, sign_attn_mask)\n",
        "        eeg_cls = self.eeg_transformer(eeg_x_ts, eeg_cls_token, eeg_attn_mask)\n",
        "        multimodal_cls_output = torch.cat([sign_cls, eeg_cls], dim = 1)\n",
        "\n",
        "        logits = self.classifier(multimodal_cls_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "edba8a97",
      "metadata": {
        "id": "edba8a97"
      },
      "outputs": [],
      "source": [
        "num_classes = len(user_id_to_num_map.keys())\n",
        "batch_size = 8\n",
        "# num_layers = 7\n",
        "num_epochs = 25\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "224d0cc3",
      "metadata": {
        "id": "224d0cc3"
      },
      "outputs": [],
      "source": [
        "train_input = {\n",
        "    'sign_data': sign_train_data,\n",
        "    'eeg_data': eeg_train_data,\n",
        "    'sign_attention_masks': sign_train_attention_masks,\n",
        "    'eeg_attention_masks': eeg_train_attention_masks,\n",
        "    'sign_cls_tokens': sign_train_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_train_cls_tokens,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "\n",
        "test_input = {\n",
        "    'sign_data': sign_test_data,\n",
        "    'eeg_data': eeg_test_data,\n",
        "    'sign_attention_masks': sign_test_attention_masks,\n",
        "    'eeg_attention_masks': eeg_test_attention_masks,\n",
        "    'sign_cls_tokens': sign_test_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_test_cls_tokens,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "\n",
        "# print(\"train input labels: \", train_input['labels'])\n",
        "train_dataset = SignatureEEGDataset(train_input, num_classes=num_classes)\n",
        "val_dataset = SignatureEEGDataset(test_input, num_classes=num_classes)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adc8dc95",
      "metadata": {},
      "source": [
        "## Checking for NaN after encountering 0 preds for all labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e417f8cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "for tensor_list in [sign_train_data, eeg_train_data, sign_train_cls_tokens, eeg_train_cls_tokens, sign_test_data, eeg_test_data, sign_test_cls_tokens, eeg_test_cls_tokens]:\n",
        "    for t in tensor_list:\n",
        "        assert not torch.isnan(t).any(), \"NaN in input data!\"\n",
        "        assert not torch.isinf(t).any(), \"Inf in input data!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4788aff",
      "metadata": {},
      "outputs": [],
      "source": [
        "assert all(0 <= l < num_classes for l in labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hQ6QKazTdEZf",
      "metadata": {
        "id": "hQ6QKazTdEZf"
      },
      "source": [
        "## Parameter Fine tuning - automated using optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dDDxuDNddI4_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dDDxuDNddI4_",
        "outputId": "54e270a2-2e1e-4583-ef08-34ad39a26570"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-29 19:10:56,595] A new study created in memory with name: no-name-080ae22b-0353-42d3-8f42-b49d92fb99dc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Parameters chosen for this trial: \n",
            "d_model:  256\n",
            "num_layers:  5\n",
            "num_heads:  4\n",
            "dropout:  0.10960414444435924\n",
            "learning rate:  7.238904403524705e-05\n",
            "batch_szie:  16\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(11), np.int64(18), np.int64(21), np.int64(69), np.int64(66), np.int64(6), np.int64(61), np.int64(36), np.int64(39), np.int64(32)]\n",
            "Pred labels:  [np.int64(34), np.int64(34), np.int64(34), np.int64(34), np.int64(65), np.int64(34), np.int64(34), np.int64(34), np.int64(34), np.int64(34)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 Validation:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(7), np.int64(7), np.int64(7), np.int64(10), np.int64(10), np.int64(10), np.int64(10), np.int64(59), np.int64(31), np.int64(31)]\n",
            "Pred labels:  [np.int64(55), np.int64(7), np.int64(7), np.int64(20), np.int64(22), np.int64(10), np.int64(10), np.int64(0), np.int64(31), np.int64(31)]\n",
            "Epoch 1/5\n",
            "Train Loss: 2.0555 | Train Acc: 0.6090\n",
            "Val Loss: 1.2828 | Val Acc: 0.6915\n",
            "Validation F1 Score: 0.6659\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(49), np.int64(28), np.int64(25), np.int64(18), np.int64(34), np.int64(7), np.int64(10), np.int64(34), np.int64(5), np.int64(22)]\n",
            "Pred labels:  [np.int64(49), np.int64(28), np.int64(25), np.int64(18), np.int64(34), np.int64(7), np.int64(60), np.int64(34), np.int64(5), np.int64(22)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(7), np.int64(7), np.int64(7), np.int64(10), np.int64(10), np.int64(10), np.int64(10), np.int64(59), np.int64(31), np.int64(31)]\n",
            "Pred labels:  [np.int64(55), np.int64(7), np.int64(7), np.int64(10), np.int64(22), np.int64(10), np.int64(10), np.int64(0), np.int64(31), np.int64(31)]\n",
            "Epoch 2/5\n",
            "Train Loss: 0.3173 | Train Acc: 0.9687\n",
            "Val Loss: 0.8921 | Val Acc: 0.7662\n",
            "Validation F1 Score: 0.7456\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(12), np.int64(53), np.int64(21), np.int64(49), np.int64(58), np.int64(9), np.int64(19), np.int64(58), np.int64(48), np.int64(28)]\n",
            "Pred labels:  [np.int64(12), np.int64(53), np.int64(21), np.int64(49), np.int64(58), np.int64(9), np.int64(19), np.int64(58), np.int64(48), np.int64(28)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(7), np.int64(7), np.int64(7), np.int64(10), np.int64(10), np.int64(10), np.int64(10), np.int64(59), np.int64(31), np.int64(31)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Epoch 3/5\n",
            "Train Loss: nan | Train Acc: 0.6056\n",
            "Val Loss: nan | Val Acc: 0.0149\n",
            "Validation F1 Score: 0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(13), np.int64(45), np.int64(57), np.int64(9), np.int64(55), np.int64(5), np.int64(36), np.int64(10), np.int64(19), np.int64(68)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(7), np.int64(7), np.int64(7), np.int64(10), np.int64(10), np.int64(10), np.int64(10), np.int64(59), np.int64(31), np.int64(31)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Epoch 4/5\n",
            "Train Loss: nan | Train Acc: 0.0206\n",
            "Val Loss: nan | Val Acc: 0.0149\n",
            "Validation F1 Score: 0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(41), np.int64(36), np.int64(54), np.int64(28), np.int64(18), np.int64(45), np.int64(11), np.int64(37), np.int64(32), np.int64(11)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(7), np.int64(7), np.int64(7), np.int64(10), np.int64(10), np.int64(10), np.int64(10), np.int64(59), np.int64(31), np.int64(31)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Epoch 5/5\n",
            "Train Loss: nan | Train Acc: 0.0206\n",
            "Val Loss: nan | Val Acc: 0.0149\n",
            "Validation F1 Score: 0.0004\n",
            "==================================================\n",
            "Model may be overfitting, time to early stop: \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-29 20:02:05,739] Trial 0 finished with value: 0.9850746268656716 and parameters: {'d_model': 256, 'num_layers': 5, 'num_heads': 4, 'lr': 7.238904403524705e-05, 'batch_size': 16, 'dropout': 0.10960414444435924}. Best is trial 0 with value: 0.9850746268656716.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Parameters chosen for this trial: \n",
            "d_model:  256\n",
            "num_layers:  5\n",
            "num_heads:  4\n",
            "dropout:  0.10960414444435924\n",
            "learning rate:  7.238904403524705e-05\n",
            "batch_szie:  16\n",
            "num_epochs:  5\n",
            "==================================================\n",
            "==================================================\n",
            "Parameters chosen for this trial: \n",
            "d_model:  128\n",
            "num_layers:  3\n",
            "num_heads:  8\n",
            "dropout:  0.1830651647153425\n",
            "learning rate:  3.8662445171871754e-05\n",
            "batch_szie:  16\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-07-29 20:03:28,711] Trial 1 failed with parameters: {'d_model': 128, 'num_layers': 3, 'num_heads': 8, 'lr': 3.8662445171871754e-05, 'batch_size': 16, 'dropout': 0.1830651647153425} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-24-1471020048.py\", line 55, in train\n",
            "    train_loss += loss.item() * labels.size(0)\n",
            "                  ^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-07-29 20:03:28,712] Trial 1 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-1471020048.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters for model: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m# torch.save(model.state_dict(), f\"/content/drive/MyDrive/dataset-final-project/multimodal-model/multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     ):\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-24-1471020048.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def train(trial):\n",
        "\n",
        "    d_model = trial.suggest_categorical('d_model', [64, 128, 256])\n",
        "    num_layers = trial.suggest_int('num_layers', 2, 8)\n",
        "    num_heads = trial.suggest_categorical('num_heads', [4, 8])\n",
        "    lr = trial.suggest_categorical('lr', [1e-6, 1e-5, 1e-4])\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    dropout = trial.suggest_float('dropout', 0.1, 0.4)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"Parameters chosen for this trial: \")\n",
        "    print(\"d_model: \", d_model)\n",
        "    print(\"num_layers: \", num_layers)\n",
        "    print(\"num_heads: \", num_heads)\n",
        "    print(\"dropout: \", dropout)\n",
        "    print(\"learning rate: \", lr)\n",
        "    print(\"batch_szie: \", batch_size)\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = SignatureEEGTransformer(\n",
        "        sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "        eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "        d_model=d_model, num_classes=num_classes, num_heads=num_heads, num_layers=num_layers,\n",
        "        sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len, dropout=dropout\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5) # weight_decay is for L2 regularization, to prevent overfitting\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    num_epochs = 5\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience = 3\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss, train_labels, train_preds = 0, [], []\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "            sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "            sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "            sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "            eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "            eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "            eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * labels.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            train_labels.extend(labels.cpu().numpy())\n",
        "            train_preds.extend(preds.cpu().numpy())\n",
        "        print(\"Train labels: \", train_labels[:10])\n",
        "        print(\"Pred labels: \", train_preds[:10])\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_labels)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_labels, val_preds = 0, [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "                sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "                sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "                sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "                eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "                eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "                eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "                loss = loss_fn(logits, labels)\n",
        "                val_loss += loss.item() * labels.size(0)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "        print(\"Val labels: \", val_labels[:10])\n",
        "        print(\"Pred labels: \", val_preds[:10])\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_labels)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "        print(f\"Validation F1 Score: {f1_score(val_labels, val_preds, average='weighted'):.4f}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Store metrics for plotting\n",
        "        if epoch == 0:\n",
        "            history = {\n",
        "                'train_loss': [],\n",
        "                'val_loss': [],\n",
        "                'train_acc': [],\n",
        "                'val_acc': [],\n",
        "                'val_f1': []\n",
        "            }\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(f1_score(val_labels, val_preds, average='weighted'))\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(\"Model may be overfitting, time to early stop: \")\n",
        "                break\n",
        "\n",
        "    epochs = range(1, len(history) + 1)\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
        "    plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
        "    plt.plot(epochs, history['val_acc'], label='Val Acc')\n",
        "    plt.plot(epochs, history['val_f1'], label='Val F1')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Accuracy & F1 over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"Parameters chosen for this trial: \")\n",
        "    print(\"d_model: \", d_model)\n",
        "    print(\"num_layers: \", num_layers)\n",
        "    print(\"num_heads: \", num_heads)\n",
        "    print(\"dropout: \", dropout)\n",
        "    print(\"learning rate: \", lr)\n",
        "    print(\"batch_szie: \", batch_size)\n",
        "    print(\"num_epochs: \", num_epochs if num_epochs == len(history) else len(history) - patience)\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return 1 - val_acc\n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(train, n_trials = 20)\n",
        "print(\"Best parameters for model: \", study.best_params)\n",
        "# torch.save(model.state_dict(), f\"/content/drive/MyDrive/dataset-final-project/multimodal-model/multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\")\n",
        "# torch.save(model.state_dict(), os.path.join(os.getenv(\"MODEL_PATH\"), f\"multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e6337e",
      "metadata": {
        "id": "20e6337e"
      },
      "source": [
        "## Feeding Sign + EEG data to transformer - Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5f4f7235",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "5f4f7235",
        "outputId": "6046b581-3333-4879-b2ba-490a4b600b09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(7), np.int64(1), np.int64(3), np.int64(41), np.int64(49), np.int64(59), np.int64(12), np.int64(33), np.int64(54), np.int64(55)]\n",
            "Pred labels:  [np.int64(42), np.int64(42), np.int64(42), np.int64(42), np.int64(42), np.int64(42), np.int64(42), np.int64(42), np.int64(45), np.int64(42)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1 Validation:   0%|          | 0/26 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(45), np.int64(45), np.int64(45), np.int64(45), np.int64(0), np.int64(20), np.int64(20)]\n",
            "Pred labels:  [np.int64(23), np.int64(23), np.int64(23), np.int64(21), np.int64(51), np.int64(23), np.int64(23), np.int64(55), np.int64(23), np.int64(65)]\n",
            "Epoch 1/15\n",
            "Train Loss: 4.0163 | Train Acc: 0.0947\n",
            "Val Loss: 3.8013 | Val Acc: 0.1791\n",
            "Validation F1 Score: 0.1334\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(44), np.int64(63), np.int64(2), np.int64(38), np.int64(47), np.int64(69), np.int64(54), np.int64(54), np.int64(50), np.int64(38)]\n",
            "Pred labels:  [np.int64(52), np.int64(7), np.int64(57), np.int64(52), np.int64(47), np.int64(34), np.int64(52), np.int64(54), np.int64(50), np.int64(21)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(45), np.int64(45), np.int64(45), np.int64(45), np.int64(0), np.int64(20), np.int64(20)]\n",
            "Pred labels:  [np.int64(24), np.int64(48), np.int64(40), np.int64(23), np.int64(10), np.int64(23), np.int64(23), np.int64(17), np.int64(65), np.int64(50)]\n",
            "Epoch 2/15\n",
            "Train Loss: 3.4323 | Train Acc: 0.3380\n",
            "Val Loss: 3.4372 | Val Acc: 0.2736\n",
            "Validation F1 Score: 0.2161\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-31-1670721525.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = SignatureEEGTransformer(\n",
        "    sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "    eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "    d_model=128, num_classes=num_classes, num_heads=4, num_layers=num_layers,\n",
        "    sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        ").to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4) # weight_decay is for L2 regularization, to prevent overfitting\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "num_epochs = 25\n",
        "\n",
        "best_loss = float('inf')\n",
        "patience = 5\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss, train_labels, train_preds = 0, [], []\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Train labels: \", train_labels[:10])\n",
        "    print(\"Pred labels: \", train_preds[:10])\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_labels)\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_labels, val_preds = 0, [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "            sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "            sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "            sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "            eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "            eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "            eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            val_loss += loss.item() * labels.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Val labels: \", val_labels[:10])\n",
        "    print(\"Pred labels: \", val_preds[:10])\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_labels)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"Validation F1 Score: {f1_score(val_labels, val_preds, average='weighted'):.4f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Store metrics for plotting\n",
        "    if epoch == 0:\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'val_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_acc': [],\n",
        "            'val_f1': []\n",
        "        }\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_f1'].append(f1_score(val_labels, val_preds, average='weighted'))\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Model may be overfitting, time to early stop: \")\n",
        "            break\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
        "plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
        "plt.plot(epochs, history['val_acc'], label='Val Acc')\n",
        "plt.plot(epochs, history['val_f1'], label='Val F1')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Accuracy & F1 over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "torch.save(model.state_dict(), f\"/content/drive/MyDrive/dataset-final-project/multimodal-model/multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\")\n",
        "# torch.save(model.state_dict(), os.path.join(os.getenv(\"MODEL_PATH\"), f\"multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca38f53",
      "metadata": {
        "id": "0ca38f53"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_labels, val_preds))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_labels, val_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5791b9fd",
      "metadata": {
        "id": "5791b9fd"
      },
      "source": [
        "## Validating Sign+EEG tranformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wc0CgUbQga7P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc0CgUbQga7P",
        "outputId": "517cac5d-10d9-4f8a-86cd-e60209f0670b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69}\n"
          ]
        }
      ],
      "source": [
        "print(set([x for x in user_id_to_num_map.values()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y1vIagzLgADI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vIagzLgADI",
        "outputId": "bfd34ef5-884a-4d98-e56c-3e23cfd3cd6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['000000802810034', '000000802810034', '000000802810034', '000140809082110', '000140809082110', '001810111230005', '001810111230005', '001810111230005', '001810111230005', '000000001941061', '000000001941061', '000000001941061', '000000001941061', '000000001941061', '000000001941061', '000000003150143', '000000003150143', '000000003150143', '000000003150143', '000000001046474', '000000001046474', '000000814510023', '000000814510023', '000000814510023', '000000001045402', '000000001045402', '000000001045402', '000000000200894', '000000000200894', '001810111230006', '001810111230006', '001810111230006', '002008410100008', '002008410100008', '002008410100008', '002008410100015', '002008410100015', '002008410100015', '002008410100015', '002008410100025', '002008410100030', '002008410100030', '002008410100030', '002008410100030', '002008410100030', '002008410100013', '002008410100013', '002008410100013', '002008410100011', '002008410100011', '002008410100011', '002008410100011', '002008410100011', '002008410100011', '002008410100016', '002008410100016', '002008410100040', '002008410100040', '002008410100018', '002008410100018', '002008410100018', '002108410100006', '002108410100006', '002108410100006', '002108410100006', '002108410100006', '002108410100005', '002108410100005', '002108410100005', '002108410100005', '002108410100002', '002108410100002', '002008410100052', '002008410100052', '002008410100052', '002008410100052', '002108410100001', '002108410100001', '002108410100001', '002008410100044', '002008410100044', '002008410300021', '002008410300021', '002008410300021', '002008410300021', '002008410100050', '002008410100050', '002008410100050', '002008410100050', '002008410100050', '002008410100050', '002108410100003', '002108410100003', '002108410100016', '002108410100016', '002108410100016', '002108410100016', '002108410100016', '002108410100016', '002108410100012', '002108410100012', '002108410100020', '002108410100020', '002108410100010', '002108410100010', '002108410100010', '002108410100010', '002108410100007', '002108410100007', '002108410100017', '002108410100017', '002108410100017', '002108410100017', '002108410100017', '002108410100046', '002108410100046', '002108410100046', '002108410100044', '002108410100044', '002108410100044', '002108410100036', '002108410100036', '002108410100036', '002108410100043', '002108410100043', '002108410100043', '002108410100040', '002108410100040', '002108410100041', '002108410100038', '002108410100038', '002108410100038', '002108410100045', '002108410100045', '002108410100061', '002108410100061', '002108410100061', '002108410200016', '002108410200016', '002108410200016', '002108410200018', '002108410200018', '002108410200018', '002108410200018', '002108410200018', '002108410100047', '002108410100047', '002108410100047', '002108410200021', '002108410200021', '002108410200021', '002108410200049', '002108410200049', '002108410200049', '002108410200049', '002108410200037', '002108410200037', '002108410200037', '002108410200037', '002108410100051', '002108410100051', '002108410100051', '002108410100048', '002108410100048', '002108410300017', '002108410300017', '002108410300017', '002108410300017', '002108410300006', '002108410300006', '002108410300006', '002108410300006', '002108410200051', '002108410300030', '002108410300030', '002108410300030', '002108410300030', '002108410300001', '002108410300039', '002108410300042', '002108410300042', '002108410300042', '002108410300028', '002108410300028', '002108410300028', '002108410300034', '002108410300041']\n"
          ]
        }
      ],
      "source": [
        "print([x['user_id'] for x in raw_val_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf85013",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcf85013",
        "outputId": "29b4b577-ee75-4808-ad8a-e50453403614"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_20336\\1646318677.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_20336\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 136, using nperseg = 136\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_20336\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 197, using nperseg = 197\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_20336\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 203, using nperseg = 203\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n"
          ]
        }
      ],
      "source": [
        "# validation loop\n",
        "\n",
        "# Augment and preprocess test data (no augmentation, just features and padding)\n",
        "for i in range(len(raw_val_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_val_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_val_data[i]['eeg_data'])\n",
        "    raw_val_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_val_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_val_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_val_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "    raw_val_data[i]['user_id'] = user_id_to_num_map[raw_val_data[i]['user_id']]\n",
        "\n",
        "sign_max_seq_len_test = max_seq_len_for_data\n",
        "eeg_max_seq_len_test = 10\n",
        "\n",
        "for i in range(len(raw_val_data)):\n",
        "    sign_data = raw_val_data[i]['sign_data']\n",
        "    eeg_data = raw_val_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len_test)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len_test)\n",
        "    raw_val_data[i]['sign_data'] = sign_data\n",
        "    raw_val_data[i]['eeg_data'] = eeg_data\n",
        "    raw_val_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_val_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "val_input_data = {\n",
        "    'sign_data': [data['sign_data'] for data in raw_val_data],\n",
        "    'eeg_data': [data['eeg_data'] for data in raw_val_data],\n",
        "    'sign_attention_masks': [data['sign_attention_mask'] for data in raw_val_data],\n",
        "    'eeg_attention_masks': [data['eeg_attention_mask'] for data in raw_val_data],\n",
        "    'sign_cls_tokens': [data['sign_cls_token'] for data in raw_val_data],\n",
        "    'eeg_cls_tokens': [data['eeg_cls_token'] for data in raw_val_data],\n",
        "    'labels': [data['user_id'] for data in raw_val_data],\n",
        "}\n",
        "\n",
        "sign_ts_dim = val_input_data['sign_data'][0].size(1)\n",
        "sign_cls_dim = val_input_data['sign_cls_tokens'][0].size(0)\n",
        "sign_seq_len = val_input_data['sign_data'][0].size(0)\n",
        "eeg_ts_dim = val_input_data['eeg_data'][0].size(1)\n",
        "eeg_cls_dim = val_input_data['eeg_cls_tokens'][0].size(0)\n",
        "eeg_seq_len = val_input_data['eeg_data'][0].size(0)\n",
        "\n",
        "val_dataset = SignatureEEGDataset(val_input_data, num_classes)\n",
        "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a98d4ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a98d4ee",
        "outputId": "67a8dfbd-3a39-42e6-a64d-5139b84de64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "187\n"
          ]
        }
      ],
      "source": [
        "print(len(val_input_data['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wUCeKktmHaiN",
      "metadata": {
        "id": "wUCeKktmHaiN"
      },
      "outputs": [],
      "source": [
        "print(test_input_data['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2648c476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2648c476",
        "outputId": "1a81b434-6763-4f1d-a742-6c03757dd92b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 7.7567\n",
            "Validation Accuracy: 0.0000\n",
            "Validation Precision: 0.0000\n",
            "Validation Recall: 0.0000\n",
            "Validation F1 Score: 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# model = SignatureEEGTransformer(\n",
        "#     sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "#     eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "#     d_model=128, num_classes=num_classes, num_heads=4, num_layers=7,\n",
        "#     sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        "# ).to(device)\n",
        "\n",
        "# model.load_state_dict(torch.load(os.path.join(os.getenv(\"MODEL_PATH\"), \"multimodal_model_07242025-142030.pth\"), map_location=device))\n",
        "\n",
        "# model.load_state_dict(torch.load(os.path.join(os.getenv(\"MODEL_PATH\"), f\"multimodal_model_07242025-142030.pth\"), map_location=device))\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.eval()\n",
        "val_loss = 0\n",
        "val_labels = []\n",
        "val_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        val_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "        val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "avg_val_loss = val_loss / len(val_labels)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "val_prec = precision_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "val_rec = recall_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "val_f1 = f1_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "\n",
        "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Validation Precision: {val_prec:.4f}\")\n",
        "print(f\"Validation Recall: {val_rec:.4f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40cb4081",
      "metadata": {
        "id": "40cb4081",
        "outputId": "67dbbbd3-cda3-46a6-d620-d047b0b0e645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(np.int64(25), np.int64(39)), (np.int64(25), np.int64(39)), (np.int64(42), np.int64(68)), (np.int64(42), np.int64(55)), (np.int64(42), np.int64(68)), (np.int64(49), np.int64(40)), (np.int64(49), np.int64(14)), (np.int64(18), np.int64(13)), (np.int64(18), np.int64(13)), (np.int64(18), np.int64(13)), (np.int64(18), np.int64(13)), (np.int64(18), np.int64(13)), (np.int64(18), np.int64(13)), (np.int64(34), np.int64(32)), (np.int64(34), np.int64(32)), (np.int64(34), np.int64(32)), (np.int64(34), np.int64(32)), (np.int64(2), np.int64(31)), (np.int64(2), np.int64(31)), (np.int64(2), np.int64(31)), (np.int64(7), np.int64(37)), (np.int64(7), np.int64(37)), (np.int64(7), np.int64(37)), (np.int64(26), np.int64(66)), (np.int64(26), np.int64(27)), (np.int64(47), np.int64(10)), (np.int64(47), np.int64(10)), (np.int64(47), np.int64(10)), (np.int64(47), np.int64(10)), (np.int64(39), np.int64(53)), (np.int64(39), np.int64(36)), (np.int64(39), np.int64(53)), (np.int64(17), np.int64(30)), (np.int64(17), np.int64(30)), (np.int64(17), np.int64(30)), (np.int64(38), np.int64(59)), (np.int64(38), np.int64(59)), (np.int64(38), np.int64(45)), (np.int64(38), np.int64(2)), (np.int64(38), np.int64(59)), (np.int64(38), np.int64(59)), (np.int64(24), np.int64(26)), (np.int64(24), np.int64(63)), (np.int64(24), np.int64(63)), (np.int64(5), np.int64(3)), (np.int64(5), np.int64(3)), (np.int64(5), np.int64(3)), (np.int64(5), np.int64(3)), (np.int64(16), np.int64(65)), (np.int64(16), np.int64(65)), (np.int64(3), np.int64(41)), (np.int64(3), np.int64(64)), (np.int64(3), np.int64(64)), (np.int64(27), np.int64(22)), (np.int64(60), np.int64(66)), (np.int64(60), np.int64(66)), (np.int64(60), np.int64(14)), (np.int64(60), np.int64(40)), (np.int64(60), np.int64(66)), (np.int64(23), np.int64(49)), (np.int64(23), np.int64(49)), (np.int64(32), np.int64(62)), (np.int64(32), np.int64(62)), (np.int64(53), np.int64(5)), (np.int64(53), np.int64(49)), (np.int64(53), np.int64(33)), (np.int64(53), np.int64(0)), (np.int64(53), np.int64(5)), (np.int64(53), np.int64(5)), (np.int64(21), np.int64(47)), (np.int64(21), np.int64(47)), (np.int64(21), np.int64(47)), (np.int64(21), np.int64(47)), (np.int64(9), np.int64(46)), (np.int64(9), np.int64(46)), (np.int64(9), np.int64(46)), (np.int64(9), np.int64(46)), (np.int64(8), np.int64(44)), (np.int64(8), np.int64(44)), (np.int64(8), np.int64(44)), (np.int64(46), np.int64(18)), (np.int64(46), np.int64(44)), (np.int64(63), np.int64(55)), (np.int64(63), np.int64(55)), (np.int64(30), np.int64(8)), (np.int64(30), np.int64(8)), (np.int64(30), np.int64(8)), (np.int64(30), np.int64(8)), (np.int64(65), np.int64(61)), (np.int64(65), np.int64(61)), (np.int64(65), np.int64(61)), (np.int64(65), np.int64(61)), (np.int64(65), np.int64(61)), (np.int64(6), np.int64(54)), (np.int64(6), np.int64(54)), (np.int64(50), np.int64(26)), (np.int64(50), np.int64(26)), (np.int64(50), np.int64(9)), (np.int64(50), np.int64(26)), (np.int64(41), np.int64(25)), (np.int64(41), np.int64(25)), (np.int64(61), np.int64(11)), (np.int64(61), np.int64(11)), (np.int64(61), np.int64(11)), (np.int64(61), np.int64(11)), (np.int64(61), np.int64(54)), (np.int64(61), np.int64(11)), (np.int64(36), np.int64(23)), (np.int64(36), np.int64(23)), (np.int64(36), np.int64(23)), (np.int64(36), np.int64(23)), (np.int64(36), np.int64(23)), (np.int64(54), np.int64(35)), (np.int64(54), np.int64(35)), (np.int64(14), np.int64(56)), (np.int64(14), np.int64(56)), (np.int64(14), np.int64(56)), (np.int64(69), np.int64(57)), (np.int64(69), np.int64(57)), (np.int64(69), np.int64(57)), (np.int64(11), np.int64(42)), (np.int64(11), np.int64(42)), (np.int64(59), np.int64(67)), (np.int64(10), np.int64(15)), (np.int64(10), np.int64(15)), (np.int64(10), np.int64(15)), (np.int64(1), np.int64(33)), (np.int64(1), np.int64(33)), (np.int64(1), np.int64(33)), (np.int64(52), np.int64(58)), (np.int64(52), np.int64(58)), (np.int64(43), np.int64(29)), (np.int64(43), np.int64(48)), (np.int64(43), np.int64(48)), (np.int64(20), np.int64(43)), (np.int64(20), np.int64(52)), (np.int64(20), np.int64(43)), (np.int64(67), np.int64(28)), (np.int64(67), np.int64(58)), (np.int64(4), np.int64(16)), (np.int64(4), np.int64(16)), (np.int64(4), np.int64(16)), (np.int64(37), np.int64(38)), (np.int64(37), np.int64(38)), (np.int64(37), np.int64(38)), (np.int64(12), np.int64(36)), (np.int64(12), np.int64(36)), (np.int64(12), np.int64(36)), (np.int64(55), np.int64(64)), (np.int64(55), np.int64(64)), (np.int64(55), np.int64(64)), (np.int64(55), np.int64(64)), (np.int64(55), np.int64(64)), (np.int64(57), np.int64(20)), (np.int64(57), np.int64(20)), (np.int64(57), np.int64(20)), (np.int64(31), np.int64(1)), (np.int64(31), np.int64(1)), (np.int64(31), np.int64(1)), (np.int64(31), np.int64(1)), (np.int64(64), np.int64(7)), (np.int64(64), np.int64(63)), (np.int64(64), np.int64(7)), (np.int64(64), np.int64(4)), (np.int64(13), np.int64(52)), (np.int64(56), np.int64(59)), (np.int64(44), np.int64(6)), (np.int64(44), np.int64(6)), (np.int64(44), np.int64(0)), (np.int64(44), np.int64(0)), (np.int64(33), np.int64(0)), (np.int64(33), np.int64(0)), (np.int64(33), np.int64(27)), (np.int64(33), np.int64(0)), (np.int64(28), np.int64(4)), (np.int64(28), np.int64(4)), (np.int64(28), np.int64(4)), (np.int64(29), np.int64(17)), (np.int64(29), np.int64(17)), (np.int64(29), np.int64(17)), (np.int64(29), np.int64(3)), (np.int64(45), np.int64(40)), (np.int64(19), np.int64(60)), (np.int64(15), np.int64(34)), (np.int64(35), np.int64(9)), (np.int64(35), np.int64(9)), (np.int64(35), np.int64(9))]\n"
          ]
        }
      ],
      "source": [
        "print([i for i in zip(val_labels, val_preds)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdf2f761",
      "metadata": {
        "id": "fdf2f761"
      },
      "source": [
        "## User Identification - Feature ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1538ae58",
      "metadata": {
        "id": "1538ae58"
      },
      "outputs": [],
      "source": [
        "def predict(input):\n",
        "    sign_data, eeg_data, sign_cls, eeg_cls, sign_attn, eeeg_attn = input\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits= model(\n",
        "            sign_data.to(device),\n",
        "            sign_cls.to(device),\n",
        "            eeg_data.to(device),\n",
        "            eeg_cls.to(device),\n",
        "            sign_attn.to(device),\n",
        "            eeeg_attn.to(device)\n",
        "        )\n",
        "        preds = logits.argmax(dim=1)\n",
        "    return preds.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7086a89",
      "metadata": {
        "id": "e7086a89"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_loader))\n",
        "sample = [batch['sign_x_ts'][:10], batch['eeg_x_ts'][:10], batch['sign_cls_token'][:10], batch['eeg_cls_token'][:10], batch['sign_attention_mask'][:10], batch['eeg_attention_mask'][:10]]\n",
        "\n",
        "explainer = shap.DeeepExplainer(predict, sample)\n",
        "\n",
        "val_batch = next(iter(val_loader))\n",
        "val_sample = [val_batch['sign_x_ts'][:10], val_batch['eeg_x_ts'][:10], val_batch['sign_cls_token'][:10], val_batch['eeg_cls_token'][:10], val_batch['sign_attention_mask'][:10], val_batch['eeg_attention_mask'][:10]]\n",
        "\n",
        "shap_values = explainer.shap_values(val_sample)\n",
        "\n",
        "sign_shap_cls_values = shap_values[0][:, 0, :]\n",
        "mean_importance = np.mean(np.abs(sign_shap_cls_values), axis=0)\n",
        "feature_names = [f\"Feature (CLS) {i+1}\" for i in range(sign_shap_cls_values.shape[1])]\n",
        "plt.barh(feature_names, mean_importance)\n",
        "plt.xlabel(\"Mean |SHAP value|\")\n",
        "plt.title(\"Sign CLS Token Feature Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22268dff",
      "metadata": {
        "id": "22268dff"
      },
      "outputs": [],
      "source": [
        "sign_shap_ts_values = shap_values[0][:, 1:, :]\n",
        "mean_importance_ts = np.mean(np.abs(sign_shap_ts_values), axis=0)\n",
        "feature_names_ts = [f\"Feature (TS) {i+1}\" for i in range(sign_shap_ts_values.shape[2])]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names_ts, mean_importance_ts.mean(axis=0))\n",
        "plt.xlabel(\"Mean |SHAP value|\")\n",
        "plt.title(\"Sign TS Token Feature Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c1a284",
      "metadata": {
        "id": "53c1a284"
      },
      "outputs": [],
      "source": [
        "eeg_shap_values = shap_values[1][:, 0, :]\n",
        "mean_importance_eeg = np.mean(np.abs(eeg_shap_values), axis=0)\n",
        "feature_names_eeg = [f\"Feature {i+1}\" for i in range(eeg_shap_values.shape[1])]\n",
        "plt.barh(feature_names_eeg, mean_importance_eeg)\n",
        "plt.xlabel(\"Mean |SHAP value|\")\n",
        "plt.title(\"EEG CLS Token Feature Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "175118d9",
      "metadata": {
        "id": "175118d9"
      },
      "outputs": [],
      "source": [
        "eeg_shap_ts_values = shap_values[1][:, 1:, :]\n",
        "mean_importance_eeg_ts = np.mean(np.abs(eeg_shap_ts_values), axis=0)\n",
        "feature_names_eeg_ts = [f\"Feature (TS) {i+1}\" for i in range(eeg_shap_ts_values.shape[2])]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names_eeg_ts, mean_importance_eeg_ts.mean(axis=0))\n",
        "plt.xlabel(\"Mean |SHAP value|\")\n",
        "plt.title(\"EEG TS Token Feature Importance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ca6804",
      "metadata": {
        "id": "d2ca6804"
      },
      "source": [
        "# Sign + EEG Forgery Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b027453",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b027453",
        "outputId": "b435c767-a41f-4dce-fe30-fe69d1e36542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files:  1138\n",
            "Test files:  379\n",
            "Val files:  380\n"
          ]
        }
      ],
      "source": [
        "train_files, _, train_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type = constants.TRAIN, task = constants.IDENTIFY)\n",
        "test_files, _, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST, task = constants.IDENTIFY)\n",
        "val_files, _, val_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.VALIDATION, task = constants.IDENTIFY)\n",
        "\n",
        "print(\"Train files: \", len(train_files))\n",
        "print(\"Test files: \", len(test_files))\n",
        "print(\"Val files: \", len(val_files))\n",
        "\n",
        "raw_train_data = get_sig_eeg_raw_data(train_files, train_labels)\n",
        "raw_test_data = get_sig_eeg_raw_data(test_files, test_labels)\n",
        "raw_val_data = get_sig_eeg_raw_data(val_files, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "934fdd8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "934fdd8d",
        "outputId": "5e9e471f-8bfe-4235-998b-55951ef514c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-10-1646318677.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
            "/tmp/ipython-input-15-4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 136, using nperseg = 136\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "/tmp/ipython-input-15-4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 203, using nperseg = 203\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "/tmp/ipython-input-15-4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 197, using nperseg = 197\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n"
          ]
        }
      ],
      "source": [
        "augmented_raw_data = []\n",
        "num_augments = 3\n",
        "\n",
        "for sample in raw_train_data:\n",
        "    augmented_raw_data.append(sample)\n",
        "    for _ in range(num_augments):\n",
        "        aug_sample = sample.copy()\n",
        "        aug_sample['sign_data'] = augment_sign_data(sample['sign_data'])\n",
        "        aug_sample['eeg_data'] = augment_eeg_data(sample['eeg_data'])\n",
        "        augmented_raw_data.append(aug_sample)\n",
        "\n",
        "raw_train_data = augmented_raw_data\n",
        "# shuffling to prevent overfitting\n",
        "random.shuffle(raw_train_data)\n",
        "\n",
        "for i in range(len(raw_train_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_train_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_train_data[i]['eeg_data'])\n",
        "    # print(\"EEG Feature data shape: \", eeg_data_with_features.shape)\n",
        "    raw_train_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_train_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_train_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_train_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "\n",
        "for i in range(len(raw_test_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_test_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_test_data[i]['eeg_data'])\n",
        "    raw_test_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_test_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_test_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_test_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "\n",
        "for i in range(len(raw_val_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_val_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_val_data[i]['eeg_data'])\n",
        "    raw_val_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_val_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_val_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_val_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = 5\n",
        "\n",
        "for i in range(len(raw_train_data)):\n",
        "    sign_data = raw_train_data[i]['sign_data']\n",
        "    eeg_data = raw_train_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_train_data[i]['sign_data'] = sign_data\n",
        "    raw_train_data[i]['eeg_data'] = eeg_data\n",
        "    raw_train_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_train_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "for i in range(len(raw_test_data)):\n",
        "    sign_data = raw_test_data[i]['sign_data']\n",
        "    eeg_data = raw_test_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_test_data[i]['sign_data'] = sign_data\n",
        "    raw_test_data[i]['eeg_data'] = eeg_data\n",
        "    raw_test_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_test_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "for i in range(len(raw_val_data)):\n",
        "    sign_data = raw_val_data[i]['sign_data']\n",
        "    eeg_data = raw_val_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_val_data[i]['sign_data'] = sign_data\n",
        "    raw_val_data[i]['eeg_data'] = eeg_data\n",
        "    raw_val_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_val_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "sign_train_data = [data['sign_data'] for data in raw_train_data]\n",
        "eeg_train_data = [data['eeg_data'] for data in raw_train_data]\n",
        "sign_train_attention_masks = [data['sign_attention_mask'] for data in raw_train_data]\n",
        "eeg_train_attention_masks = [data['eeg_attention_mask'] for data in raw_train_data]\n",
        "sign_train_cls_tokens = [data['sign_cls_token'] for data in raw_train_data]\n",
        "eeg_train_cls_tokens = [data['eeg_cls_token'] for data in raw_train_data]\n",
        "labels_train = [data['label'] for data in raw_train_data]\n",
        "files_train = [data['file'] for data in raw_train_data]\n",
        "\n",
        "sign_test_data = [data['sign_data'] for data in raw_test_data]\n",
        "eeg_test_data = [data['eeg_data'] for data in raw_test_data]\n",
        "sign_test_attention_masks = [data['sign_attention_mask'] for data in raw_test_data]\n",
        "eeg_test_attention_masks = [data['eeg_attention_mask'] for data in raw_test_data]\n",
        "sign_test_cls_tokens = [data['sign_cls_token'] for data in raw_test_data]\n",
        "eeg_test_cls_tokens = [data['eeg_cls_token'] for data in raw_test_data]\n",
        "labels_test = [data['label'] for data in raw_test_data]\n",
        "files_test = [data['file'] for data in raw_test_data]\n",
        "\n",
        "sign_val_data = [data['sign_data'] for data in raw_val_data]\n",
        "eeg_val_data = [data['eeg_data'] for data in raw_val_data]\n",
        "sign_val_attention_masks = [data['sign_attention_mask'] for data in raw_val_data]\n",
        "eeg_val_attention_masks = [data['eeg_attention_mask'] for data in raw_val_data]\n",
        "eeg_val_cls_tokens = [data['eeg_cls_token'] for data in raw_val_data]\n",
        "sign_val_cls_tokens = [data['sign_cls_token'] for data in raw_val_data]\n",
        "labels_val = [data['label'] for data in raw_val_data]\n",
        "files_val = [data['file'] for data in raw_val_data]\n",
        "\n",
        "train_input = {\n",
        "    'sign_data': sign_train_data,\n",
        "    'eeg_data': eeg_train_data,\n",
        "    'sign_attention_masks': sign_train_attention_masks,\n",
        "    'eeg_attention_masks': eeg_train_attention_masks,\n",
        "    'sign_cls_tokens': sign_train_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_train_cls_tokens,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "\n",
        "test_input = {\n",
        "    'sign_data': sign_test_data,\n",
        "    'eeg_data': eeg_test_data,\n",
        "    'sign_attention_masks': sign_test_attention_masks,\n",
        "    'eeg_attention_masks': eeg_test_attention_masks,\n",
        "    'sign_cls_tokens': sign_test_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_test_cls_tokens,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "\n",
        "val_input = {\n",
        "    'sign_data': sign_val_data,\n",
        "    'eeg_data': eeg_val_data,\n",
        "    'sign_attention_masks': sign_val_attention_masks,\n",
        "    'eeg_attention_masks': eeg_val_attention_masks,\n",
        "    'sign_cls_tokens': sign_val_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_val_cls_tokens,\n",
        "    'labels': labels_val,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mfj5Dy56QBpw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfj5Dy56QBpw",
        "outputId": "0f28641f-9790-493a-cfe3-fbc36ce8c04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sign train data type:  <class 'list'>\n",
            "EEG train data type:  <class 'list'>\n",
            "Sign train data type:  <class 'torch.Tensor'>\n",
            "EEG train data type:  <class 'torch.Tensor'>\n",
            "Sign train cls tokens type:  <class 'torch.Tensor'>\n",
            "EEG train cls tokens type:  <class 'torch.Tensor'>\n",
            "Sign train data shape:  torch.Size([3000, 11])\n",
            "EEG train data shape:  torch.Size([5, 325])\n",
            "Sign train attention mask shape:  torch.Size([3001])\n",
            "EEG train attention mask shape:  torch.Size([6])\n",
            "Train labels length:  4540\n",
            "Test labels length:  379\n",
            "Train labels:  [1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
            "Test labels:  [1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "Num signs:  4540\n"
          ]
        }
      ],
      "source": [
        "print(\"Sign train data type: \", type(sign_train_data))\n",
        "print(\"EEG train data type: \", type(eeg_train_data))\n",
        "print(\"Sign train data type: \", type(sign_train_attention_masks[0]))\n",
        "print(\"EEG train data type: \", type(eeg_train_attention_masks[0]))\n",
        "print(\"Sign train cls tokens type: \", type(sign_train_cls_tokens[0]))\n",
        "print(\"EEG train cls tokens type: \", type(eeg_train_cls_tokens[0]))\n",
        "\n",
        "print(\"Sign train data shape: \", sign_train_data[0].shape)\n",
        "print(\"EEG train data shape: \", eeg_train_data[0].shape)\n",
        "print(\"Sign train attention mask shape: \", sign_train_attention_masks[0].shape)\n",
        "print(\"EEG train attention mask shape: \", eeg_train_attention_masks[0].shape)\n",
        "print(\"Train labels length: \", len(labels_train))\n",
        "print(\"Test labels length: \", len(labels_test))\n",
        "print(\"Train labels: \", labels_train[:10])\n",
        "print(\"Test labels: \", labels_test[:10])\n",
        "\n",
        "print(\"Num signs: \", len(sign_train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OIOwXfZiPZe5",
      "metadata": {
        "id": "OIOwXfZiPZe5"
      },
      "outputs": [],
      "source": [
        "sign_ts_dim = sign_train_data[0].size(1)\n",
        "sign_cls_dim = sign_train_cls_tokens[0].size(0)\n",
        "sign_seq_len = sign_train_data[0].size(0)\n",
        "eeg_ts_dim = eeg_train_data[0].size(1)\n",
        "eeg_cls_dim = eeg_train_cls_tokens[0].size(0)\n",
        "eeg_seq_len = eeg_train_data[0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb57db8",
      "metadata": {
        "id": "6cb57db8"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "d_model = 256\n",
        "num_classes = 2\n",
        "num_heads = 4\n",
        "num_layers = 4\n",
        "num_epochs = 25\n",
        "\n",
        "train_loader = DataLoader(SignatureEEGDataset(train_input, num_classes), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(SignatureEEGDataset(test_input, num_classes), batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(SignatureEEGDataset(val_input, num_classes), batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72dc05ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72dc05ba",
        "outputId": "949ae2c6-b6ab-4aee-ea4b-7087d677f53d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 1/25\n",
            "Train Loss: 0.6458 | Train Acc: 0.6216\n",
            "Test Loss: 0.6170 | Test Acc: 0.6596\n",
            "Test F1 Score: 0.6560\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 2/25\n",
            "Train Loss: 0.5844 | Train Acc: 0.6826\n",
            "Test Loss: 0.5735 | Test Acc: 0.7018\n",
            "Test F1 Score: 0.6979\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 3/25\n",
            "Train Loss: 0.5429 | Train Acc: 0.7240\n",
            "Test Loss: 0.5645 | Test Acc: 0.6860\n",
            "Test F1 Score: 0.6854\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 4/25\n",
            "Train Loss: 0.5205 | Train Acc: 0.7357\n",
            "Test Loss: 0.5771 | Test Acc: 0.6939\n",
            "Test F1 Score: 0.6942\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 5/25\n",
            "Train Loss: 0.4869 | Train Acc: 0.7621\n",
            "Test Loss: 0.5691 | Test Acc: 0.6992\n",
            "Test F1 Score: 0.6980\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 6/25\n",
            "Train Loss: 0.4622 | Train Acc: 0.7817\n",
            "Test Loss: 0.5953 | Test Acc: 0.6939\n",
            "Test F1 Score: 0.6807\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 7/25\n",
            "Train Loss: 0.4505 | Train Acc: 0.7833\n",
            "Test Loss: 0.5573 | Test Acc: 0.7388\n",
            "Test F1 Score: 0.7390\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 8/25\n",
            "Train Loss: 0.4191 | Train Acc: 0.8066\n",
            "Test Loss: 0.6245 | Test Acc: 0.7098\n",
            "Test F1 Score: 0.7088\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 9/25\n",
            "Train Loss: 0.4022 | Train Acc: 0.8176\n",
            "Test Loss: 0.5920 | Test Acc: 0.7282\n",
            "Test F1 Score: 0.7282\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 10/25\n",
            "Train Loss: 0.3876 | Train Acc: 0.8222\n",
            "Test Loss: 0.6087 | Test Acc: 0.7203\n",
            "Test F1 Score: 0.7198\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 11/25\n",
            "Train Loss: 0.3553 | Train Acc: 0.8427\n",
            "Test Loss: 0.7225 | Test Acc: 0.7150\n",
            "Test F1 Score: 0.7113\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 12/25\n",
            "Train Loss: 0.3555 | Train Acc: 0.8447\n",
            "Test Loss: 0.5924 | Test Acc: 0.7203\n",
            "Test F1 Score: 0.7165\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 13/25\n",
            "Train Loss: 0.3302 | Train Acc: 0.8575\n",
            "Test Loss: 0.6291 | Test Acc: 0.7071\n",
            "Test F1 Score: 0.7046\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 14/25\n",
            "Train Loss: 0.3083 | Train Acc: 0.8707\n",
            "Test Loss: 0.6299 | Test Acc: 0.7282\n",
            "Test F1 Score: 0.7239\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 15/25\n",
            "Train Loss: 0.3026 | Train Acc: 0.8720\n",
            "Test Loss: 0.6918 | Test Acc: 0.6913\n",
            "Test F1 Score: 0.6872\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 16/25\n",
            "Train Loss: 0.2751 | Train Acc: 0.8866\n",
            "Test Loss: 0.6974 | Test Acc: 0.7414\n",
            "Test F1 Score: 0.7411\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 17/25\n",
            "Train Loss: 0.2620 | Train Acc: 0.8934\n",
            "Test Loss: 0.7482 | Test Acc: 0.7150\n",
            "Test F1 Score: 0.7130\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 18/25\n",
            "Train Loss: 0.2442 | Train Acc: 0.9037\n",
            "Test Loss: 0.7593 | Test Acc: 0.7124\n",
            "Test F1 Score: 0.7097\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 19/25\n",
            "Train Loss: 0.2363 | Train Acc: 0.9055\n",
            "Test Loss: 0.7481 | Test Acc: 0.7282\n",
            "Test F1 Score: 0.7243\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 20/25\n",
            "Train Loss: 0.2188 | Train Acc: 0.9159\n",
            "Test Loss: 0.8342 | Test Acc: 0.7256\n",
            "Test F1 Score: 0.7214\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 21/25\n",
            "Train Loss: 0.2109 | Train Acc: 0.9176\n",
            "Test Loss: 0.9173 | Test Acc: 0.7282\n",
            "Test F1 Score: 0.7284\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 22/25\n",
            "Train Loss: 0.1999 | Train Acc: 0.9196\n",
            "Test Loss: 0.9379 | Test Acc: 0.7256\n",
            "Test F1 Score: 0.7255\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 23/25\n",
            "Train Loss: 0.1880 | Train Acc: 0.9278\n",
            "Test Loss: 0.9487 | Test Acc: 0.6992\n",
            "Test F1 Score: 0.6933\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 24/25\n",
            "Train Loss: 0.1967 | Train Acc: 0.9256\n",
            "Test Loss: 0.9693 | Test Acc: 0.7045\n",
            "Test F1 Score: 0.7000\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test labels:  [np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Pred labels:  [np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1)]\n",
            "Epoch 25/25\n",
            "Train Loss: 0.1624 | Train Acc: 0.9385\n",
            "Test Loss: 0.9600 | Test Acc: 0.7203\n",
            "Test F1 Score: 0.7197\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SignatureEEGTransformer(\n",
        "    sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "    eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "    d_model=d_model, num_classes=num_classes, num_heads=num_heads, num_layers=num_layers,\n",
        "    sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        ").to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4) # weight_decay is for L2 regularization, to prevent overfitting\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# best_loss = float('inf')\n",
        "# patience = 5\n",
        "# counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss, train_labels, train_preds = 0, [], []\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Train labels: \", train_labels[:10])\n",
        "    print(\"Pred labels: \", train_preds[:10])\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_labels)\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss, test_labels, test_preds = 0, [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=f\"Epoch {epoch+1} Testing\", leave=False):\n",
        "            sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "            sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "            sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "            eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "            eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "            eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            test_loss += loss.item() * labels.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            test_labels.extend(labels.cpu().numpy())\n",
        "            test_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Test labels: \", test_labels[:10])\n",
        "    print(\"Pred labels: \", test_preds[:10])\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_labels)\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "    print(f\"Test F1 Score: {f1_score(test_labels, test_preds, average='weighted'):.4f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Store metrics for plotting\n",
        "    if epoch == 0:\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'test_loss': [],\n",
        "            'train_acc': [],\n",
        "            'test_acc': [],\n",
        "            'test_f1': []\n",
        "        }\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['test_loss'].append(avg_test_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    history['test_f1'].append(f1_score(test_labels, test_preds, average='weighted'))\n",
        "\n",
        "    # if test_loss < best_loss:\n",
        "    #     best_loss = test_loss\n",
        "    #     counter = 0\n",
        "    # else:\n",
        "    #     counter += 1\n",
        "    #     if counter >= patience:\n",
        "    #         print(\"Model may be overfitting, time to early stop: \")\n",
        "    #         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yTce2qz9iocV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "yTce2qz9iocV",
        "outputId": "0fd9ae66-5679-4db5-bacf-8a2d6e13c23f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = range(1, len(history['train_loss']) + 1)\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
        "plt.plot(epochs, history['test_loss'], label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
        "plt.plot(epochs, history['test_acc'], label='Test Acc')\n",
        "plt.plot(epochs, history['test_f1'], label='Test F1')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Accuracy & F1 over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "ConfusionMatrixDisplay.from_predictions(test_labels, test_preds, cmap='Blues', ax=plt.gca())\n",
        "plt.title('Test Confusion Matrix')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "torch.save(model.state_dict(), f\"/content/drive/MyDrive/dataset-final-project/forgery-model/forgery_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\")\n",
        "# torch.save(model.state_dict(), os.path.join(os.getenv(\"MODEL_PATH\"), f\"multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jd4J-PUtia6B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd4J-PUtia6B",
        "outputId": "6c764c6b-45e5-4d30-ecbf-1abcc9fe8cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_loss': [0.5745288943786071, 0.47318450171540727, 0.41117847509082434, 0.36110928735711073, 0.31777375354246945, 0.2800721627100258], 'test_loss': [0.590848282962487, 0.6172190133609998, 0.641930687651628, 0.6819166986954873, 0.7083314655245452, 0.8247748450732404], 'train_acc': [0.6896275530636764, 0.7712454945935122, 0.8129755706848217, 0.8411694032839407, 0.868241890268322, 0.8882659191029235], 'test_acc': [0.712401055408971, 0.712401055408971, 0.7282321899736148, 0.7361477572559367, 0.7546174142480211, 0.7493403693931399], 'test_f1': [0.7045452423095135, 0.7124851504239937, 0.7283116559052417, 0.7296599618499355, 0.7522703535727733, 0.7488341886880712]}\n"
          ]
        }
      ],
      "source": [
        "print(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7157db9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7157db9b",
        "outputId": "383a95a5-6e1e-4cd2-89d1-7fd5b0872459"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.8375\n",
            "Validation Accuracy: 0.7487\n",
            "Validation Precision: 0.7665\n",
            "Validation Recall: 0.7500\n",
            "Validation F1 Score: 0.7451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "val_loss = 0\n",
        "val_labels = []\n",
        "val_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        val_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "        val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "avg_val_loss = val_loss / len(val_labels)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "val_prec = precision_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "val_rec = recall_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "val_f1 = f1_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "\n",
        "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Validation Precision: {val_prec:.4f}\")\n",
        "print(f\"Validation Recall: {val_rec:.4f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4667389",
      "metadata": {
        "id": "e4667389"
      },
      "source": [
        "# Sign + EEG anomaly detection - Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abcc9f79",
      "metadata": {
        "id": "abcc9f79"
      },
      "outputs": [],
      "source": [
        "class AnomalyDataset(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        sign_attention_masks = input_data['sign_attention_masks']\n",
        "        eeg_attention_masks = input_data['eeg_attention_masks']\n",
        "        # sign_cls_tokens = input_data['sign_cls_tokens']\n",
        "        # eeg_cls_tokens = input_data['eeg_cls_tokens']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "        # self.sign_cls_token = sign_cls_tokens\n",
        "        self.sign_attention_mask = sign_attention_masks\n",
        "        self.sign_seq_len = sign_data[0].shape[0]\n",
        "        self.sign_ts_dim = sign_data[0].shape[1]\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "        # self.eeg_cls_token = eeg_cls_tokens\n",
        "        self.eeg_attention_mask = eeg_attention_masks\n",
        "        self.eeg_seq_len = eeg_data[0].shape[0]\n",
        "        self.eeg_ts_dim = eeg_data[0].shape[1]\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            # 'sign_cls_token': self.sign_cls_token[idx],\n",
        "            'sign_attention_mask': self.sign_attention_mask[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            # 'eeg_cls_token': self.eeg_cls_token[idx],\n",
        "            'eeg_attention_mask': self.eeg_attention_mask[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5a3179",
      "metadata": {
        "id": "6e5a3179"
      },
      "outputs": [],
      "source": [
        "\n",
        "files_mat_genuine_train, user_ids_genuine_train, train_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.TRAIN)\n",
        "files_mat_test, user_ids_test, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST)\n",
        "\n",
        "raw_data_train = get_sig_eeg_raw_data(files_mat_genuine_train, train_labels)\n",
        "raw_data_test = get_sig_eeg_raw_data(files_mat_test, test_labels)\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = int(max_seq_len_for_data // 2)\n",
        "\n",
        "for i in range(len(raw_data_train)):\n",
        "    sign_feat, _ = get_sign_data_features(raw_data_train[i]['sign_data'])\n",
        "    eeg_data, _, _ = get_eeg_data_features(raw_data_train[i]['eeg_data'])\n",
        "    sign_feat, sign_mask = attach_attention_tokens_and_padding(sign_feat, sign_max_seq_len)\n",
        "    eeg_data, eeg_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_data_train[i]['sign_data'] = sign_feat\n",
        "    raw_data_train[i]['eeg_data'] = eeg_data\n",
        "    raw_data_train[i]['sign_attention_mask'] = sign_mask\n",
        "    raw_data_train[i]['eeg_attention_mask'] = eeg_mask\n",
        "\n",
        "for i in range(len(raw_data_test)):\n",
        "    sign_feat, _ = get_sign_data_features(raw_data_test[i]['sign_data'])\n",
        "    eeg_data, _, _ = get_eeg_data_features(raw_data_test[i]['eeg_data'])\n",
        "    sign_feat, sign_mask = attach_attention_tokens_and_padding(sign_feat, sign_max_seq_len)\n",
        "    eeg_data, eeg_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_data_test[i]['sign_data'] = sign_feat\n",
        "    raw_data_test[i]['eeg_data'] = eeg_data\n",
        "    raw_data_test[i]['sign_attention_mask'] = sign_mask\n",
        "    raw_data_test[i]['eeg_attention_mask'] = eeg_mask\n",
        "\n",
        "sign_data_train = [d['sign_data'] for d in raw_data_train]\n",
        "eeg_data_train = [d['eeg_data'] for d in raw_data_train]\n",
        "sign_attention_masks_train = [d['sign_attention_mask'][1:] for d in raw_data_train]\n",
        "eeg_attention_masks_train = [d['eeg_attention_mask'][1:] for d in raw_data_train]\n",
        "labels_train = [d['label'] for d in raw_data_train]\n",
        "\n",
        "sign_data_test = [d['sign_data'] for d in raw_data_test]\n",
        "eeg_data_test = [d['eeg_data'] for d in raw_data_test]\n",
        "sign_attention_masks_test = [d['sign_attention_mask'][1:] for d in raw_data_test]\n",
        "eeg_attention_masks_test = [d['eeg_attention_mask'][1:] for d in raw_data_test]\n",
        "labels_test = [d['label'] for d in raw_data_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bf5795",
      "metadata": {
        "id": "c7bf5795"
      },
      "outputs": [],
      "source": [
        "input_data_train = {\n",
        "    'sign_data': sign_data_train,\n",
        "    'eeg_data': eeg_data_train,\n",
        "    'sign_attention_masks': sign_attention_masks_train,\n",
        "    'eeg_attention_masks': eeg_attention_masks_train,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "input_data_test = {\n",
        "    'sign_data': sign_data_test,\n",
        "    'eeg_data': eeg_data_test,\n",
        "    'sign_attention_masks': sign_attention_masks_test,\n",
        "    'eeg_attention_masks': eeg_attention_masks_test,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "anomaly_train_dataset = AnomalyDataset(input_data_train, num_classes=1)\n",
        "anomaly_test_dataset = AnomalyDataset(input_data_test, num_classes=1)\n",
        "anomaly_train_loader = DataLoader(anomaly_train_dataset, batch_size=16, shuffle=True)\n",
        "anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "sign_ts_dim_train = input_data_train['sign_data'][0].size(1)\n",
        "# sign_attention_masks_train = input_data_train['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_train = input_data_train['sign_data'][0].size(0)\n",
        "eeg_ts_dim_train = input_data_train['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_train = input_data_train['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_train = input_data_train['eeg_data'][0].size(0)\n",
        "\n",
        "sign_ts_dim_test = input_data_test['sign_data'][0].size(1)\n",
        "# sign_attention_masks_test = input_data_test['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_test = input_data_test['sign_data'][0].size(0)\n",
        "eeg_ts_dim_test = input_data_test['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_test = input_data_test['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_test = input_data_test['eeg_data'][0].size(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c660ee51",
      "metadata": {
        "id": "c660ee51"
      },
      "outputs": [],
      "source": [
        "# print(\"Sign data type: \", eeg_data_train[0])\n",
        "# print(\"EEG data type: \", type(eeg_data))\n",
        "# print(\"Sign attention mask type: \", type(sign_attention_masks[0]))\n",
        "# print(\"EEG attention mask type: \", type(eeg_attention_masks[0]))\n",
        "# print(\"Sign cls token type: \", type(sign_cls_tokens[0]))\n",
        "# print(\"EEG cls token type: \", type(eeg_cls_tokens[0]))\n",
        "# print(\"Labels type: \", type(labels))\n",
        "# print(\"Files type: \", type(files))\n",
        "\n",
        "\n",
        "print(\"Sign data shape: \", sign_data_train[0].shape)\n",
        "print(\"EEG data shape: \", eeg_data_train[0].shape)\n",
        "print(\"Sign attention mask shape: \", sign_attention_masks_train[0].shape)\n",
        "print(\"EEG attention mask shape: \", eeg_attention_masks_train[0].shape)\n",
        "# print(\"Sign cls token shape: \", sign_cls_tokens_train[0].shape)\n",
        "# print(\"EEG cls token shape: \", eeg_cls_tokens_train[0].shape)\n",
        "print(\"Labels shape: \", len(labels_train))\n",
        "print(\"Labels unique elements: \", set(labels_train))\n",
        "# print(\"Files shape: \", len(files_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9220ac",
      "metadata": {
        "id": "ae9220ac"
      },
      "outputs": [],
      "source": [
        "# print(torch.isnan(sign_x_ts).any(), torch.isinf(sign_x_ts).any())\n",
        "# print(torch.isnan(eeg_x_ts).any(), torch.isinf(eeg_x_ts).any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6136abc",
      "metadata": {
        "id": "b6136abc"
      },
      "outputs": [],
      "source": [
        "class SignEEGTransformerAutoEncoder(nn.Module):\n",
        "    def __init__(self, sign_input_dim, sign_seq_len, eeg_input_dim, eeg_seq_len, d_model=128, num_heads=4, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.sign_input_proj = nn.Linear(sign_input_dim, d_model)\n",
        "        self.sign_pos_enc = PositionalEncoding(d_model, sign_seq_len)\n",
        "        sign_encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.sign_encoder = nn.TransformerEncoder(sign_encoder_layer, num_layers=num_layers)\n",
        "        sign_decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.sign_decoder = nn.TransformerDecoder(sign_decoder_layer, num_layers=num_layers)\n",
        "        self.sign_output_proj = nn.Linear(d_model, sign_input_dim)\n",
        "\n",
        "        self.eeg_input_proj = nn.Linear(eeg_input_dim, d_model)\n",
        "        self.eeg_pos_enc = PositionalEncoding(d_model, eeg_seq_len)\n",
        "        eeg_encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.eeg_encoder = nn.TransformerEncoder(eeg_encoder_layer, num_layers=num_layers)\n",
        "        eeg_decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.eeg_decoder = nn.TransformerDecoder(eeg_decoder_layer, num_layers=num_layers)\n",
        "        self.eeg_output_proj = nn.Linear(d_model, eeg_input_dim)\n",
        "\n",
        "    def forward(self, sign_x, eeg_x, sign_attn_mask=None, eeg_attn_mask=None):\n",
        "        sign_x_proj = self.sign_input_proj(sign_x) + self.sign_pos_enc(sign_x)\n",
        "        sign_memory = self.sign_encoder(sign_x_proj, src_key_padding_mask=sign_attn_mask)\n",
        "        sign_decoded = self.sign_decoder(sign_x_proj, sign_memory, tgt_key_padding_mask=sign_attn_mask, memory_key_padding_mask=sign_attn_mask)\n",
        "        sign_recon = self.sign_output_proj(sign_decoded)\n",
        "        eeg_x_proj = self.eeg_input_proj(eeg_x) + self.eeg_pos_enc(eeg_x)\n",
        "        eeg_memory = self.eeg_encoder(eeg_x_proj, src_key_padding_mask=eeg_attn_mask)\n",
        "        eeg_decoded = self.eeg_decoder(eeg_x_proj, eeg_memory, tgt_key_padding_mask=eeg_attn_mask, memory_key_padding_mask=eeg_attn_mask)\n",
        "        eeg_recon = self.eeg_output_proj(eeg_decoded)\n",
        "\n",
        "        return sign_recon, eeg_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33023d89",
      "metadata": {
        "id": "33023d89"
      },
      "outputs": [],
      "source": [
        "def train_validate_autoencoder(model, train_loader, val_loader, device, num_epochs=20, lr=1e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "            sign_x = batch['sign_x_ts'].to(device)\n",
        "            sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "            if sign_mask.dim() == 3:\n",
        "                sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "            eeg_x = batch['eeg_x_ts'].to(device)\n",
        "            eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "            if eeg_mask.dim() == 3:\n",
        "                eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            sign_recon, eeg_recon = model(sign_x, eeg_x, sign_mask, eeg_mask)\n",
        "            loss_sign = loss_fn(sign_recon, sign_x)\n",
        "            loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "            loss = loss_sign + loss_eeg\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "                sign_x = batch['sign_x_ts'].to(device)\n",
        "                sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "                if sign_mask.dim() == 3:\n",
        "                    sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "                eeg_x = batch['eeg_x_ts'].to(device)\n",
        "                eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "                if eeg_mask.dim() == 3:\n",
        "                    eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "                sign_recon, eeg_recon = model(sign_x, eeg_x, sign_mask, eeg_mask)\n",
        "                loss_sign = loss_fn(sign_recon, sign_x)\n",
        "                loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "                loss = loss_sign + loss_eeg\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b868eebe",
      "metadata": {
        "id": "b868eebe"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "anomaly_model = SignEEGTransformerAutoEncoder(sign_input_dim=sign_ts_dim_train, sign_seq_len=sign_seq_len_train, eeg_input_dim=eeg_ts_dim_train, eeg_seq_len=eeg_seq_len_train, d_model=128, num_heads=4, num_layers=2).to(device)\n",
        "\n",
        "model = train_validate_autoencoder(anomaly_model, anomaly_train_loader, anomaly_test_loader, device, num_epochs=10, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05abbc8a",
      "metadata": {
        "id": "05abbc8a"
      },
      "outputs": [],
      "source": [
        "# model = SignEEGTransformerAutoEncoder(\n",
        "#     sign_input_dim=sign_ts_dim_test,\n",
        "#     sign_seq_len=sign_seq_len_test,\n",
        "#     eeg_input_dim=eeg_ts_dim_test,\n",
        "#     eeg_seq_len=eeg_seq_len_test,\n",
        "#     d_model=128,\n",
        "#     num_heads=4,\n",
        "#     num_layers=2\n",
        "# )\n",
        "# model.load_state_dict(torch.load(\"D:\\\\KCL Final Year Individual Project\\\\Implementation\\\\Project Implementation\\models\\\\anomaly_model_07212025-153342.pth\", map_location='cpu'))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "all_scores = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in anomaly_test_loader:\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = torch.tensor(batch['labels'], dtype=torch.float32).to(device)\n",
        "        sign_recon, eeg_recon = model(sign_x_ts, eeg_x_ts, sign_attention_mask, eeg_attention_mask)\n",
        "        sign_error = ((sign_recon - sign_x_ts) ** 2).max(dim=(1, 2)).cpu().numpy()\n",
        "        eeg_error = ((eeg_recon - eeg_x_ts) ** 2).max(dim=(1, 2)).cpu().numpy()\n",
        "        scores = sign_error + eeg_error\n",
        "        all_scores.extend(scores)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_scores_np = np.array(all_scores)\n",
        "all_labels_np = np.array(all_labels)\n",
        "fpr, tpr, thresholds = roc_curve(all_labels_np, all_scores_np)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "threshold = thresholds[optimal_idx]\n",
        "# print(\"Optimal threshold:\", optimal_threshold)\n",
        "preds = (np.array(all_scores) > threshold).astype(int)\n",
        "roc = roc_auc_score(all_labels, all_scores)\n",
        "acc = accuracy_score(all_labels, preds)\n",
        "prec = precision_score(all_labels, preds, zero_division=0)\n",
        "rec = recall_score(all_labels, preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, preds, zero_division=0)\n",
        "\n",
        "print(f\"ROC AUC: {roc:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels=[0,1]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))\n",
        "\n",
        "plt.hist(np.array(all_scores)[np.array(all_labels)==0], bins=50, alpha=0.5, label='Genuine')\n",
        "plt.hist(np.array(all_scores)[np.array(all_labels)==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "plt.legend()\n",
        "plt.title(\"Anomaly Scores Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca15cb9",
      "metadata": {
        "id": "5ca15cb9"
      },
      "source": [
        "## Sign + EEG Anomaly - CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f6e336",
      "metadata": {
        "id": "a4f6e336"
      },
      "outputs": [],
      "source": [
        "class AnomalyCNNDataset(Dataset):\n",
        "    def __init__(self, input_data):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "        # # self.sign_cls_token = sign_cls_tokens\n",
        "        # self.sign_attention_mask = sign_attention_masks\n",
        "        self.sign_seq_len = sign_data[0].shape[0]\n",
        "        self.sign_ts_dim = sign_data[0].shape[1]\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "        # # self.eeg_cls_token = eeg_cls_tokens\n",
        "        # self.eeg_attention_mask = eeg_attention_masks\n",
        "        self.eeg_seq_len = eeg_data[0].shape[0]\n",
        "        self.eeg_ts_dim = eeg_data[0].shape[1]\n",
        "\n",
        "        # self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            # # 'sign_cls_token': self.sign_cls_token[idx],\n",
        "            # 'sign_attention_mask': self.sign_attention_mask[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            # # 'eeg_cls_token': self.eeg_cls_token[idx],\n",
        "            # 'eeg_attention_mask': self.eeg_attention_mask[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf77fc3",
      "metadata": {
        "id": "8cf77fc3"
      },
      "outputs": [],
      "source": [
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, latent_dim, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        z = self.encoder(x)\n",
        "        return z.squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625de453",
      "metadata": {
        "id": "625de453"
      },
      "outputs": [],
      "source": [
        "class CNNDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 32 * (seq_len // 4)),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (32, seq_len // 4)),\n",
        "            nn.ConvTranspose1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(64, output_dim, kernel_size=4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.decoder(z)\n",
        "        return x.permute(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c33ddd",
      "metadata": {
        "id": "48c33ddd"
      },
      "outputs": [],
      "source": [
        "class SignEEGCNNAutoencoder(nn.Module):\n",
        "    def __init__(self, sign_input_dim, eeg_input_dim, sign_seq_len, eeg_seq_len, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.sign_encoder = CNNEncoder(sign_input_dim, latent_dim)\n",
        "        self.eeg_encoder = CNNEncoder(eeg_input_dim, latent_dim)\n",
        "        self.sign_decoder = CNNDecoder(latent_dim, sign_input_dim, sign_seq_len)\n",
        "        self.eeg_decoder = CNNDecoder(latent_dim, eeg_input_dim, eeg_seq_len)\n",
        "\n",
        "    def forward(self, sign_x, eeg_x):\n",
        "        sign_z = self.sign_encoder(sign_x)\n",
        "        eeg_z = self.eeg_encoder(eeg_x)\n",
        "        sign_recon = self.sign_decoder(sign_z)\n",
        "        eeg_recon = self.eeg_decoder(eeg_z)\n",
        "        return sign_recon, eeg_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d50f8f",
      "metadata": {
        "id": "c8d50f8f"
      },
      "outputs": [],
      "source": [
        "def train_validate_autoencoder(model, train_loader, device, num_epochs=10, lr=1e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "            # print(\"Current batch sign seq len: \", batch['sign_x_ts'].shape[1])\n",
        "            # print(\"Current batch eeg seq len: \", batch['eeg_x_ts'].shape[1])\n",
        "            sign_x = batch['sign_x_ts'].to(device)\n",
        "            # sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "            # if sign_mask.dim() == 3:\n",
        "            #     sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "            eeg_x = batch['eeg_x_ts'].to(device)\n",
        "            # eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "            # if eeg_mask.dim() == 3:\n",
        "            #     eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            sign_recon, eeg_recon = model(sign_x, eeg_x)\n",
        "            loss_sign = loss_fn(sign_recon, sign_x)\n",
        "            loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "            loss = loss_sign + loss_eeg\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # model.eval()\n",
        "        # val_loss = 0\n",
        "        # with torch.no_grad():\n",
        "        #     for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "        #         sign_x = batch['sign_x_ts'].to(device)\n",
        "        #         # sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "        #         # if sign_mask.dim() == 3:\n",
        "        #         #     sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "        #         eeg_x = batch['eeg_x_ts'].to(device)\n",
        "        #         # eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "        #         # if eeg_mask.dim() == 3:\n",
        "        #         #     eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "        #         sign_recon, eeg_recon = model(sign_x, eeg_x)\n",
        "        #         loss_sign = loss_fn(sign_recon, sign_x)\n",
        "        #         loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "        #         loss = loss_sign + loss_eeg\n",
        "        #         val_loss += loss.item()\n",
        "        # avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        # print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65dfab3",
      "metadata": {
        "id": "c65dfab3"
      },
      "outputs": [],
      "source": [
        "files_mat_genuine_train, user_ids_genuine_train, train_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.TRAIN)\n",
        "files_mat_test, user_ids_test, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST)\n",
        "\n",
        "raw_data_train = get_sig_eeg_raw_data(files_mat_genuine_train, train_labels)\n",
        "raw_data_test = get_sig_eeg_raw_data(files_mat_test, test_labels)\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = int(max_seq_len_for_data // 2)\n",
        "\n",
        "for i in range(len(raw_data_train)):\n",
        "    sign_feat, sign_cls_token = get_sign_data_features(raw_data_train[i]['sign_data'])\n",
        "    eeg_data, eeg_features, eeg_cls_token = get_eeg_data_features(raw_data_train[i]['eeg_data'])\n",
        "    sign_cls_expanded = sign_cls_token.unsqueeze(0).expand(sign_feat.shape[0], -1)\n",
        "    sign_feat = torch.cat((sign_feat, sign_cls_expanded), dim=1)\n",
        "    eeg_cls_expanded = eeg_cls_token.unsqueeze(0).expand(eeg_data.shape[0], -1)\n",
        "    eeg_data = torch.cat([eeg_data, eeg_cls_expanded], dim=1)\n",
        "    raw_data_train[i]['sign_data'] = sign_feat\n",
        "    raw_data_train[i]['eeg_data'] = eeg_data\n",
        "\n",
        "for i in range(len(raw_data_test)):\n",
        "    sign_feat, sign_cls_token = get_sign_data_features(raw_data_test[i]['sign_data'])\n",
        "    eeg_data, eeg_features, eeg_cls_token = get_eeg_data_features(raw_data_test[i]['eeg_data'])\n",
        "    sign_cls_expanded = sign_cls_token.unsqueeze(0).expand(sign_feat.shape[0], -1)\n",
        "    sign_feat = torch.cat((sign_feat, sign_cls_expanded), dim=1)\n",
        "    eeg_cls_expanded = eeg_cls_token.unsqueeze(0).expand(eeg_data.shape[0], -1)\n",
        "    eeg_data = torch.cat([eeg_data, eeg_cls_expanded], dim=1)\n",
        "    raw_data_test[i]['sign_data'] = sign_feat\n",
        "    raw_data_test[i]['eeg_data'] = eeg_data\n",
        "\n",
        "sign_data_train = [d['sign_data'] for d in raw_data_train]\n",
        "eeg_data_train = [d['eeg_data'] for d in raw_data_train]\n",
        "labels_train = [d['label'] for d in raw_data_train]\n",
        "\n",
        "sign_data_test = [d['sign_data'] for d in raw_data_test]\n",
        "eeg_data_test = [d['eeg_data'] for d in raw_data_test]\n",
        "labels_test = [d['label'] for d in raw_data_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ca5ebe",
      "metadata": {
        "id": "d1ca5ebe"
      },
      "outputs": [],
      "source": [
        "def sign_eeg_collate_fn(batch):\n",
        "    # Use your global fixed lengths\n",
        "    fixed_sign_len = max_seq_len_for_data\n",
        "    fixed_eeg_len = int(max_seq_len_for_data // 2)\n",
        "    sign_x = [item['sign_x_ts'] for item in batch]\n",
        "    eeg_x = [item['eeg_x_ts'] for item in batch]\n",
        "    labels = [item['labels'] for item in batch]\n",
        "    # Pad each sample individually to fixed length\n",
        "    sign_x_padded = torch.stack([\n",
        "        torch.nn.functional.pad(x, (0, 0, 0, fixed_sign_len - x.shape[0]), mode='constant', value=0)\n",
        "        for x in sign_x\n",
        "    ])\n",
        "    eeg_x_padded = torch.stack([\n",
        "        torch.nn.functional.pad(x, (0, 0, 0, fixed_eeg_len - x.shape[0]), mode='constant', value=0)\n",
        "        for x in eeg_x\n",
        "    ])\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    return {\n",
        "        'sign_x_ts': sign_x_padded,\n",
        "        'eeg_x_ts': eeg_x_padded,\n",
        "        'labels': labels\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c01a494",
      "metadata": {
        "id": "9c01a494"
      },
      "outputs": [],
      "source": [
        "input_data_train = {\n",
        "    'sign_data': sign_data_train,\n",
        "    'eeg_data': eeg_data_train,\n",
        "    # 'sign_attention_masks': sign_attention_masks_train,\n",
        "    # 'eeg_attention_masks': eeg_attention_masks_train,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "input_data_test = {\n",
        "    'sign_data': sign_data_test,\n",
        "    'eeg_data': eeg_data_test,\n",
        "    # 'sign_attention_masks': sign_attention_masks_test,\n",
        "    # 'eeg_attention_masks': eeg_attention_masks_test,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "# anomaly_train_dataset = AnomalyCNNDataset(input_data_train)\n",
        "# anomaly_test_dataset = AnomalyCNNDataset(input_data_test)\n",
        "# anomaly_train_loader = DataLoader(anomaly_train_dataset, batch_size=16, shuffle=True, collate_fn=sign_collate_fn)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False, collate_fn=eeg_collate_fn)\n",
        "sign_ts_dim_train = input_data_train['sign_data'][0].size(1)\n",
        "# sign_attention_masks_train = input_data_train['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_train = input_data_train['sign_data'][0].size(0)\n",
        "eeg_ts_dim_train = input_data_train['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_train = input_data_train['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_train = input_data_train['eeg_data'][0].size(0)\n",
        "\n",
        "sign_ts_dim_test = input_data_test['sign_data'][0].size(1)\n",
        "# sign_attention_masks_test = input_data_test['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_test = input_data_test['sign_data'][0].size(0)\n",
        "eeg_ts_dim_test = input_data_test['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_test = input_data_test['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_test = input_data_test['eeg_data'][0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a1ac3c",
      "metadata": {
        "id": "a4a1ac3c"
      },
      "outputs": [],
      "source": [
        "sign_seq_len = sign_data_train[0].shape[0]\n",
        "sign_input_dim = sign_data_train[0].shape[1]\n",
        "eeg_seq_len = eeg_data_train[0].shape[0]\n",
        "eeg_input_dim = eeg_data_train[0].shape[1]\n",
        "latent_dim = 32\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_dataset = AnomalyCNNDataset(input_data_train)\n",
        "test_dataset = AnomalyCNNDataset(input_data_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=sign_eeg_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=sign_eeg_collate_fn)\n",
        "\n",
        "anomaly_cnn_model = SignEEGCNNAutoencoder(sign_input_dim, eeg_input_dim, max_seq_len_for_data, int(max_seq_len_for_data // 2), latent_dim).to(device)\n",
        "anomaly_model = train_validate_autoencoder(anomaly_cnn_model, train_loader, device=device, num_epochs=10, lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd0e7122",
      "metadata": {
        "id": "fd0e7122"
      },
      "outputs": [],
      "source": [
        "anomaly_model.eval()\n",
        "all_scores = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        sign_x = batch['sign_x_ts'].to(device)\n",
        "        eeg_x = batch['eeg_x_ts'].to(device)\n",
        "        labels = batch['labels'].cpu().numpy()\n",
        "        sign_recon, eeg_recon = anomaly_model(sign_x, eeg_x)\n",
        "        # using max squared error per sample as anomaly score\n",
        "        sign_error = torch.amax((sign_recon - sign_x) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        eeg_error = torch.amax((eeg_recon - eeg_x) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        scores = sign_error + eeg_error\n",
        "        all_scores.extend(scores)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "all_scores = np.array(all_scores)\n",
        "all_labels = np.array(all_labels)\n",
        "mask = ~np.isnan(all_scores) & ~np.isnan(all_labels) # mask out all NaN values to avoid error in roc_curve\n",
        "all_scores = all_scores[mask]\n",
        "all_labels = all_labels[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726ff6e8",
      "metadata": {
        "id": "726ff6e8"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
        "roc_auc = roc_auc_score(all_labels, all_scores)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "threshold = thresholds[optimal_idx]\n",
        "preds = (all_scores > threshold).astype(int)\n",
        "\n",
        "acc = accuracy_score(all_labels, preds)\n",
        "prec = precision_score(all_labels, preds, zero_division=0)\n",
        "rec = recall_score(all_labels, preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, preds, zero_division=0)\n",
        "\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels=[0,1]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(all_scores[all_labels==0], bins=50, alpha=0.5, label='Genuine')\n",
        "plt.hist(all_scores[all_labels==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
        "plt.legend()\n",
        "plt.title(\"Anomaly Scores Distribution\")\n",
        "plt.xlabel(\"Anomaly Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a6020a",
      "metadata": {
        "id": "96a6020a"
      },
      "source": [
        "## Anomaly Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219d1d03",
      "metadata": {
        "id": "219d1d03"
      },
      "outputs": [],
      "source": [
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# num_epochs = 10\n",
        "\n",
        "# anomaly_model = SignatureEEGTransformer(\n",
        "#     sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "#     eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "#     d_model=128, num_classes=1, num_heads=4, num_layers=4,\n",
        "#     sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        "# ).to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(anomaly_model.parameters(), lr=1e-5)\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # only one class, so only one logit output per sample\n",
        "\n",
        "# anomaly_test_dataset = SignatureEEGDataset(test_input_data, num_classes=1)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     anomaly_model.train()\n",
        "#     total_loss = 0\n",
        "#     for batch in tqdm(anomaly_train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "#         sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#         sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#         sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#         eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#         eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#         eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#         labels = torch.zeros(sign_x_ts.size(0), dtype=torch.float32).to(device)  # All genuine = 0\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         logits = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#         loss = loss_fn(logits.squeeze(1), labels)\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(anomaly_model.parameters(), max_norm=1.0)\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item() * labels.size(0)\n",
        "#     avg_loss = total_loss / len(anomaly_train_dataloader.dataset)\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "#     threshold = 0.5\n",
        "#     # Validation/Test at every epoch\n",
        "#     anomaly_model.eval()\n",
        "#     all_scores = []\n",
        "#     all_labels = []\n",
        "#     with torch.no_grad():\n",
        "#         for batch in anomaly_test_loader:\n",
        "#             sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#             sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#             sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#             eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#             eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#             eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#             labels = torch.tensor(batch['labels'], dtype=torch.float32).to(device)\n",
        "#             scores = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#             all_scores.extend(scores.cpu().numpy())\n",
        "#             all_labels.extend(labels.cpu().numpy())\n",
        "#     preds = (np.array(all_scores) > threshold).astype(int)\n",
        "#     roc = roc_auc_score(all_labels, all_scores)\n",
        "#     print(f\"Validation ROC AUC: {roc:.4f}\")\n",
        "#     print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels=[0,1]))\n",
        "#     print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))\n",
        "#     plt.hist(np.array(all_scores)[np.array(all_labels)==0], bins=50, alpha=0.5, label='Genuine')\n",
        "#     plt.hist(np.array(all_scores)[np.array(all_labels)==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155207fc",
      "metadata": {
        "id": "155207fc"
      },
      "outputs": [],
      "source": [
        "# # training loop for anomaly detection\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# num_epochs = 5\n",
        "\n",
        "# anomaly_model = SignatureEEGTransformer(\n",
        "#     sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "#     eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "#     d_model=128, num_classes=1, num_heads=4, num_layers=2,\n",
        "#     sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        "# ).to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(anomaly_model.parameters(), lr=1e-5)\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # only one class, so only one logit output per sample\n",
        "\n",
        "# anomaly_model.train()\n",
        "# for epoch in range(num_epochs):\n",
        "#     total_loss = 0\n",
        "#     for batch in tqdm(anomaly_train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "#         sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#         sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#         sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#         eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#         eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#         eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#         labels = torch.zeros(sign_x_ts.size(0), dtype=torch.float32).to(device)  # All genuine = 0\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         logits = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#         loss = loss_fn(logits.squeeze(1), labels) # logits size turned out to be [8,1] so we need to squeeze it to [8]\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(anomaly_model.parameters(), max_norm=1.0)\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item() * labels.size(0)\n",
        "#     avg_loss = total_loss / len(anomaly_train_dataloader.dataset)\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fbc0586",
      "metadata": {
        "id": "1fbc0586"
      },
      "outputs": [],
      "source": [
        "torch.save(anomaly_model.state_dict(), os.path.join(os.getenv(\"MODEL_PATH\"), f\"anomaly_detection_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9159ba2b",
      "metadata": {
        "id": "9159ba2b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # testing loop for anomaly detection\n",
        "# files_mat_test, user_ids_test, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST)\n",
        "# raw_test_data = get_sig_eeg_raw_data(files_mat_test, test_labels)\n",
        "\n",
        "# # Augment and preprocess test data (no augmentation, just features and padding)\n",
        "# for i in range(len(raw_test_data)):\n",
        "#     _, sign_cls_token = get_sign_data_features(raw_test_data[i]['sign_data'])\n",
        "#     _, eeg_cls_token = get_eeg_data_features(raw_test_data[i]['eeg_data'])\n",
        "#     # raw_test_data[i]['sign_data'] = sign_data_with_features\n",
        "#     raw_test_data[i]['sign_cls_token'] = sign_cls_token\n",
        "#     # raw_test_data[i]['eeg_data'] = eeg_data_with_features\n",
        "#     raw_test_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "\n",
        "# sign_max_seq_len_test = int(max_seq_len_for_data//2)\n",
        "# eeg_max_seq_len_test = int(max_seq_len_for_data // 4)\n",
        "\n",
        "# for i in range(len(raw_test_data)):\n",
        "#     sign_data = raw_test_data[i]['sign_data']\n",
        "#     eeg_data = raw_test_data[i]['eeg_data']\n",
        "#     sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len_test)\n",
        "#     eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len_test)\n",
        "#     raw_test_data[i]['sign_data'] = sign_data\n",
        "#     raw_test_data[i]['eeg_data'] = eeg_data\n",
        "#     raw_test_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "#     raw_test_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "# test_input_data = {\n",
        "#     'sign_data': [data['sign_data'] for data in raw_test_data],\n",
        "#     'eeg_data': [data['eeg_data'] for data in raw_test_data],\n",
        "#     'sign_attention_masks': [data['sign_attention_mask'] for data in raw_test_data],\n",
        "#     'eeg_attention_masks': [data['eeg_attention_mask'] for data in raw_test_data],\n",
        "#     'sign_cls_tokens': [data['sign_cls_token'] for data in raw_test_data],\n",
        "#     'eeg_cls_tokens': [data['eeg_cls_token'] for data in raw_test_data],\n",
        "#     'labels': [data['label'] for data in raw_test_data],\n",
        "# }\n",
        "\n",
        "# sign_ts_dim = test_input_data['sign_data'][0].size(1)\n",
        "# sign_cls_dim = test_input_data['sign_cls_tokens'][0].size(0)\n",
        "# sign_seq_len = test_input_data['sign_data'][0].size(0)\n",
        "# eeg_ts_dim = test_input_data['eeg_data'][0].size(1)\n",
        "# eeg_cls_dim = test_input_data['eeg_cls_tokens'][0].size(0)\n",
        "# eeg_seq_len = test_input_data['eeg_data'][0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a12e5f6c",
      "metadata": {
        "id": "a12e5f6c"
      },
      "outputs": [],
      "source": [
        "# anomaly_test_dataset = SignatureEEGDataset(test_input_data, num_classes=1)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc68ae78",
      "metadata": {
        "id": "bc68ae78"
      },
      "outputs": [],
      "source": [
        "# threshold = 0.5\n",
        "# anomaly_test_dataset = SignatureEEGDataset(test_input_data, num_classes=1)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# anomaly_model.eval()\n",
        "# all_scores = []\n",
        "# all_labels = []\n",
        "# with torch.no_grad():\n",
        "#     for batch in tqdm(anomaly_test_loader, desc=\"Testing\", leave=False):\n",
        "#         sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#         sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#         sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#         eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#         eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#         eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#         labels = torch.tensor(batch['labels'], dtype=torch.float32).to(device)\n",
        "#         scores = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#         all_scores.extend(scores.cpu().numpy())\n",
        "#         all_labels.extend(labels.cpu().numpy())\n",
        "# preds = (np.array(all_scores) > threshold).astype(int)\n",
        "# print(\"ROC AUC:\", roc_auc_score(all_labels, all_scores))\n",
        "# print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels = [0,1]))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53437dc",
      "metadata": {
        "id": "c53437dc"
      },
      "outputs": [],
      "source": [
        "# pp.pprint(list(zip(all_scores, all_labels, preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11217528",
      "metadata": {
        "id": "11217528"
      },
      "outputs": [],
      "source": [
        "# plt.hist(np.array(all_scores)[np.array(all_labels)==0], bins=50, alpha=0.5, label='Genuine')\n",
        "# plt.hist(np.array(all_scores)[np.array(all_labels)==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ccedc4",
      "metadata": {
        "id": "d7ccedc4"
      },
      "source": [
        "# Sign + EEG in CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d8f0ea",
      "metadata": {
        "id": "72d8f0ea"
      },
      "outputs": [],
      "source": [
        "class SignatureEEGDatasetForCNN(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1980decf",
      "metadata": {
        "id": "1980decf"
      },
      "outputs": [],
      "source": [
        "# def prepare_sign_eeg_for_cnn(input_data):\n",
        "#     sign_data = input_data['sign_data']\n",
        "#     eeg_data = input_data['eeg_data']\n",
        "#     sign_cls_tokens = input_data['sign_cls_tokens']\n",
        "#     eeg_cls_tokens = input_data['eeg_cls_tokens']\n",
        "#     labels = input_data['labels']\n",
        "\n",
        "#     sign_cnn_data = []\n",
        "#     eeg_cnn_data = []\n",
        "\n",
        "#     for s, s_cls, e, e_cls in zip(sign_data, sign_cls_tokens, eeg_data, eeg_cls_tokens):\n",
        "#         # Expand cls token to match sequence length\n",
        "#         s_cls_expanded = s_cls.unsqueeze(0).expand(s.shape[0], -1)\n",
        "#         e_cls_expanded = e_cls.unsqueeze(0).expand(e.shape[0], -1)\n",
        "#         # Concatenate along feature dimension\n",
        "#         sign_cnn_data.append(torch.cat([s, s_cls_expanded], dim=1))\n",
        "#         eeg_cnn_data.append(torch.cat([e, e_cls_expanded], dim=1))\n",
        "\n",
        "#     sign_cnn_data = torch.stack(sign_cnn_data)  # (num_samples, seq_len, sign_ts_dim + sign_cls_dim)\n",
        "#     eeg_cnn_data = torch.stack(eeg_cnn_data)    # (num_samples, seq_len, eeg_ts_dim + eeg_cls_dim)\n",
        "#     labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "#     return sign_cnn_data, eeg_cnn_data, labels\n",
        "\n",
        "# sign_cnn_data, eeg_cnn_data, cnn_labels = prepare_sign_eeg_for_cnn(input_data)\n",
        "# print(\"Sign CNN data shape:\", sign_cnn_data.shape)\n",
        "# print(\"EEG CNN data shape:\", eeg_cnn_data.shape)\n",
        "# print(\"Labels shape:\", cnn_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70236896",
      "metadata": {
        "id": "70236896"
      },
      "outputs": [],
      "source": [
        "class SignEEGCNN(nn.Module):\n",
        "    def __init__(self, sign_input_dim, eeg_input_dim, num_classes):\n",
        "        super(SignEEGCNN, self).__init__()\n",
        "        self.sign_conv = nn.Sequential(\n",
        "            nn.Conv1d(sign_input_dim, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2)\n",
        "        )\n",
        "        self.eeg_conv = nn.Sequential(\n",
        "            nn.Conv1d(eeg_input_dim, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2)\n",
        "        )\n",
        "        self.sign_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.eeg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(64 * 2, num_classes)\n",
        "\n",
        "    def forward(self, sign_x_ts, eeg_x_ts):\n",
        "        sign_x_ts = sign_x_ts.permute(0, 2, 1)\n",
        "        eeg_x_ts = eeg_x_ts.permute(0, 2, 1)\n",
        "\n",
        "        sign_features = self.sign_conv(sign_x_ts)\n",
        "        eeg_features = self.eeg_conv(eeg_x_ts)\n",
        "\n",
        "        sign_features = self.sign_pool(sign_features).squeeze(-1)\n",
        "        eeg_features = self.eeg_pool(eeg_features).squeeze(-1)\n",
        "        combined_features = torch.cat([sign_features, eeg_features], dim=1)\n",
        "\n",
        "        logits = self.fc(combined_features)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c8a043",
      "metadata": {
        "id": "86c8a043"
      },
      "outputs": [],
      "source": [
        "# training loop for CNN\n",
        "sign_cnn_data = sign_data\n",
        "eeg_cnn_data = eeg_data\n",
        "cnn_labels = torch.tensor(labels, dtype=torch.long)\n",
        "sign_cnn_data = torch.stack([x if isinstance(x, torch.Tensor) else torch.tensor(x) for x in sign_data])\n",
        "eeg_cnn_data = torch.stack([x if isinstance(x, torch.Tensor) else torch.tensor(x) for x in eeg_data])\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cnn_model = SignEEGCNN(sign_input_dim=sign_cnn_data.shape[2], eeg_input_dim=eeg_cnn_data.shape[2], num_classes=2).to(device)\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "sign_train, sign_test, eeg_train, eeg_test, labels_train, labels_test = train_test_split(\n",
        "    sign_cnn_data, eeg_cnn_data, cnn_labels, test_size=0.2, random_state=42, stratify=cnn_labels\n",
        ")\n",
        "\n",
        "train_dataset = SignatureEEGDatasetForCNN({\n",
        "    'sign_data': sign_train,\n",
        "    'eeg_data': eeg_train,\n",
        "    'labels': labels_train\n",
        "}, num_classes=2)\n",
        "test_dataset = SignatureEEGDatasetForCNN({\n",
        "    'sign_data': sign_test,\n",
        "    'eeg_data': eeg_test,\n",
        "    'labels': labels_test\n",
        "}, num_classes=2)\n",
        "\n",
        "cnn_dataset = SignatureEEGDatasetForCNN({\n",
        "    'sign_data': sign_cnn_data,\n",
        "    'eeg_data': eeg_cnn_data,\n",
        "    'labels': cnn_labels\n",
        "}, num_classes=2)\n",
        "cnn_dataloader = DataLoader(cnn_dataset, batch_size=8, shuffle=True)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    cnn_model.train()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    pbar = tqdm(enumerate(cnn_dataloader), total=len(cnn_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for batch_idx, batch in pbar:\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = cnn_model(sign_x_ts, eeg_x_ts)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(cnn_model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        pbar.set_postfix({\"Batch Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_loss = total_loss / len(all_labels) if all_labels else 0\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
        "    print(f\"{'Loss':<10}{'Accuracy':<12}{'Precision':<12}{'Recall':<10}{'F1-Score':<10}\")\n",
        "    print(f\"{avg_loss:<10.4f}{acc:<12.4f}{prec:<12.4f}{rec:<10.4f}{f1:<10.4f}\")\n",
        "    print(\"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c68df6",
      "metadata": {
        "id": "01c68df6"
      },
      "source": [
        "## EEG - Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008dad0f",
      "metadata": {
        "id": "008dad0f"
      },
      "outputs": [],
      "source": [
        "# # For debugging\n",
        "# def get_max_attention_token_len(attention_tokens):\n",
        "#     max_len = 0\n",
        "#     for item in attention_tokens:\n",
        "#         max_len = max(max_len, item.shape[0])\n",
        "#     return max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df4193d",
      "metadata": {
        "id": "3df4193d"
      },
      "outputs": [],
      "source": [
        "# print(get_max_attention_token_len(eeg_final_dataset['attention_masks']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e8fd1a",
      "metadata": {
        "id": "40e8fd1a"
      },
      "outputs": [],
      "source": [
        "# # print(normalized_sign_data_dict['000000000200894'][0])\n",
        "# # print(normalized_eeg_data_dict['000000000200894'][0])\n",
        "# # print(user_labels['000000000200894'][0])\n",
        "# eeg_data = get_eeg_data_features(eeg_data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e8e176",
      "metadata": {
        "id": "d9e8e176"
      },
      "outputs": [],
      "source": [
        "# sign_data_dict, eeg_data_dict, labels = get_sig_eeg_data_dicts(files_mat_appended, labels_appended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e11f5ec",
      "metadata": {
        "id": "7e11f5ec"
      },
      "outputs": [],
      "source": [
        "# # Single data\n",
        "# user_id = '002108410100048'\n",
        "# single_eeg_data = {}\n",
        "# single_eeg_data[user_id] = eeg_data_dict[user_id]\n",
        "\n",
        "# normalized_eeg_data_dict = normalize_eeg_data_dict(single_eeg_data)\n",
        "# eeg_data_with_features = get_eeg_data_features(normalized_eeg_data_dict)\n",
        "# eeg_final_data = eeg_attach_attention_tokens_and_labels(eeg_data_with_features, labels)\n",
        "# eeg_final_dataset = prepare_eeg_dataset_with_all_parts(eeg_final_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c911b8",
      "metadata": {
        "id": "89c911b8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4657fae",
      "metadata": {
        "id": "b4657fae"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(eeg_data_with_features['002108410100048']['data'][2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec789b9",
      "metadata": {
        "id": "bec789b9"
      },
      "outputs": [],
      "source": [
        "# max_len = get_eeg_max_seq_len(eeg_data_with_features)\n",
        "# print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab796cee",
      "metadata": {
        "id": "ab796cee"
      },
      "outputs": [],
      "source": [
        "# print(eeg_final_data['002108410100048']['labels'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1eaf4e",
      "metadata": {
        "id": "2d1eaf4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(eeg_final_dataset['labels'].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff475923",
      "metadata": {
        "id": "ff475923"
      },
      "source": [
        "# Misc - Trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e9aa8c",
      "metadata": {
        "id": "c0e9aa8c"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# x1 = torch.tensor([[1.0, 2.0],\n",
        "#                    [3.0, 1.0],\n",
        "#                    [0.0, 0.0]])\n",
        "\n",
        "# x2 = torch.tensor([[2.0, 1.0],\n",
        "#                    [0.0, 3.0],\n",
        "#                    [1.0, 1.0]])\n",
        "# distances = F.pairwise_distance(x1, x2)\n",
        "\n",
        "# print(\"Pairwise distances:\", distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c042f2",
      "metadata": {
        "id": "62c042f2"
      },
      "outputs": [],
      "source": [
        "# According to the paper: The instances corresponding to the last EEG activity for each subject were interpolated to match the length of the longest genuine instance for that subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d85c8021",
      "metadata": {
        "id": "d85c8021"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import numpy as np\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "\n",
        "# class SignatureEEGDataset(Dataset):\n",
        "#     def __init__(self, signature_data, eeg_data, labels):\n",
        "\n",
        "#         self.samples = []\n",
        "\n",
        "#         # Combine the data\n",
        "#         for user_id in signature_data:\n",
        "#             # Ensure we have matching signature, EEG, and label entries\n",
        "#             n_samples = len(signature_data[user_id])\n",
        "#             for i in range(n_samples):\n",
        "#                 signature = signature_data[user_id][i]\n",
        "#                 eeg = eeg_data[user_id][i]\n",
        "#                 label = labels[user_id][i]\n",
        "\n",
        "#                 # Convert to tensors\n",
        "#                 signature_tensor = torch.FloatTensor(signature)\n",
        "#                 eeg_tensor = torch.FloatTensor(eeg)\n",
        "#                 label_tensor = torch.LongTensor([label])\n",
        "\n",
        "#                 self.samples.append((signature_tensor, eeg_tensor, label_tensor))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.samples)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.samples[idx]\n",
        "\n",
        "# def collate_fn(batch):\n",
        "\n",
        "#     signatures, eegs, labels = zip(*batch)\n",
        "\n",
        "#     # Pad sequences to the same length\n",
        "#     signatures_padded = torch.nn.utils.rnn.pad_sequence(signatures, batch_first=True)\n",
        "#     eegs_padded = torch.nn.utils.rnn.pad_sequence(eegs, batch_first=True)\n",
        "\n",
        "#     labels = torch.cat(labels)\n",
        "\n",
        "#     return signatures_padded, eegs_padded, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae257955",
      "metadata": {
        "id": "ae257955"
      },
      "outputs": [],
      "source": [
        "# class SignatureEEGTransformer(nn.Module):\n",
        "#     def __init__(self, signature_dim=7, eeg_channels=10, d_model=128, nhead=4, num_layers=3, num_classes=2):\n",
        "#         super(SignatureEEGTransformer, self).__init__()\n",
        "\n",
        "#         # Signature embedding\n",
        "#         self.signature_embedding = nn.Linear(signature_dim, d_model)\n",
        "\n",
        "#         # EEG embedding\n",
        "#         self.eeg_embedding = nn.Linear(eeg_channels, d_model)\n",
        "\n",
        "#         # Positional encoding\n",
        "#         self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "#         # Transformer encoder\n",
        "#         encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
        "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "#         # Classifier\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Linear(d_model * 2, d_model),  # *2 because we concatenate signature and EEG features\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(d_model, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, signature, eeg):\n",
        "#         # Signature processing\n",
        "#         signature_embedded = self.signature_embedding(signature)\n",
        "#         signature_embedded = self.positional_encoding(signature_embedded)\n",
        "\n",
        "#         # EEG processing\n",
        "#         eeg_embedded = self.eeg_embedding(eeg)\n",
        "#         eeg_embedded = self.positional_encoding(eeg_embedded)\n",
        "\n",
        "#         # Transformer expects (seq_len, batch, features)\n",
        "#         signature_embedded = signature_embedded.permute(1, 0, 2)\n",
        "#         eeg_embedded = eeg_embedded.permute(1, 0, 2)\n",
        "\n",
        "#         # Process through transformer\n",
        "#         signature_features = self.transformer_encoder(signature_embedded)\n",
        "#         eeg_features = self.transformer_encoder(eeg_embedded)\n",
        "\n",
        "#         # Average over time dimension\n",
        "#         signature_features = signature_features.mean(dim=0)\n",
        "#         eeg_features = eeg_features.mean(dim=0)\n",
        "\n",
        "#         # Concatenate features\n",
        "#         combined_features = torch.cat([signature_features, eeg_features], dim=1)\n",
        "\n",
        "#         # Classify\n",
        "#         output = self.classifier(combined_features)\n",
        "\n",
        "#         return output\n",
        "\n",
        "# class PositionalEncoding(nn.Module):\n",
        "#     def __init__(self, d_model, max_len=5000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return x + self.pe[:x.size(0), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1805ef3b",
      "metadata": {
        "id": "1805ef3b"
      },
      "outputs": [],
      "source": [
        "# def train_model(signature_data, eeg_data, labels, epochs=20, batch_size=32):\n",
        "#     # Create dataset\n",
        "#     dataset = SignatureEEGDataset(signature_data, eeg_data, labels)\n",
        "\n",
        "#     # Split into train and validation\n",
        "#     train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "#     # Create dataloaders\n",
        "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "#     val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "#     # Initialize model\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     model = SignatureEEGTransformer().to(device)\n",
        "\n",
        "#     # Loss and optimizer\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "#     # Training loop\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         train_loss = 0.0\n",
        "\n",
        "#         for signatures, eegs, labels in train_loader:\n",
        "#             signatures, eegs, labels = signatures.to(device), eegs.to(device), labels.to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             outputs = model(signatures, eegs)\n",
        "#             loss = criterion(outputs, labels)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             train_loss += loss.item()\n",
        "\n",
        "#         # Validation\n",
        "#         model.eval()\n",
        "#         val_loss = 0.0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for signatures, eegs, labels in val_loader:\n",
        "#                 signatures, eegs, labels = signatures.to(device), eegs.to(device), labels.to(device)\n",
        "\n",
        "#                 outputs = model(signatures, eegs)\n",
        "#                 loss = criterion(outputs, labels)\n",
        "\n",
        "#                 val_loss += loss.item()\n",
        "#                 _, predicted = torch.max(outputs.data, 1)\n",
        "#                 total += labels.size(0)\n",
        "#                 correct += (predicted == labels).sum().item()\n",
        "\n",
        "#         print(f'Epoch {epoch+1}/{epochs}')\n",
        "#         print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
        "#         print(f'Val Loss: {val_loss/len(val_loader):.4f}')\n",
        "#         print(f'Val Accuracy: {100*correct/total:.2f}%')\n",
        "#         print('-' * 50)\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4996d7b",
      "metadata": {
        "id": "c4996d7b"
      },
      "outputs": [],
      "source": [
        "# model = train_model(normalized_sign_data_dict, normalized_eeg_data_dict, user_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa7e04c",
      "metadata": {
        "id": "1fa7e04c"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models\n",
        "\n",
        "# def prepare_data_with_masking(signature_data, eeg_data, labels_dict):\n",
        "#     \"\"\"\n",
        "#     Prepares data with dynamic padding and preserves original lengths for masking.\n",
        "#     Returns:\n",
        "#         - Padded sequences\n",
        "#         - Sequence length arrays (for masking)\n",
        "#         - Labels\n",
        "#     \"\"\"\n",
        "#     # Initialize lists\n",
        "#     X_signature, X_eeg = [], []\n",
        "#     len_signature, len_eeg = [], []\n",
        "#     y = []\n",
        "\n",
        "#     for user_id in labels_dict.keys():\n",
        "#         for i in range(len(labels_dict[user_id])):\n",
        "#             # Signature data\n",
        "#             sig = signature_data[user_id][i]\n",
        "#             X_signature.append(sig)\n",
        "#             len_signature.append(len(sig))\n",
        "\n",
        "#             # EEG data\n",
        "#             eeg = eeg_data[user_id][i]\n",
        "#             X_eeg.append(eeg)\n",
        "#             len_eeg.append(len(eeg))\n",
        "\n",
        "#             # Label\n",
        "#             y.append(labels_dict[user_id][i])\n",
        "\n",
        "#     # Pad sequences to max length in dataset\n",
        "#     max_len_sig = max(len_signature)\n",
        "#     max_len_eeg = max(len_eeg)\n",
        "\n",
        "#     X_signature_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "#         X_signature, maxlen=max_len_sig, dtype='float32', padding='post'\n",
        "#     )\n",
        "\n",
        "#     X_eeg_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "#         X_eeg, maxlen=max_len_eeg, dtype='float32', padding='post'\n",
        "#     )\n",
        "\n",
        "#     return (\n",
        "#         X_signature_pad, np.array(len_signature),\n",
        "#         X_eeg_pad, np.array(len_eeg),\n",
        "#         np.array(y)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0cc45c",
      "metadata": {
        "id": "6c0cc45c"
      },
      "outputs": [],
      "source": [
        "# def create_masked_model(signature_shape, eeg_shape):\n",
        "#     \"\"\"Creates a model with masking layers to ignore padding\"\"\"\n",
        "#     # Signature branch\n",
        "#     signature_input = layers.Input(shape=signature_shape, name='signature_input')\n",
        "#     signature_length = layers.Input(shape=(1,), name='signature_length', dtype='int32')\n",
        "\n",
        "#     sig = layers.Masking(mask_value=0.0)(signature_input)\n",
        "#     sig = layers.Conv1D(32, 5, activation='relu', padding='same')(sig)\n",
        "#     sig = layers.MaxPooling1D(2)(sig)\n",
        "#     sig = layers.Conv1D(64, 5, activation='relu', padding='same')(sig)\n",
        "#     sig = layers.MaxPooling1D(2)(sig)\n",
        "#     sig = layers.GlobalAveragePooling1D()(sig)\n",
        "\n",
        "#     # EEG branch\n",
        "#     eeg_input = layers.Input(shape=eeg_shape, name='eeg_input')\n",
        "#     eeg_length = layers.Input(shape=(1,), name='eeg_length', dtype='int32')\n",
        "\n",
        "#     eeg = layers.Masking(mask_value=0.0)(eeg_input)\n",
        "#     eeg = layers.Conv1D(32, 5, activation='relu', padding='same')(eeg)\n",
        "#     eeg = layers.MaxPooling1D(2)(eeg)\n",
        "#     eeg = layers.Conv1D(64, 5, activation='relu', padding='same')(eeg)\n",
        "#     eeg = layers.MaxPooling1D(2)(eeg)\n",
        "#     eeg = layers.GlobalAveragePooling1D()(eeg)\n",
        "\n",
        "#     # Combine branches\n",
        "#     combined = layers.concatenate([sig, eeg])\n",
        "#     combined = layers.Dense(128, activation='relu')(combined)\n",
        "#     outputs = layers.Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "#     # Model with length inputs\n",
        "#     model = models.Model(\n",
        "#         inputs=[signature_input, signature_length, eeg_input, eeg_length],\n",
        "#         outputs=outputs\n",
        "#     )\n",
        "\n",
        "#     model.compile(optimizer='adam',\n",
        "#                  loss='binary_crossentropy',\n",
        "#                  metrics=['accuracy'])\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7e44d0",
      "metadata": {
        "id": "bb7e44d0"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, X_sig, len_sig, X_eeg, len_eeg, y, batch_size=32):\n",
        "        self.X_sig = X_sig\n",
        "        self.len_sig = len_sig\n",
        "        self.X_eeg = X_eeg\n",
        "        self.len_eeg = len_eeg\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.y) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_sig = self.X_sig[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_len_sig = self.len_sig[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_eeg = self.X_eeg[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_len_eeg = self.len_eeg[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_y = self.y[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "\n",
        "        return [batch_sig, batch_len_sig, batch_eeg, batch_len_eeg], batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16ae07d",
      "metadata": {
        "id": "f16ae07d"
      },
      "outputs": [],
      "source": [
        "# def train_authentication_model(signature_data, eeg_data, labels_dict):\n",
        "#     # Prepare data\n",
        "#     X_signature, X_eeg, y = prepare_data(signature_data, eeg_data, labels_dict)\n",
        "\n",
        "#     # Split into train and test sets\n",
        "#     (X_signature_train, X_signature_test,\n",
        "#      X_eeg_train, X_eeg_test,\n",
        "#      y_train, y_test) = train_test_split(X_signature, X_eeg, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#     # Create model\n",
        "#     signature_shape = X_signature_train.shape[1:]\n",
        "#     eeg_shape = X_eeg_train.shape[1:]\n",
        "#     model = create_dual_input_model(signature_shape, eeg_shape)\n",
        "\n",
        "#     # Train model\n",
        "#     history = model.fit(\n",
        "#         [X_signature_train, X_eeg_train],\n",
        "#         y_train,\n",
        "#         epochs=50,\n",
        "#         batch_size=32,\n",
        "#         validation_data=([X_signature_test, X_eeg_test], y_test),\n",
        "#         callbacks=[\n",
        "#             tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "#             tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=3)\n",
        "#         ]\n",
        "#     )\n",
        "\n",
        "#     return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c9be06",
      "metadata": {
        "id": "44c9be06"
      },
      "outputs": [],
      "source": [
        "# 1. Prepare data\n",
        "X_sig, len_sig, X_eeg, len_eeg, norm_y = prepare_data_with_masking(signature_data, eeg_data, labels_dict)\n",
        "\n",
        "# 2. Split data\n",
        "(X_sig_train, X_sig_test,\n",
        " len_sig_train, len_sig_test,\n",
        " X_eeg_train, X_eeg_test,\n",
        " len_eeg_train, len_eeg_test,\n",
        " y_train, y_test) = train_test_split(X_sig, len_sig, X_eeg, len_eeg, norm_y, test_size=0.2)\n",
        "\n",
        "# 3. Create model\n",
        "model = create_masked_model(X_sig_train.shape[1:], X_eeg_train.shape[1:])\n",
        "\n",
        "# 4. Create generators\n",
        "train_gen = DataGenerator(X_sig_train, len_sig_train, X_eeg_train, len_eeg_train, y_train)\n",
        "val_gen = DataGenerator(X_sig_test, len_sig_test, X_eeg_test, len_eeg_test, y_test)\n",
        "\n",
        "# 5. Train\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e718c86",
      "metadata": {
        "id": "7e718c86"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_signature_test, X_eeg_test, y_test):\n",
        "    results = model.evaluate([X_signature_test, X_eeg_test], y_test)\n",
        "    print(f\"Test Loss: {results[0]:.4f}\")\n",
        "    print(f\"Test Accuracy: {results[1]:.4f}\")\n",
        "    print(f\"Test AUC: {results[2]:.4f}\")\n",
        "\n",
        "    # You can add more evaluation metrics as needed\n",
        "    y_pred = model.predict([X_signature_test, X_eeg_test])\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
