{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be6e58c6",
      "metadata": {
        "id": "be6e58c6"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xkA1YQ7W-MUl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkA1YQ7W-MUl",
        "outputId": "7fa9e23b-fa00-4276-d44c-62f5357e7e40"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "odgwpcFd-NGU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odgwpcFd-NGU",
        "outputId": "ee47d850-f60c-41fc-8d69-2c9be3b706f8"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install python-dotenv\n",
        "!pip install scipy\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "853f3b96",
      "metadata": {
        "id": "853f3b96"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import constants\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import scipy.io as sp\n",
        "import pprint as pp\n",
        "from scipy.signal import welch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c2fe3aa",
      "metadata": {
        "id": "8c2fe3aa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize, linewidth=300, suppress=True)\n",
        "pd.set_option('display.max_colwidth', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a4bc15",
      "metadata": {
        "id": "97a4bc15"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd2b9b4c",
      "metadata": {
        "id": "dd2b9b4c"
      },
      "outputs": [],
      "source": [
        "# some calculations\n",
        "# for the dataset, 10 seconds = 1280 frames. 1 second = 128 frames. We can sue this to find the number of seconds that were taken to record the signature.\n",
        "\n",
        "recording_samp_rate = 128 # per second\n",
        "per_phase_frames = 1280 # seconds\n",
        "max_seq_len_for_data = 3000 # frames\n",
        "# desampling_factor = 1 # reducing sequences by this size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91ee960",
      "metadata": {
        "id": "c91ee960"
      },
      "source": [
        "# Fetching raw data (Sign + EEG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0358fbdd",
      "metadata": {
        "id": "0358fbdd"
      },
      "source": [
        "## Processing raw files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d6301463",
      "metadata": {
        "id": "d6301463"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "dataset_path = os.getenv('DATASET_PATH')\n",
        "# dataset_path = '/content/drive/MyDrive/dataset-final-project/SignEEGv1.0'\n",
        "\n",
        "def get_dataset_files_and_user_ids(data_category, data_type = constants.TRAIN, task = constants.IDENTIFY):\n",
        "    user_ids = []\n",
        "    labels = []\n",
        "    files_mat = []\n",
        "\n",
        "    # Get training and testing data\n",
        "    data_split = pd.read_csv(os.path.join(dataset_path, \"Identification_split.csv\" if task == constants.IDENTIFY else \"Verification_split.csv\"))\n",
        "    data_categories = [constants.GENUINE, constants.FORGED] if data_category == constants.ALL else [data_category]\n",
        "    files_for_task = list(data_split[data_split.set == data_type].filename)\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        if os.path.basename(root) in data_categories:\n",
        "            for file in files:\n",
        "                if file.endswith('.mat') and file in files_for_task:\n",
        "                    files_mat.append(os.path.join(root, file))\n",
        "                    labels.append(os.path.basename(root))\n",
        "        if os.path.basename(root) != constants.GENUINE and os.path.basename(root) != constants.FORGED and os.path.basename(root) != 'SignEEGv1.0':\n",
        "            user_ids.append(os.path.basename(root))\n",
        "\n",
        "    return files_mat, user_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6154f6d9",
      "metadata": {
        "id": "6154f6d9"
      },
      "outputs": [],
      "source": [
        "# small note: np.delete(axis = 1) will delete a column, axis = 0 will delete a row. be careful"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69bfe1d",
      "metadata": {
        "id": "c69bfe1d"
      },
      "source": [
        "## Getting list of sign data, eeg data and label for each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "85c4f11d",
      "metadata": {
        "id": "85c4f11d"
      },
      "outputs": [],
      "source": [
        "def get_sig_eeg_raw_data(mat_files, labels, desampling_factor = 1):\n",
        "    raw_data_list = []\n",
        "    for mat_file, label in zip(mat_files, labels):\n",
        "        mat_content = sp.loadmat(mat_file)\n",
        "        user_id = str(mat_content['subject']['SubjectID'][0][0][0])\n",
        "        sig_data = mat_content['subject']['SignWacom'][0][0]\n",
        "        eeg_ica_data = mat_content['subject']['ICA_EEG'][0][0].T\n",
        "        sig_data = torch.from_numpy(np.delete(sig_data, 0, axis=1)).to(dtype=torch.float32)\n",
        "\n",
        "        # getting part of eeg data during which signature was recorded (ROI)\n",
        "        roi_frames_start = -(eeg_ica_data.shape[0] % per_phase_frames) if per_phase_frames > 0 else 0\n",
        "        eeg_ica_data = torch.from_numpy(eeg_ica_data[roi_frames_start:]).to(dtype=torch.float32)\n",
        "\n",
        "        # desampling the data\n",
        "        if desampling_factor > 1:\n",
        "            sig_data = sig_data[::desampling_factor, :]\n",
        "            eeg_ica_data = eeg_ica_data[::desampling_factor, :]\n",
        "\n",
        "        if sig_data.shape[0] > max_seq_len_for_data:\n",
        "            # print(\"Caught you!!!\")\n",
        "            # print(\"User ID: \", user_id)\n",
        "            # print(\"File: \", mat_file)\n",
        "            continue # Skip these files because it's too long, outlier\n",
        "        raw_data_list.append({\n",
        "            'sign_data': sig_data,\n",
        "            'eeg_data': eeg_ica_data,\n",
        "            'user_id': user_id,\n",
        "            'label': 0 if label == constants.GENUINE else 1,\n",
        "            'file': mat_file\n",
        "        })\n",
        "\n",
        "    return raw_data_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4a9078",
      "metadata": {
        "id": "0a4a9078"
      },
      "source": [
        "# Augmenting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6ac35e70",
      "metadata": {
        "id": "6ac35e70"
      },
      "outputs": [],
      "source": [
        "def augment_sign_data(sign_data, noise_std=0.01, scale_range=(0.95, 1.05), rotation_deg=5):\n",
        "    augmented = sign_data.clone()\n",
        "    augmented[:, 2:] += torch.randn_like(augmented[:, 2:]) * noise_std\n",
        "    scale = random.uniform(*scale_range)\n",
        "    augmented[:, 2] *= scale\n",
        "    augmented[:, 3] *= scale\n",
        "\n",
        "    # Random rotation (x, y)\n",
        "    theta = math.radians(random.uniform(-rotation_deg, rotation_deg))\n",
        "    x = augmented[:, 2].clone()\n",
        "    y = augmented[:, 3].clone()\n",
        "    augmented[:, 2] = x * math.cos(theta) - y * math.sin(theta)\n",
        "    augmented[:, 3] = x * math.sin(theta) + y * math.cos(theta)\n",
        "\n",
        "    return augmented\n",
        "\n",
        "def augment_eeg_data(eeg_data, noise_std=0.01, scale_range=(0.95, 1.05), time_shift_max=10):\n",
        "    augmented = eeg_data.clone()\n",
        "    augmented += torch.randn_like(augmented) * noise_std\n",
        "    scale = random.uniform(*scale_range)\n",
        "    augmented *= scale\n",
        "    shift = random.randint(-time_shift_max, time_shift_max)\n",
        "    if shift > 0:\n",
        "        augmented = torch.cat([augmented[shift:], torch.zeros_like(augmented[:shift])], dim=0)\n",
        "    elif shift < 0:\n",
        "        augmented = torch.cat([torch.zeros_like(augmented[shift:]), augmented[:shift]], dim=0)\n",
        "\n",
        "    return augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d478c1",
      "metadata": {
        "id": "10d478c1"
      },
      "source": [
        "# Sign Data Classification Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ccb8429",
      "metadata": {
        "id": "6ccb8429"
      },
      "source": [
        "## Sign data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "59a2b561",
      "metadata": {
        "id": "59a2b561"
      },
      "outputs": [],
      "source": [
        "def normalize_sign_data_dict(sign_data):\n",
        "\n",
        "    mean = torch.mean(sign_data[:, 2:], dim=0)\n",
        "    std = torch.std(sign_data[:, 2:], dim=0)\n",
        "    std = torch.where(std == 0, torch.tensor(1.0, dtype=torch.float32), std)\n",
        "    normalized = (sign_data[:, 2:] - mean) / std\n",
        "    normalized = torch.cat([sign_data[:, 0:2], normalized], dim=1).to(dtype=torch.float32)\n",
        "    return normalized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b972dd",
      "metadata": {
        "id": "f1b972dd"
      },
      "source": [
        "## Sign Data Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5eadc841",
      "metadata": {
        "id": "5eadc841"
      },
      "outputs": [],
      "source": [
        "def get_sign_data_features(sign_data):\n",
        "    normalized_sign_data = normalize_sign_data_dict(sign_data)\n",
        "    x = sign_data[:, 2]\n",
        "    y = sign_data[:, 3]\n",
        "\n",
        "    normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
        "    norm_x = normalized_sign_data[:, 2]\n",
        "    norm_y = normalized_sign_data[:, 3]\n",
        "    vx = torch.gradient(norm_x)[0]\n",
        "    vy = torch.gradient(norm_y)[0]\n",
        "    velocity = torch.sqrt(vx**2 + vy**2)\n",
        "    ax = torch.gradient(vx)[0]\n",
        "    ay = torch.gradient(vy)[0]\n",
        "    acceleration = torch.sqrt(ax**2 + ay**2)\n",
        "\n",
        "    avg_vx = torch.mean(vx)\n",
        "    avg_vy = torch.mean(vy)\n",
        "    avg_ax = torch.mean(ax)\n",
        "    avg_ay = torch.mean(ay)\n",
        "\n",
        "    # log curvature radius\n",
        "    dt = 1\n",
        "    dx = torch.gradient(norm_x, spacing=(dt,))[0]\n",
        "    dy = torch.gradient(norm_y, spacing=(dt,))[0]\n",
        "    v_t = torch.sqrt(dx ** 2 + dy ** 2)\n",
        "    v_t = torch.where(v_t == 0, torch.tensor(1e-10, dtype=v_t.dtype), v_t)\n",
        "    theta = torch.atan2(dy, dx)\n",
        "    dtheta = torch.gradient(theta, spacing=(dt,))[0]\n",
        "    dtheta = torch.where(dtheta == 0, torch.tensor(1e-10, dtype=dtheta.dtype), dtheta)\n",
        "    log_curv_radius = torch.log(torch.abs(v_t / dtheta) + 1e-10)\n",
        "    # print(\"Log Curve Radius shape: \", log_curv_radius.shape)\n",
        "    # getting static features\n",
        "    pendown_frames = normalized_sign_data[:, 1] == 1\n",
        "    num_strokes = torch.unique(normalized_sign_data[pendown_frames][:, 0]).shape[0]\n",
        "    x_down = normalized_sign_data[pendown_frames][:, 2]\n",
        "    y_down = normalized_sign_data[pendown_frames][:, 3]\n",
        "    sign_centroid = torch.tensor([torch.mean(x_down), torch.mean(y_down)], dtype=torch.float32)\n",
        "    if y_down.shape[0] > 0:\n",
        "        sign_height = torch.max(y_down) - torch.min(y_down)\n",
        "    else:\n",
        "        sign_height = 0\n",
        "    if x_down.shape[0] > 0:\n",
        "        sign_width = torch.max(x_down) - torch.min(x_down)\n",
        "    else:\n",
        "        sign_width = 0\n",
        "    height_width_ratio = sign_height / sign_width if sign_width != 0 else torch.tensor(0.0, dtype=torch.float32)\n",
        "\n",
        "    # new time dependent feature - jerk\n",
        "    jerk = torch.sqrt(torch.gradient(vx)[0]**2 + torch.gradient(vy)[0]**2)\n",
        "\n",
        "    pressure = sign_data[pendown_frames][:, 4]\n",
        "    azimuth = sign_data[pendown_frames][:, 5]\n",
        "    altitude = sign_data[pendown_frames][:, 6]\n",
        "    avg_pressure = torch.mean(pressure)\n",
        "    avg_azimuth = torch.mean(azimuth)\n",
        "    avg_altitude = torch.mean(altitude)\n",
        "    max_pressure = torch.max(pressure) if pressure.numel() > 0 else torch.tensor(0.0, dtype=torch.float32)\n",
        "    sign_duration = sign_data.shape[0] / recording_samp_rate\n",
        "    cls_token = torch.tensor([\n",
        "        num_strokes, sign_height, sign_width, height_width_ratio, sign_centroid[0], sign_centroid[1], avg_pressure, avg_azimuth, avg_altitude, avg_vx, avg_vy, avg_ax, avg_ay, max_pressure, sign_duration], dtype=torch.float32)\n",
        "    sign_data_aug = torch.cat([normalized_sign_data, velocity.unsqueeze(1), acceleration.unsqueeze(1), log_curv_radius.unsqueeze(1), jerk.unsqueeze(1)], dim=1)\n",
        "\n",
        "    return sign_data_aug, cls_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75128f7a",
      "metadata": {
        "id": "75128f7a"
      },
      "source": [
        "## Prepare sign dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0eb40603",
      "metadata": {
        "id": "0eb40603"
      },
      "outputs": [],
      "source": [
        "def attach_attention_tokens_and_padding(data, max_len):\n",
        "    # print(\"EEG Data shape: \", data.shape)\n",
        "    if data.shape[0] == 0:\n",
        "        feat_dim = data.shape[1] if data.ndim == 2 else 1\n",
        "        return torch.zeros((max_len, feat_dim), dtype=torch.float32), torch.zeros(max_len, dtype=torch.float32)\n",
        "    seq_len, feat_dim = data.shape\n",
        "    pad_width = (0, max_len - seq_len)\n",
        "    padded_data = torch.nn.functional.pad(data, (0, 0, 0, pad_width[1]), mode='constant', value=0)\n",
        "    attention_mask = torch.zeros(max_len + 1, dtype=torch.float32)\n",
        "    attention_mask[:seq_len + 1] = 1  # +1 for cls_token\n",
        "    return padded_data, attention_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c62d30c",
      "metadata": {
        "id": "6c62d30c"
      },
      "outputs": [],
      "source": [
        "# # For single data\n",
        "\n",
        "# sign_dict_sample, eeg_dict_sample, label = get_sig_eeg_data_dicts([files_mat_appended[0]], [1])\n",
        "# # print(sign_dict_sample['000000000200894'][0].shape)\n",
        "# normalized_sign_data_sample = normalize_sign_data_dict(sign_dict_sample)\n",
        "# sign_with_features = get_sign_data_features(normalized_sign_data_sample)\n",
        "# # print()\n",
        "# final_sign_data = sign_attach_attention_tokens_and_labels(sign_with_features, label)\n",
        "# final_sign_dataset = prepare_sign_dataset_with_all_parts(final_sign_data)\n",
        "# # print(\"Max len: \", get_sign_max_seq_len(sign_with_features))\n",
        "# # print(final_sign_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db33ebbb",
      "metadata": {
        "id": "db33ebbb"
      },
      "source": [
        "## Sign Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eedde36e",
      "metadata": {
        "id": "eedde36e"
      },
      "outputs": [],
      "source": [
        "# num_classes will be 2 (0 = unauthenticated, 1 = authenticated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d20fc0",
      "metadata": {
        "id": "d3d20fc0"
      },
      "outputs": [],
      "source": [
        "''' current data format:\n",
        "\n",
        "Just for reference, so that I don't forget later\n",
        "\n",
        "original data:\n",
        "\n",
        "{\n",
        "    user_id: string,\n",
        "    data: [ [ [], [], [] ... ], [ [], [], [] ... ] ...  ], size: (30 * 1200 * 7) = (num_samples_per_user * time_series_len * num_features)\n",
        "}\n",
        "\n",
        "extracted data:\n",
        "\n",
        "{\n",
        "    cls_tokens: tensor([ , , , , ... ], [ , , , ,  ....], [ , , , , ...] ... ), size: (total_num_samples * num_features),\n",
        "    data: tensor([ [], [], [] ... ], [ [], [], [] ... ] ...), size: (total_num_samples * time_series_len * num_features),\n",
        "    attention_masks: tensor([1, 1, 1, ...], [1, 1,1, ...] ... ), size: (total_num_samples * time_series_len),\n",
        "    labels: tensor([1, 0, 1, 0 ...]), size: (total_num_samples, )\n",
        "}\n",
        "'''\n",
        "\n",
        "class SignatureDataset(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        self.seq_len = input_data['sign_data'][0].shape[0]\n",
        "        self.ts_dim = input_data['sign_data'][0].shape[1]\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.x_ts = input_data['sign_data']\n",
        "        self.cls_token = input_data['sign_cls_tokens']\n",
        "        self.labels = input_data['labels']\n",
        "        self.attention_mask = input_data['sign_attention_masks']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'x_ts': self.x_ts[idx],\n",
        "            'cls_token': self.cls_token[idx],\n",
        "            'labels': self.labels[idx],\n",
        "            'attention_mask': self.attention_mask[idx]\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451ebf92",
      "metadata": {
        "id": "451ebf92"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len + 1, d_model)\n",
        "        position = torch.arange(0, max_len + 1, dtype = torch.float).unsqueeze(1)\n",
        "        divterm = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # Credits to hkproj@github for this as https://github.com/hkproj/pytorch-transformer/blob/main/model.py\n",
        "        pe[:, 0::2] = torch.sin(position * divterm)\n",
        "        pe[:, 1::2] = torch.cos(position * divterm)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "014ab58f",
      "metadata": {
        "id": "014ab58f"
      },
      "outputs": [],
      "source": [
        "class SignatureTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, cls_dim, d_model, num_classes, num_heads, num_layers, max_seq_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_len)\n",
        "        self.cls_proj = nn.Linear(cls_dim, d_model)\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dropout = dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers = num_layers)\n",
        "        # uncomment for single modality\n",
        "        self.classifier = nn.Sequential(nn.Linear(d_model, d_model), nn.ReLU(), nn.Linear(d_model, num_classes))\n",
        "\n",
        "    def forward(self, x_ts, cls_token, attn_mask = None):\n",
        "        x_ts = torch.nan_to_num(x_ts, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        cls_token = torch.nan_to_num(cls_token, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        batch_size, t, feat_dim = x_ts.shape\n",
        "        x_proj = self.input_projection(x_ts)\n",
        "        cls_proj = self.cls_proj(cls_token).unsqueeze(1)\n",
        "        # print(\"x_proj size: \", x_proj.shape)\n",
        "        # print(\"cls_proj size: \", cls_proj.shape)\n",
        "        x = torch.cat([cls_proj, x_proj], dim=1)\n",
        "        # print(\"x_proj and cls_proj concatenated size: \", x.shape)\n",
        "        x = x + self.positional_encoding(x)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask == 0 # True = ignore the value, False = include it!!!!!!!!!!\n",
        "            # cls_mask = torch.zeros((batch_size, 1), dtype=torch.bool, device=attn_mask.device)\n",
        "            full_mask = torch.cat([attn_mask], dim=1)  # [batch_size, t+1]\n",
        "        else:\n",
        "            full_mask = None\n",
        "        # print(\"Mask shape: \", full_mask.shape)\n",
        "        x = self.transformer(x, src_key_padding_mask=full_mask)\n",
        "        cls_output = x[:, 0, :]\n",
        "        # uncomment for single modality transformer\n",
        "        # logits = self.classifier(cls_output)\n",
        "        # return logits\n",
        "\n",
        "        # uncomment for multimodal transformer\n",
        "        return cls_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a0fc6b",
      "metadata": {},
      "source": [
        "## Training Sign Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbbdd6a0",
      "metadata": {
        "id": "bbbdd6a0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def sign_training_loop(model, dataloader, optimizer, loss_fn, device, num_epochs=10):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    model_path = os.getenv(\"MODEL_PATH\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        total_samples = 0\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        for i, batch in enumerate(tqdm(dataloader, desc=\"Training\", leave=False)):\n",
        "            x_ts = batch['x_ts'].to(device)\n",
        "            cls_token = batch['cls_token'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_ts, cls_token, attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN loss detected!\")\n",
        "                print(\"Labels:\", labels)\n",
        "                print(\"Logits:\", logits)\n",
        "                break\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x_ts.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            total_samples += x_ts.size(0)\n",
        "\n",
        "        avg_loss = total_loss / total_samples if total_samples > 0 else 0\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "        rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "        print(f\"Loss: {avg_loss:.4f} | Acc: {acc:.4f} | Prec: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
        "    torch.save(model.state_dict(), os.path.join(model_path, f\"model{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5b8f2a",
      "metadata": {
        "id": "1f5b8f2a"
      },
      "source": [
        "## Sign Data Feed to Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e7649a",
      "metadata": {
        "id": "d2e7649a"
      },
      "outputs": [],
      "source": [
        "input_data = {\n",
        "    'sign_data': sign_data,\n",
        "    'eeg_data': eeg_data,\n",
        "    'sign_attention_masks': sign_attention_masks,\n",
        "    'eeg_attention_masks': eeg_attention_masks,\n",
        "    'sign_cls_tokens': sign_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_cls_tokens,\n",
        "    'labels': labels,\n",
        "}\n",
        "ts_dim = input_data['sign_data'][0].size(1)\n",
        "cls_dim = input_data['sign_cls_tokens'][0].size(0)\n",
        "d_model = 64\n",
        "num_classes = 2\n",
        "seq_len = max([data.shape[0] for data in input_data['sign_data']])\n",
        "batch_size = 8\n",
        "\n",
        "dataset = SignatureDataset(input_data, num_classes)\n",
        "# dataset.__getitem__(0)['x_ts'].shape\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "sign_model = SignatureTransformer(input_dim=ts_dim, cls_dim=cls_dim, d_model=d_model, num_classes=num_classes, num_heads=4, num_layers=2, max_seq_len=seq_len)\n",
        "optimizer = optim.Adam(sign_model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "sign_training_loop(sign_model, dataloader, optimizer, loss_fn, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a51e3b",
      "metadata": {
        "id": "08a51e3b"
      },
      "source": [
        "## Sign - Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c8245b",
      "metadata": {
        "id": "46c8245b"
      },
      "outputs": [],
      "source": [
        "# # print(len(final_signature_data['002108410100044']['cls_tokens']))\n",
        "# # print(len(final_signature_data['002108410100044']['data']))\n",
        "# # print(len(final_signature_data['002108410100044']['attention_masks']))\n",
        "\n",
        "# # print(final_signature_data['002108410100044']['cls_tokens'][0].shape)\n",
        "# # print(final_signature_data['002108410100044']['data'][0].shape)\n",
        "# # print(final_signature_data['002108410100044']['attention_masks'][0].shape)\n",
        "\n",
        "\n",
        "# print(len(final_sign_dataset_for_all_users['cls_tokens']))\n",
        "# print(len(final_sign_dataset_for_all_users['data']))\n",
        "# print(len(final_sign_dataset_for_all_users['attention_masks']))\n",
        "# print(len(final_sign_dataset_for_all_users['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec3dd28",
      "metadata": {
        "id": "1ec3dd28"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# print(len(final_sign_dataset_for_all_users['cls_tokens']))\n",
        "# print(len(final_sign_dataset_for_all_users['data']))\n",
        "# print(len(final_sign_dataset_for_all_users['attention_masks']))\n",
        "\n",
        "# print(final_sign_dataset_for_all_users['cls_tokens'][0].shape)\n",
        "# print(final_sign_dataset_for_all_users['data'][0].shape)\n",
        "# print(final_sign_dataset_for_all_users['attention_masks'][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93df9de",
      "metadata": {
        "id": "a93df9de"
      },
      "outputs": [],
      "source": [
        "# print(normalized_sign_data_dict['000000000200894'][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432f8149",
      "metadata": {
        "id": "432f8149"
      },
      "outputs": [],
      "source": [
        "# normalized_sign_data_dict = normalize_sign_data_dict(sign_data_dict)\n",
        "# # print(sign_data_dict['000000000200894'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4fc84a",
      "metadata": {
        "id": "4e4fc84a"
      },
      "outputs": [],
      "source": [
        "# print(len(sign_times_for_users))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21ab25fe",
      "metadata": {
        "id": "21ab25fe"
      },
      "source": [
        "# EEG Data Classification Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a6fe1a5",
      "metadata": {
        "id": "6a6fe1a5"
      },
      "source": [
        "## EEG Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e12b2c96",
      "metadata": {
        "id": "e12b2c96"
      },
      "outputs": [],
      "source": [
        "def normalize_eeg_data_dict(eeg_data_dict):\n",
        "    normalized_eeg_data_dict = {}\n",
        "    for user_id, eeg_list in eeg_data_dict.items():\n",
        "        normalized_eeg_data_dict[user_id] = []\n",
        "        for eeg_data in eeg_list:\n",
        "            mean = eeg_data.mean(dim=0, keepdim=True)\n",
        "            std = eeg_data.std(dim=0, keepdim=True)\n",
        "            std = torch.where(std == 0, torch.tensor(1.0, dtype=std.dtype, device=std.device), std)\n",
        "            normalized = (eeg_data - mean) / std\n",
        "            normalized_eeg_data_dict[user_id].append(normalized)\n",
        "    return normalized_eeg_data_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c86c80",
      "metadata": {
        "id": "18c86c80"
      },
      "source": [
        "## EEG Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "613e78d8",
      "metadata": {
        "id": "613e78d8"
      },
      "outputs": [],
      "source": [
        "def extract_fft_features(eeg_data, fs=128, epoch_length_sec=1): # taking 1s instead of 30s because the signal duration is short\n",
        "    n_samples, n_channels = eeg_data.shape\n",
        "    epoch_len = int(epoch_length_sec * fs)\n",
        "    n_epochs = n_samples // epoch_len\n",
        "    features = []\n",
        "    for i in range(n_epochs):\n",
        "        epoch = eeg_data[i*epoch_len:(i+1)*epoch_len, :]\n",
        "        epoch_features = []\n",
        "        for ch in range(n_channels):\n",
        "            fft_vals = np.fft.rfft(epoch[:, ch])\n",
        "            fft_power = np.abs(fft_vals)\n",
        "            epoch_features.extend(np.abs(fft_vals).flatten())\n",
        "        features.append(epoch_features)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9c6685fb",
      "metadata": {
        "id": "9c6685fb"
      },
      "outputs": [],
      "source": [
        "def get_nth_difference_mean_for_signal(input_signal, n):\n",
        "    input_signal = torch.as_tensor(input_signal)\n",
        "    diff = torch.abs(input_signal[n:] - input_signal[:-n])\n",
        "    res = torch.sum(diff) / (input_signal.shape[0] - n)\n",
        "    return res\n",
        "\n",
        "def normalize_for_eeg_related_data(data):\n",
        "    data = torch.as_tensor(data, dtype=torch.float32)\n",
        "    mean = torch.mean(data, dim=0)\n",
        "    std = torch.std(data, dim=0)\n",
        "    std = torch.where(std == 0, torch.tensor(1.0, dtype=std.dtype, device=std.device), std)\n",
        "    norm = (data - mean) / std\n",
        "    return norm\n",
        "\n",
        "def get_eeg_data_features(eeg_data, fs=recording_samp_rate):\n",
        "\n",
        "    signal_mean = torch.mean(eeg_data)\n",
        "    signal_std = torch.std(eeg_data)\n",
        "\n",
        "    first_difference_sample_mean_absolute_difference_raw_signal = get_nth_difference_mean_for_signal(eeg_data, 1)\n",
        "    second_difference_sample_mean_absolute_difference_raw_signal = get_nth_difference_mean_for_signal(eeg_data, 2)\n",
        "\n",
        "    normalized_signal = normalize_for_eeg_related_data(eeg_data)\n",
        "    first_difference_sample_mean_absolute_difference_normalized_signal = get_nth_difference_mean_for_signal(normalized_signal, 1)\n",
        "    second_difference_sample_mean_absolute_difference_normalized_signal = get_nth_difference_mean_for_signal(normalized_signal, 2)\n",
        "    fw_powers = []\n",
        "    eeg_data = torch.as_tensor(eeg_data, dtype=torch.float32)\n",
        "    for ch in range(normalized_signal.shape[1]):\n",
        "        # Welch returns numpy arrays, so convert to torch\n",
        "        f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
        "        f = torch.from_numpy(f).to(normalized_signal.device)\n",
        "        Pxx = torch.from_numpy(Pxx).to(normalized_signal.device)\n",
        "        fw_power = torch.sum(f * Pxx) / torch.sum(Pxx) if torch.sum(Pxx) > 0 else torch.tensor(0.0, device=normalized_signal.device)\n",
        "        fw_powers.append(fw_power)\n",
        "    fw_power_arr = torch.stack(fw_powers).unsqueeze(0)\n",
        "    # cls_token = torch.cat([signal_mean, signal_std, first_difference_sample_mean_absolute_difference_raw_signal, second_difference_sample_mean_absolute_difference_raw_signal, first_difference_sample_mean_absolute_difference_normalized_signal, second_difference_sample_mean_absolute_difference_normalized_signal])\n",
        "    # cls_token = torch.stack(fw_power_arr)\n",
        "    fft_features = extract_fft_features(normalized_signal.cpu().numpy(), fs=fs) # because we are using np.fft.rfft\n",
        "    features = [signal_mean, signal_std, first_difference_sample_mean_absolute_difference_raw_signal, second_difference_sample_mean_absolute_difference_raw_signal, first_difference_sample_mean_absolute_difference_normalized_signal, second_difference_sample_mean_absolute_difference_normalized_signal]\n",
        "    # for epoch_feat in fft_features:\n",
        "    #     features.extend(epoch_feat)\n",
        "    features.extend(fw_power_arr.squeeze(0).tolist())\n",
        "    cls_token = torch.tensor(features, dtype=torch.float32)\n",
        "    # uncomment if fft_features as eeg_data fails\n",
        "    # return normalized_signal, cls_token\n",
        "    fft_features = torch.tensor(fft_features, dtype=torch.float32)\n",
        "    fft_features = torch.nan_to_num(fft_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    return normalized_signal, fft_features, cls_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36432dfd",
      "metadata": {
        "id": "36432dfd"
      },
      "source": [
        "## EEG Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bf5a48",
      "metadata": {
        "id": "86bf5a48"
      },
      "outputs": [],
      "source": [
        "# # All EEG Data\n",
        "\n",
        "# files_mat_genuine, user_ids_genuine, genuine_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE)\n",
        "# files_mat_forged, user_ids_forged, forged_labels = get_dataset_files_and_user_ids(data_category=constants.FORGED)\n",
        "\n",
        "# files_mat_genuine.extend(files_mat_forged)\n",
        "# files_mat_appended = files_mat_genuine\n",
        "# genuine_labels.extend(forged_labels)\n",
        "# labels_appended = genuine_labels\n",
        "\n",
        "# # shuffling to prevent overfitting\n",
        "# files_all = np.array(files_mat_appended)\n",
        "# labels_all = np.array(labels_appended)\n",
        "\n",
        "# indices = np.arange(len(files_all))\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# files_mat_appended = files_all[indices]\n",
        "# labels_appended = labels_all[indices]\n",
        "\n",
        "# sign_data_dict, eeg_data_dict, labels = get_sig_eeg_raw_data(files_mat_appended, labels_appended)\n",
        "# normalized_eeg_data_dict = normalize_eeg_data_dict(eeg_data_dict)\n",
        "# eeg_data_with_features = get_eeg_data_features(normalized_eeg_data_dict)\n",
        "# eeg_final_data = eeg_attach_attention_tokens_and_labels(eeg_data_with_features, labels)\n",
        "# eeg_final_dataset = prepare_eeg_dataset_with_all_parts(eeg_final_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f06a7c4",
      "metadata": {
        "id": "8f06a7c4"
      },
      "outputs": [],
      "source": [
        "# input_data = eeg_final_dataset\n",
        "# ts_dim = input_data['data'][0].size(1)\n",
        "# cls_dim = input_data['cls_tokens'][0].size(0)\n",
        "# d_model = 64\n",
        "# num_classes = 2\n",
        "# seq_len = get_eeg_max_seq_len(eeg_data_with_features)\n",
        "# batch_size = 8\n",
        "\n",
        "# dataset = SignatureDataset(input_data, num_classes)\n",
        "# # dataset.__getitem__(0)['x_ts'].shape\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# eeg_model = SignatureTransformer(input_dim=ts_dim, cls_dim=cls_dim, d_model=d_model, num_classes=num_classes, num_heads=4, num_layers=4, max_seq_len=seq_len)\n",
        "# optimizer = optim.Adam(eeg_model.parameters(), lr=1e-4)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# sign_training_loop(eeg_model, dataloader, optimizer, loss_fn, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07f624e0",
      "metadata": {
        "id": "07f624e0"
      },
      "source": [
        "# Sign + EEG Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f15581d",
      "metadata": {
        "id": "9f15581d"
      },
      "source": [
        "## Getting the EEG and Sign data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e155462c",
      "metadata": {
        "id": "e155462c",
        "outputId": "a9e88ac3-d6ed-4b7e-c076-6d7fb2c96e6a"
      },
      "outputs": [],
      "source": [
        "# files_mat_genuine, user_ids_genuine, genuine_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type = constants.TRAIN)\n",
        "# # files_mat_forged, user_ids_forged, forged_labels = get_dataset_files_and_user_ids(data_category=constants.FORGED, data_type = constants.TRAIN)\n",
        "\n",
        "# # files_mat_genuine.extend(files_mat_forged)\n",
        "# files_mat_appended = files_mat_genuine\n",
        "# # genuine_labels.extend(forged_labels)\n",
        "# # labels_appended = genuine_labels\n",
        "# # user_ids_genuine.extend(user_ids_forged)\n",
        "# labels_appended = user_ids_genuine\n",
        "\n",
        "# # assigning a number to each user id\n",
        "# user_id_to_num_map = {user_id: i for i, user_id in enumerate(set(labels_appended))}\n",
        "# labels_appended = [user_id_to_num_map[label] for label in labels_appended]\n",
        "# print(len(labels_appended))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "314126b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "314126b2",
        "outputId": "42c990a5-c309-47bc-80ec-068b47730ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files:  583\n",
            "Test files:  201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\1646318677.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 203, using nperseg = 203\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 197, using nperseg = 197\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 136, using nperseg = 136\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n"
          ]
        }
      ],
      "source": [
        "train_files, user_ids, train_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type = constants.TRAIN, task = constants.IDENTIFY)\n",
        "test_files, _, test_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.TEST, task = constants.IDENTIFY)\n",
        "# files_mat_forged, user_ids_forged, forged_labels = get_dataset_files_and_user_ids(data_category=constants.FORGED, data_type = constants.TRAIN)\n",
        "print(\"Train files: \", len(train_files))\n",
        "print(\"Test files: \", len(test_files))\n",
        "# files_mat_genuine.extend(files_mat_forged)\n",
        "# files_mat_appended = files_mat_genuine\n",
        "# genuine_labels.extend(forged_labels)\n",
        "# labels_appended = genuine_labels\n",
        "# user_ids_genuine.extend(user_ids_forged)\n",
        "\n",
        "# assigning a number to each user id\n",
        "user_id_to_num_map = {user_id: i for i, user_id in enumerate(set(user_ids))}\n",
        "\n",
        "# indices = np.arange(len(files_all))\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# train test split\n",
        "# train_indices, test_indices = train_test_split(range(len(labels_all)), test_size=0.2, random_state=42, stratify=labels_all)\n",
        "# train_files = [files_mat_appended[i] for i in train_indices]\n",
        "# train_labels = [labels_appended[i] for i in train_indices]\n",
        "# test_files = [files_mat_appended[i] for i in test_indices]\n",
        "# test_labels = [labels_appended[i] for i in test_indices]\n",
        "\n",
        "# files_mat_appended = files_all[indices]\n",
        "# labels_appended = labels_all[indices]\n",
        "\n",
        "raw_train_data = get_sig_eeg_raw_data(train_files, train_labels)\n",
        "raw_test_data = get_sig_eeg_raw_data(test_files, test_labels)\n",
        "\n",
        "# for debugging only\n",
        "# print(\"EEG Data seq len: \", [data['eeg_data'].shape[0] for data in raw_data])\n",
        "\n",
        "augmented_raw_data = []\n",
        "num_augments = 20\n",
        "\n",
        "for sample in raw_train_data:\n",
        "    augmented_raw_data.append(sample)\n",
        "    for _ in range(num_augments):\n",
        "        aug_sample = sample.copy()\n",
        "        aug_sample['sign_data'] = augment_sign_data(sample['sign_data'])\n",
        "        aug_sample['eeg_data'] = augment_eeg_data(sample['eeg_data'])\n",
        "        augmented_raw_data.append(aug_sample)\n",
        "\n",
        "raw_train_data = augmented_raw_data\n",
        "# shuffling to prevent overfitting\n",
        "random.shuffle(raw_train_data)\n",
        "\n",
        "for i in range(len(raw_train_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_train_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_train_data[i]['eeg_data'])\n",
        "    # print(\"EEG Feature data shape: \", eeg_data_with_features.shape)\n",
        "    raw_train_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_train_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_train_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_train_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "    raw_train_data[i]['user_id'] = user_id_to_num_map[raw_train_data[i]['user_id']]\n",
        "\n",
        "for i in range(len(raw_test_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_test_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_test_data[i]['eeg_data'])\n",
        "    raw_test_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_test_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_test_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_test_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "    raw_test_data[i]['user_id'] = user_id_to_num_map[raw_test_data[i]['user_id']]\n",
        "\n",
        "# sign_max_seq_len = max([data['sign_data'].shape[0] for data in raw_data])\n",
        "# eeg_max_seq_len = max([data['eeg_data'].shape[0] for data in raw_data])\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = 10\n",
        "\n",
        "for i in range(len(raw_train_data)):\n",
        "    sign_data = raw_train_data[i]['sign_data']\n",
        "    eeg_data = raw_train_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_train_data[i]['sign_data'] = sign_data\n",
        "    raw_train_data[i]['eeg_data'] = eeg_data\n",
        "    raw_train_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_train_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "for i in range(len(raw_test_data)):\n",
        "    sign_data = raw_test_data[i]['sign_data']\n",
        "    eeg_data = raw_test_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_test_data[i]['sign_data'] = sign_data\n",
        "    raw_test_data[i]['eeg_data'] = eeg_data\n",
        "    raw_test_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_test_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "sign_train_data = [data['sign_data'] for data in raw_train_data]\n",
        "eeg_train_data = [data['eeg_data'] for data in raw_train_data]\n",
        "sign_train_attention_masks = [data['sign_attention_mask'] for data in raw_train_data]\n",
        "eeg_train_attention_masks = [data['eeg_attention_mask'] for data in raw_train_data]\n",
        "sign_train_cls_tokens = [data['sign_cls_token'] for data in raw_train_data]\n",
        "eeg_train_cls_tokens = [data['eeg_cls_token'] for data in raw_train_data]\n",
        "labels_train = [data['user_id'] for data in raw_train_data]\n",
        "files_train = [data['file'] for data in raw_train_data]\n",
        "\n",
        "sign_test_data = [data['sign_data'] for data in raw_test_data]\n",
        "eeg_test_data = [data['eeg_data'] for data in raw_test_data]\n",
        "sign_test_attention_masks = [data['sign_attention_mask'] for data in raw_test_data]\n",
        "eeg_test_attention_masks = [data['eeg_attention_mask'] for data in raw_test_data]\n",
        "sign_test_cls_tokens = [data['sign_cls_token'] for data in raw_test_data]\n",
        "eeg_test_cls_tokens = [data['eeg_cls_token'] for data in raw_test_data]\n",
        "labels_test = [data['user_id'] for data in raw_test_data]\n",
        "files_test = [data['file'] for data in raw_test_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "794909ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "794909ef",
        "outputId": "ecaca753-68f0-45a4-c9e2-17f5ce1d94b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sign train data type:  <class 'list'>\n",
            "EEG train data type:  <class 'list'>\n",
            "Sign train data type:  <class 'torch.Tensor'>\n",
            "EEG train data type:  <class 'torch.Tensor'>\n",
            "Sign train cls tokens type:  <class 'torch.Tensor'>\n",
            "EEG train cls tokens type:  <class 'torch.Tensor'>\n",
            "Sign train data shape:  torch.Size([3000, 11])\n",
            "EEG train data shape:  torch.Size([10, 325])\n",
            "Sign train attention mask shape:  torch.Size([3001])\n",
            "EEG train attention mask shape:  torch.Size([11])\n",
            "Train labels length:  12222\n",
            "Test labels length:  201\n",
            "Train labels:  [39, 14, 8, 14, 20, 62, 20, 25, 47, 23]\n",
            "Test labels:  [42, 42, 59, 59, 59, 59, 59, 59, 4, 4]\n"
          ]
        }
      ],
      "source": [
        "print(\"Sign train data type: \", type(sign_train_data))\n",
        "print(\"EEG train data type: \", type(eeg_train_data))\n",
        "print(\"Sign train data type: \", type(sign_train_attention_masks[0]))\n",
        "print(\"EEG train data type: \", type(eeg_train_attention_masks[0]))\n",
        "print(\"Sign train cls tokens type: \", type(sign_train_cls_tokens[0]))\n",
        "print(\"EEG train cls tokens type: \", type(eeg_train_cls_tokens[0]))\n",
        "\n",
        "print(\"Sign train data shape: \", sign_train_data[0].shape)\n",
        "print(\"EEG train data shape: \", eeg_train_data[0].shape)\n",
        "print(\"Sign train attention mask shape: \", sign_train_attention_masks[0].shape)\n",
        "print(\"EEG train attention mask shape: \", eeg_train_attention_masks[0].shape)\n",
        "print(\"Train labels length: \", len(labels_train))\n",
        "print(\"Test labels length: \", len(labels_test))\n",
        "print(\"Train labels: \", labels_train[:10])\n",
        "print(\"Test labels: \", labels_test[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88540e7",
      "metadata": {
        "id": "f88540e7"
      },
      "outputs": [],
      "source": [
        "sign_ts_dim = sign_train_data[0].size(1)\n",
        "sign_cls_dim = sign_train_cls_tokens[0].size(0)\n",
        "sign_seq_len = sign_train_data[0].size(0)\n",
        "eeg_ts_dim = eeg_train_data[0].size(1)\n",
        "eeg_cls_dim = eeg_train_cls_tokens[0].size(0)\n",
        "eeg_seq_len = eeg_train_data[0].size(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "755c6a5e",
      "metadata": {
        "id": "755c6a5e"
      },
      "source": [
        "## Redesigning the Transformer model implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "eeec2cc5",
      "metadata": {
        "id": "eeec2cc5"
      },
      "outputs": [],
      "source": [
        "class SignatureEEGDataset(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        sign_attention_masks = input_data['sign_attention_masks']\n",
        "        eeg_attention_masks = input_data['eeg_attention_masks']\n",
        "        sign_cls_tokens = input_data['sign_cls_tokens']\n",
        "        eeg_cls_tokens = input_data['eeg_cls_tokens']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "        self.sign_cls_token = sign_cls_tokens\n",
        "        self.sign_attention_mask = sign_attention_masks\n",
        "        self.sign_seq_len = sign_data[0].shape[0]\n",
        "        self.sign_ts_dim = sign_data[0].shape[1]\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "        self.eeg_cls_token = eeg_cls_tokens\n",
        "        self.eeg_attention_mask = eeg_attention_masks\n",
        "        self.eeg_seq_len = eeg_data[0].shape[0]\n",
        "        self.eeg_ts_dim = eeg_data[0].shape[1]\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            'sign_cls_token': self.sign_cls_token[idx],\n",
        "            'sign_attention_mask': self.sign_attention_mask[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            'eeg_cls_token': self.eeg_cls_token[idx],\n",
        "            'eeg_attention_mask': self.eeg_attention_mask[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61162a58",
      "metadata": {
        "id": "61162a58"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len + 1, d_model)\n",
        "        position = torch.arange(0, max_len + 1, dtype = torch.float).unsqueeze(1)\n",
        "        divterm = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # Credits to hkproj@github for this as https://github.com/hkproj/pytorch-transformer/blob/main/model.py\n",
        "        pe[:, 0::2] = torch.sin(position * divterm)\n",
        "        pe[:, 1::2] = torch.cos(position * divterm)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d21068",
      "metadata": {
        "id": "f1d21068"
      },
      "outputs": [],
      "source": [
        "class SignatureEEGTransformer(nn.Module):\n",
        "    def __init__(self, sign_input_dim, sign_cls_dim, eeg_input_dim, eeg_cls_dim, d_model, num_classes, num_heads, num_layers, sign_max_seq_len, eeg_max_seq_len, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.sign_transfomer = SignatureTransformer(sign_input_dim, sign_cls_dim, d_model, num_classes, num_heads, num_layers, sign_max_seq_len, dropout)\n",
        "        self.eeg_transformer = SignatureTransformer(eeg_input_dim, eeg_cls_dim, d_model, num_classes, num_heads, num_layers, eeg_max_seq_len, dropout)\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.Linear(d_model * 2, d_model), nn.ReLU(), nn.Linear(d_model, num_classes))\n",
        "\n",
        "    def forward(self, sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attn_mask = None, eeg_attn_mask = None):\n",
        "        sign_cls = self.sign_transfomer(sign_x_ts, sign_cls_token, sign_attn_mask)\n",
        "        eeg_cls = self.eeg_transformer(eeg_x_ts, eeg_cls_token, eeg_attn_mask)\n",
        "        multimodal_cls_output = torch.cat([sign_cls, eeg_cls], dim = 1)\n",
        "\n",
        "        logits = self.classifier(multimodal_cls_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "224d0cc3",
      "metadata": {
        "id": "224d0cc3"
      },
      "outputs": [],
      "source": [
        "train_input = {\n",
        "    'sign_data': sign_train_data,\n",
        "    'eeg_data': eeg_train_data,\n",
        "    'sign_attention_masks': sign_train_attention_masks,\n",
        "    'eeg_attention_masks': eeg_train_attention_masks,\n",
        "    'sign_cls_tokens': sign_train_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_train_cls_tokens,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "\n",
        "test_input = {\n",
        "    'sign_data': sign_test_data,\n",
        "    'eeg_data': eeg_test_data,\n",
        "    'sign_attention_masks': sign_test_attention_masks,\n",
        "    'eeg_attention_masks': eeg_test_attention_masks,\n",
        "    'sign_cls_tokens': sign_test_cls_tokens,\n",
        "    'eeg_cls_tokens': eeg_test_cls_tokens,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "\n",
        "num_classes = len(user_id_to_num_map.keys())\n",
        "batch_size = 16\n",
        "\n",
        "# print(\"train input labels: \", train_input['labels'])\n",
        "train_dataset = SignatureEEGDataset(train_input, num_classes=num_classes)\n",
        "val_dataset = SignatureEEGDataset(test_input, num_classes=num_classes)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e6337e",
      "metadata": {},
      "source": [
        "## Feeding Sign + EEG data to transformer - Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4f7235",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "5f4f7235",
        "outputId": "6e256f1b-fe7c-4577-b3fc-8b0cb02b5435"
      },
      "outputs": [],
      "source": [
        "# transformer training loop\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# model = SignatureEEGTransformer(sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim, eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim, d_model=128, num_classes=2, num_heads=4, num_layers=2, sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len).to(device)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "# num_epochs = 5\n",
        "\n",
        "num_layers = 4\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = SignatureEEGTransformer(\n",
        "    sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "    eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "    d_model=128, num_classes=num_classes, num_heads=4, num_layers=num_layers,\n",
        "    sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        ").to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "num_epochs = 25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss, train_labels, train_preds = 0, [], []\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        # printing one batch for debugging\n",
        "        # print(\"Sign x_ts shape: \", sign_x_ts.shape)\n",
        "        # print(\"Sign cls token shape: \", sign_cls_token.shape)\n",
        "        # print(\"EEG x_ts shape: \", eeg_x_ts.shape)\n",
        "        # print(\"EEG cls token shape: \", eeg_cls_token.shape)\n",
        "        # print(\"Sign attention mask shape: \", sign_attention_mask.shape)\n",
        "        # print(\"EEG attention mask shape: \", eeg_attention_mask.shape)\n",
        "        # print(\"Labels: \", labels)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Train labels: \", train_labels)\n",
        "    print(\"Pred labels: \", train_preds)\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_labels)\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_labels, val_preds = 0, [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "            sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "            sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "            sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "            eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "            eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "            eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            val_loss += loss.item() * labels.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Val labels: \", val_labels)\n",
        "    print(\"Pred labels: \", val_preds)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_labels)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "    print(\"=\"*50)\n",
        "# torch.save(model.state_dict(), f\"/content/drive/MyDrive/dataset-final-project/multimodal-model/multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\")\n",
        "torch.save(model.state_dict(), os.path.join(os.getenv(\"MODEL_PATH\"), f\"multimodal_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca38f53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ca38f53",
        "outputId": "a00a2bf3-8347-4527-c310-58ebf8ba01ee"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_labels, val_preds))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_labels, val_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5791b9fd",
      "metadata": {},
      "source": [
        "## Validating Sign+EEG tranformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "dcf85013",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcf85013",
        "outputId": "492a002c-b565-41dd-dee7-394c61fc30d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\1646318677.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  normalized_sign_data = torch.tensor(normalized_sign_data, dtype=torch.float32)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 136, using nperseg = 136\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 197, using nperseg = 197\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n",
            "C:\\Users\\Abhay Nambiar\\AppData\\Local\\Temp\\ipykernel_18472\\4004042047.py:30: UserWarning: nperseg=256 is greater than signal length max(len(x), len(y)) = 203, using nperseg = 203\n",
            "  f, Pxx = welch(normalized_signal[:, ch].cpu().numpy(), fs=fs)\n"
          ]
        }
      ],
      "source": [
        "# validation loop\n",
        "# Set model to evaluation mode\n",
        "\n",
        "# Prepare test data\n",
        "val_files, _, val_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.VALIDATION)\n",
        "raw_val_data = get_sig_eeg_raw_data(val_files, val_labels)\n",
        "\n",
        "# Augment and preprocess test data (no augmentation, just features and padding)\n",
        "for i in range(len(raw_val_data)):\n",
        "    sign_data_with_features, sign_cls_token = get_sign_data_features(raw_val_data[i]['sign_data'])\n",
        "    eeg_data_raw, eeg_data_with_features, eeg_cls_token = get_eeg_data_features(raw_val_data[i]['eeg_data'])\n",
        "    raw_val_data[i]['sign_data'] = sign_data_with_features\n",
        "    raw_val_data[i]['sign_cls_token'] = sign_cls_token\n",
        "    raw_val_data[i]['eeg_data'] = eeg_data_with_features\n",
        "    raw_val_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "    raw_val_data[i]['user_id'] = user_id_to_num_map[raw_val_data[i]['user_id']]\n",
        "\n",
        "sign_max_seq_len_test = max_seq_len_for_data\n",
        "eeg_max_seq_len_test = 10\n",
        "\n",
        "for i in range(len(raw_val_data)):\n",
        "    sign_data = raw_val_data[i]['sign_data']\n",
        "    eeg_data = raw_val_data[i]['eeg_data']\n",
        "    sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len_test)\n",
        "    eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len_test)\n",
        "    raw_val_data[i]['sign_data'] = sign_data\n",
        "    raw_val_data[i]['eeg_data'] = eeg_data\n",
        "    raw_val_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "    raw_val_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "val_input_data = {\n",
        "    'sign_data': [data['sign_data'] for data in raw_val_data],\n",
        "    'eeg_data': [data['eeg_data'] for data in raw_val_data],\n",
        "    'sign_attention_masks': [data['sign_attention_mask'] for data in raw_val_data],\n",
        "    'eeg_attention_masks': [data['eeg_attention_mask'] for data in raw_val_data],\n",
        "    'sign_cls_tokens': [data['sign_cls_token'] for data in raw_val_data],\n",
        "    'eeg_cls_tokens': [data['eeg_cls_token'] for data in raw_val_data],\n",
        "    'labels': [data['user_id'] for data in raw_val_data],\n",
        "}\n",
        "\n",
        "sign_ts_dim = val_input_data['sign_data'][0].size(1)\n",
        "sign_cls_dim = val_input_data['sign_cls_tokens'][0].size(0)\n",
        "sign_seq_len = val_input_data['sign_data'][0].size(0)\n",
        "eeg_ts_dim = val_input_data['eeg_data'][0].size(1)\n",
        "eeg_cls_dim = val_input_data['eeg_cls_tokens'][0].size(0)\n",
        "eeg_seq_len = val_input_data['eeg_data'][0].size(0)\n",
        "\n",
        "val_dataset = SignatureEEGDataset(val_input_data, num_classes)\n",
        "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1a98d4ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "187\n"
          ]
        }
      ],
      "source": [
        "print(len(val_input_data['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wUCeKktmHaiN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUCeKktmHaiN",
        "outputId": "7bf93eb0-afc6-4b0b-dafc-89328262b302"
      },
      "outputs": [],
      "source": [
        "print(test_input_data['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2648c476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2648c476",
        "outputId": "ee876d33-550b-42f5-a1db-0fb099e0db2e"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "val_loss = 0\n",
        "val_labels = []\n",
        "val_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        logits = model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        val_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "        val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "avg_val_loss = val_loss / len(val_labels)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "val_prec = precision_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "val_rec = recall_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "val_f1 = f1_score(val_labels, val_preds, zero_division=0, average='macro')\n",
        "\n",
        "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Validation Precision: {val_prec:.4f}\")\n",
        "print(f\"Validation Recall: {val_rec:.4f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40cb4081",
      "metadata": {
        "id": "40cb4081",
        "outputId": "851592bc-8d03-4bdf-a672-049a4bec715d"
      },
      "outputs": [],
      "source": [
        "print([i for i in zip(val_labels, val_preds)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4667389",
      "metadata": {
        "id": "e4667389"
      },
      "source": [
        "# Sign + EEG anomaly detection - Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abcc9f79",
      "metadata": {
        "id": "abcc9f79"
      },
      "outputs": [],
      "source": [
        "class AnomalyDataset(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        sign_attention_masks = input_data['sign_attention_masks']\n",
        "        eeg_attention_masks = input_data['eeg_attention_masks']\n",
        "        # sign_cls_tokens = input_data['sign_cls_tokens']\n",
        "        # eeg_cls_tokens = input_data['eeg_cls_tokens']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "        # self.sign_cls_token = sign_cls_tokens\n",
        "        self.sign_attention_mask = sign_attention_masks\n",
        "        self.sign_seq_len = sign_data[0].shape[0]\n",
        "        self.sign_ts_dim = sign_data[0].shape[1]\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "        # self.eeg_cls_token = eeg_cls_tokens\n",
        "        self.eeg_attention_mask = eeg_attention_masks\n",
        "        self.eeg_seq_len = eeg_data[0].shape[0]\n",
        "        self.eeg_ts_dim = eeg_data[0].shape[1]\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            # 'sign_cls_token': self.sign_cls_token[idx],\n",
        "            'sign_attention_mask': self.sign_attention_mask[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            # 'eeg_cls_token': self.eeg_cls_token[idx],\n",
        "            'eeg_attention_mask': self.eeg_attention_mask[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5a3179",
      "metadata": {
        "id": "6e5a3179",
        "outputId": "6c39c181-a07d-4168-ac76-034a1392f170"
      },
      "outputs": [],
      "source": [
        "\n",
        "files_mat_genuine_train, user_ids_genuine_train, train_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.TRAIN)\n",
        "files_mat_test, user_ids_test, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST)\n",
        "\n",
        "raw_data_train = get_sig_eeg_raw_data(files_mat_genuine_train, train_labels)\n",
        "raw_data_test = get_sig_eeg_raw_data(files_mat_test, test_labels)\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = int(max_seq_len_for_data // 2)\n",
        "\n",
        "for i in range(len(raw_data_train)):\n",
        "    sign_feat, _ = get_sign_data_features(raw_data_train[i]['sign_data'])\n",
        "    eeg_data, _, _ = get_eeg_data_features(raw_data_train[i]['eeg_data'])\n",
        "    sign_feat, sign_mask = attach_attention_tokens_and_padding(sign_feat, sign_max_seq_len)\n",
        "    eeg_data, eeg_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_data_train[i]['sign_data'] = sign_feat\n",
        "    raw_data_train[i]['eeg_data'] = eeg_data\n",
        "    raw_data_train[i]['sign_attention_mask'] = sign_mask\n",
        "    raw_data_train[i]['eeg_attention_mask'] = eeg_mask\n",
        "\n",
        "for i in range(len(raw_data_test)):\n",
        "    sign_feat, _ = get_sign_data_features(raw_data_test[i]['sign_data'])\n",
        "    eeg_data, _, _ = get_eeg_data_features(raw_data_test[i]['eeg_data'])\n",
        "    sign_feat, sign_mask = attach_attention_tokens_and_padding(sign_feat, sign_max_seq_len)\n",
        "    eeg_data, eeg_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len)\n",
        "    raw_data_test[i]['sign_data'] = sign_feat\n",
        "    raw_data_test[i]['eeg_data'] = eeg_data\n",
        "    raw_data_test[i]['sign_attention_mask'] = sign_mask\n",
        "    raw_data_test[i]['eeg_attention_mask'] = eeg_mask\n",
        "\n",
        "sign_data_train = [d['sign_data'] for d in raw_data_train]\n",
        "eeg_data_train = [d['eeg_data'] for d in raw_data_train]\n",
        "sign_attention_masks_train = [d['sign_attention_mask'][1:] for d in raw_data_train]\n",
        "eeg_attention_masks_train = [d['eeg_attention_mask'][1:] for d in raw_data_train]\n",
        "labels_train = [d['label'] for d in raw_data_train]\n",
        "\n",
        "sign_data_test = [d['sign_data'] for d in raw_data_test]\n",
        "eeg_data_test = [d['eeg_data'] for d in raw_data_test]\n",
        "sign_attention_masks_test = [d['sign_attention_mask'][1:] for d in raw_data_test]\n",
        "eeg_attention_masks_test = [d['eeg_attention_mask'][1:] for d in raw_data_test]\n",
        "labels_test = [d['label'] for d in raw_data_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bf5795",
      "metadata": {
        "id": "c7bf5795",
        "outputId": "288330e4-b10b-4eaf-a7da-6b271bf9e99d"
      },
      "outputs": [],
      "source": [
        "input_data_train = {\n",
        "    'sign_data': sign_data_train,\n",
        "    'eeg_data': eeg_data_train,\n",
        "    'sign_attention_masks': sign_attention_masks_train,\n",
        "    'eeg_attention_masks': eeg_attention_masks_train,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "input_data_test = {\n",
        "    'sign_data': sign_data_test,\n",
        "    'eeg_data': eeg_data_test,\n",
        "    'sign_attention_masks': sign_attention_masks_test,\n",
        "    'eeg_attention_masks': eeg_attention_masks_test,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "anomaly_train_dataset = AnomalyDataset(input_data_train, num_classes=1)\n",
        "anomaly_test_dataset = AnomalyDataset(input_data_test, num_classes=1)\n",
        "anomaly_train_loader = DataLoader(anomaly_train_dataset, batch_size=16, shuffle=True)\n",
        "anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "sign_ts_dim_train = input_data_train['sign_data'][0].size(1)\n",
        "# sign_attention_masks_train = input_data_train['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_train = input_data_train['sign_data'][0].size(0)\n",
        "eeg_ts_dim_train = input_data_train['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_train = input_data_train['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_train = input_data_train['eeg_data'][0].size(0)\n",
        "\n",
        "sign_ts_dim_test = input_data_test['sign_data'][0].size(1)\n",
        "# sign_attention_masks_test = input_data_test['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_test = input_data_test['sign_data'][0].size(0)\n",
        "eeg_ts_dim_test = input_data_test['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_test = input_data_test['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_test = input_data_test['eeg_data'][0].size(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c660ee51",
      "metadata": {
        "id": "c660ee51",
        "outputId": "1e56c499-e841-4d5b-9b08-ceafba23ea23"
      },
      "outputs": [],
      "source": [
        "# print(\"Sign data type: \", eeg_data_train[0])\n",
        "# print(\"EEG data type: \", type(eeg_data))\n",
        "# print(\"Sign attention mask type: \", type(sign_attention_masks[0]))\n",
        "# print(\"EEG attention mask type: \", type(eeg_attention_masks[0]))\n",
        "# print(\"Sign cls token type: \", type(sign_cls_tokens[0]))\n",
        "# print(\"EEG cls token type: \", type(eeg_cls_tokens[0]))\n",
        "# print(\"Labels type: \", type(labels))\n",
        "# print(\"Files type: \", type(files))\n",
        "\n",
        "\n",
        "print(\"Sign data shape: \", sign_data_train[0].shape)\n",
        "print(\"EEG data shape: \", eeg_data_train[0].shape)\n",
        "print(\"Sign attention mask shape: \", sign_attention_masks_train[0].shape)\n",
        "print(\"EEG attention mask shape: \", eeg_attention_masks_train[0].shape)\n",
        "# print(\"Sign cls token shape: \", sign_cls_tokens_train[0].shape)\n",
        "# print(\"EEG cls token shape: \", eeg_cls_tokens_train[0].shape)\n",
        "print(\"Labels shape: \", len(labels_train))\n",
        "print(\"Labels unique elements: \", set(labels_train))\n",
        "# print(\"Files shape: \", len(files_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9220ac",
      "metadata": {
        "id": "ae9220ac"
      },
      "outputs": [],
      "source": [
        "# print(torch.isnan(sign_x_ts).any(), torch.isinf(sign_x_ts).any())\n",
        "# print(torch.isnan(eeg_x_ts).any(), torch.isinf(eeg_x_ts).any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6136abc",
      "metadata": {
        "id": "b6136abc"
      },
      "outputs": [],
      "source": [
        "class SignEEGTransformerAutoEncoder(nn.Module):\n",
        "    def __init__(self, sign_input_dim, sign_seq_len, eeg_input_dim, eeg_seq_len, d_model=128, num_heads=4, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.sign_input_proj = nn.Linear(sign_input_dim, d_model)\n",
        "        self.sign_pos_enc = PositionalEncoding(d_model, sign_seq_len)\n",
        "        sign_encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.sign_encoder = nn.TransformerEncoder(sign_encoder_layer, num_layers=num_layers)\n",
        "        sign_decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.sign_decoder = nn.TransformerDecoder(sign_decoder_layer, num_layers=num_layers)\n",
        "        self.sign_output_proj = nn.Linear(d_model, sign_input_dim)\n",
        "\n",
        "        self.eeg_input_proj = nn.Linear(eeg_input_dim, d_model)\n",
        "        self.eeg_pos_enc = PositionalEncoding(d_model, eeg_seq_len)\n",
        "        eeg_encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.eeg_encoder = nn.TransformerEncoder(eeg_encoder_layer, num_layers=num_layers)\n",
        "        eeg_decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.eeg_decoder = nn.TransformerDecoder(eeg_decoder_layer, num_layers=num_layers)\n",
        "        self.eeg_output_proj = nn.Linear(d_model, eeg_input_dim)\n",
        "\n",
        "    def forward(self, sign_x, eeg_x, sign_attn_mask=None, eeg_attn_mask=None):\n",
        "        sign_x_proj = self.sign_input_proj(sign_x) + self.sign_pos_enc(sign_x)\n",
        "        sign_memory = self.sign_encoder(sign_x_proj, src_key_padding_mask=sign_attn_mask)\n",
        "        sign_decoded = self.sign_decoder(sign_x_proj, sign_memory, tgt_key_padding_mask=sign_attn_mask, memory_key_padding_mask=sign_attn_mask)\n",
        "        sign_recon = self.sign_output_proj(sign_decoded)\n",
        "        eeg_x_proj = self.eeg_input_proj(eeg_x) + self.eeg_pos_enc(eeg_x)\n",
        "        eeg_memory = self.eeg_encoder(eeg_x_proj, src_key_padding_mask=eeg_attn_mask)\n",
        "        eeg_decoded = self.eeg_decoder(eeg_x_proj, eeg_memory, tgt_key_padding_mask=eeg_attn_mask, memory_key_padding_mask=eeg_attn_mask)\n",
        "        eeg_recon = self.eeg_output_proj(eeg_decoded)\n",
        "\n",
        "        return sign_recon, eeg_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33023d89",
      "metadata": {
        "id": "33023d89"
      },
      "outputs": [],
      "source": [
        "def train_validate_autoencoder(model, train_loader, val_loader, device, num_epochs=20, lr=1e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "            sign_x = batch['sign_x_ts'].to(device)\n",
        "            sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "            if sign_mask.dim() == 3:\n",
        "                sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "            eeg_x = batch['eeg_x_ts'].to(device)\n",
        "            eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "            if eeg_mask.dim() == 3:\n",
        "                eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            sign_recon, eeg_recon = model(sign_x, eeg_x, sign_mask, eeg_mask)\n",
        "            loss_sign = loss_fn(sign_recon, sign_x)\n",
        "            loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "            loss = loss_sign + loss_eeg\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "                sign_x = batch['sign_x_ts'].to(device)\n",
        "                sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "                if sign_mask.dim() == 3:\n",
        "                    sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "                eeg_x = batch['eeg_x_ts'].to(device)\n",
        "                eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "                if eeg_mask.dim() == 3:\n",
        "                    eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "                sign_recon, eeg_recon = model(sign_x, eeg_x, sign_mask, eeg_mask)\n",
        "                loss_sign = loss_fn(sign_recon, sign_x)\n",
        "                loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "                loss = loss_sign + loss_eeg\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b868eebe",
      "metadata": {
        "id": "b868eebe"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "anomaly_model = SignEEGTransformerAutoEncoder(sign_input_dim=sign_ts_dim_train, sign_seq_len=sign_seq_len_train, eeg_input_dim=eeg_ts_dim_train, eeg_seq_len=eeg_seq_len_train, d_model=128, num_heads=4, num_layers=2).to(device)\n",
        "\n",
        "model = train_validate_autoencoder(anomaly_model, anomaly_train_loader, anomaly_test_loader, device, num_epochs=10, lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05abbc8a",
      "metadata": {
        "id": "05abbc8a",
        "outputId": "364310f9-2f8c-46f8-91e2-fdaf8d36aa22"
      },
      "outputs": [],
      "source": [
        "# model = SignEEGTransformerAutoEncoder(\n",
        "#     sign_input_dim=sign_ts_dim_test,\n",
        "#     sign_seq_len=sign_seq_len_test,\n",
        "#     eeg_input_dim=eeg_ts_dim_test,\n",
        "#     eeg_seq_len=eeg_seq_len_test,\n",
        "#     d_model=128,\n",
        "#     num_heads=4,\n",
        "#     num_layers=2\n",
        "# )\n",
        "# model.load_state_dict(torch.load(\"D:\\\\KCL Final Year Individual Project\\\\Implementation\\\\Project Implementation\\models\\\\anomaly_model_07212025-153342.pth\", map_location='cpu'))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "all_scores = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in anomaly_test_loader:\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "        eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "        labels = torch.tensor(batch['labels'], dtype=torch.float32).to(device)\n",
        "        sign_recon, eeg_recon = model(sign_x_ts, eeg_x_ts, sign_attention_mask, eeg_attention_mask)\n",
        "        sign_error = ((sign_recon - sign_x_ts) ** 2).max(dim=(1, 2)).cpu().numpy()\n",
        "        eeg_error = ((eeg_recon - eeg_x_ts) ** 2).max(dim=(1, 2)).cpu().numpy()\n",
        "        scores = sign_error + eeg_error\n",
        "        all_scores.extend(scores)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_scores_np = np.array(all_scores)\n",
        "all_labels_np = np.array(all_labels)\n",
        "fpr, tpr, thresholds = roc_curve(all_labels_np, all_scores_np)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "threshold = thresholds[optimal_idx]\n",
        "# print(\"Optimal threshold:\", optimal_threshold)\n",
        "preds = (np.array(all_scores) > threshold).astype(int)\n",
        "roc = roc_auc_score(all_labels, all_scores)\n",
        "acc = accuracy_score(all_labels, preds)\n",
        "prec = precision_score(all_labels, preds, zero_division=0)\n",
        "rec = recall_score(all_labels, preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, preds, zero_division=0)\n",
        "\n",
        "print(f\"ROC AUC: {roc:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels=[0,1]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))\n",
        "\n",
        "plt.hist(np.array(all_scores)[np.array(all_labels)==0], bins=50, alpha=0.5, label='Genuine')\n",
        "plt.hist(np.array(all_scores)[np.array(all_labels)==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "plt.legend()\n",
        "plt.title(\"Anomaly Scores Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca15cb9",
      "metadata": {
        "id": "5ca15cb9"
      },
      "source": [
        "## Sign + EEG Anomaly - CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f6e336",
      "metadata": {
        "id": "a4f6e336"
      },
      "outputs": [],
      "source": [
        "class AnomalyCNNDataset(Dataset):\n",
        "    def __init__(self, input_data):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "        # # self.sign_cls_token = sign_cls_tokens\n",
        "        # self.sign_attention_mask = sign_attention_masks\n",
        "        self.sign_seq_len = sign_data[0].shape[0]\n",
        "        self.sign_ts_dim = sign_data[0].shape[1]\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "        # # self.eeg_cls_token = eeg_cls_tokens\n",
        "        # self.eeg_attention_mask = eeg_attention_masks\n",
        "        self.eeg_seq_len = eeg_data[0].shape[0]\n",
        "        self.eeg_ts_dim = eeg_data[0].shape[1]\n",
        "\n",
        "        # self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            # # 'sign_cls_token': self.sign_cls_token[idx],\n",
        "            # 'sign_attention_mask': self.sign_attention_mask[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            # # 'eeg_cls_token': self.eeg_cls_token[idx],\n",
        "            # 'eeg_attention_mask': self.eeg_attention_mask[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf77fc3",
      "metadata": {
        "id": "8cf77fc3"
      },
      "outputs": [],
      "source": [
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, latent_dim, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        z = self.encoder(x)\n",
        "        return z.squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625de453",
      "metadata": {
        "id": "625de453"
      },
      "outputs": [],
      "source": [
        "class CNNDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 32 * (seq_len // 4)),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (32, seq_len // 4)),\n",
        "            nn.ConvTranspose1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose1d(64, output_dim, kernel_size=4, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.decoder(z)\n",
        "        return x.permute(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c33ddd",
      "metadata": {
        "id": "48c33ddd"
      },
      "outputs": [],
      "source": [
        "class SignEEGCNNAutoencoder(nn.Module):\n",
        "    def __init__(self, sign_input_dim, eeg_input_dim, sign_seq_len, eeg_seq_len, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.sign_encoder = CNNEncoder(sign_input_dim, latent_dim)\n",
        "        self.eeg_encoder = CNNEncoder(eeg_input_dim, latent_dim)\n",
        "        self.sign_decoder = CNNDecoder(latent_dim, sign_input_dim, sign_seq_len)\n",
        "        self.eeg_decoder = CNNDecoder(latent_dim, eeg_input_dim, eeg_seq_len)\n",
        "\n",
        "    def forward(self, sign_x, eeg_x):\n",
        "        sign_z = self.sign_encoder(sign_x)\n",
        "        eeg_z = self.eeg_encoder(eeg_x)\n",
        "        sign_recon = self.sign_decoder(sign_z)\n",
        "        eeg_recon = self.eeg_decoder(eeg_z)\n",
        "        return sign_recon, eeg_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d50f8f",
      "metadata": {
        "id": "c8d50f8f"
      },
      "outputs": [],
      "source": [
        "def train_validate_autoencoder(model, train_loader, device, num_epochs=10, lr=1e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "            # print(\"Current batch sign seq len: \", batch['sign_x_ts'].shape[1])\n",
        "            # print(\"Current batch eeg seq len: \", batch['eeg_x_ts'].shape[1])\n",
        "            sign_x = batch['sign_x_ts'].to(device)\n",
        "            # sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "            # if sign_mask.dim() == 3:\n",
        "            #     sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "            eeg_x = batch['eeg_x_ts'].to(device)\n",
        "            # eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "            # if eeg_mask.dim() == 3:\n",
        "            #     eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            sign_recon, eeg_recon = model(sign_x, eeg_x)\n",
        "            loss_sign = loss_fn(sign_recon, sign_x)\n",
        "            loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "            loss = loss_sign + loss_eeg\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # model.eval()\n",
        "        # val_loss = 0\n",
        "        # with torch.no_grad():\n",
        "        #     for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
        "        #         sign_x = batch['sign_x_ts'].to(device)\n",
        "        #         # sign_mask = batch['sign_attention_mask'].to(device) if 'sign_attention_mask' in batch else None\n",
        "        #         # if sign_mask.dim() == 3:\n",
        "        #         #     sign_mask = sign_mask.squeeze(1) if sign_mask is not None else None\n",
        "        #         eeg_x = batch['eeg_x_ts'].to(device)\n",
        "        #         # eeg_mask = batch['eeg_attention_mask'].to(device) if 'eeg_attention_mask' in batch else None\n",
        "        #         # if eeg_mask.dim() == 3:\n",
        "        #         #     eeg_mask = eeg_mask.squeeze(1) if eeg_mask is not None else None\n",
        "\n",
        "        #         sign_recon, eeg_recon = model(sign_x, eeg_x)\n",
        "        #         loss_sign = loss_fn(sign_recon, sign_x)\n",
        "        #         loss_eeg = loss_fn(eeg_recon, eeg_x)\n",
        "        #         loss = loss_sign + loss_eeg\n",
        "        #         val_loss += loss.item()\n",
        "        # avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        # print(f\"Epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65dfab3",
      "metadata": {
        "id": "c65dfab3",
        "outputId": "63257f44-9097-4e09-9d40-78f944337ec4"
      },
      "outputs": [],
      "source": [
        "files_mat_genuine_train, user_ids_genuine_train, train_labels = get_dataset_files_and_user_ids(data_category=constants.GENUINE, data_type=constants.TRAIN)\n",
        "files_mat_test, user_ids_test, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST)\n",
        "\n",
        "raw_data_train = get_sig_eeg_raw_data(files_mat_genuine_train, train_labels)\n",
        "raw_data_test = get_sig_eeg_raw_data(files_mat_test, test_labels)\n",
        "\n",
        "sign_max_seq_len = max_seq_len_for_data\n",
        "eeg_max_seq_len = int(max_seq_len_for_data // 2)\n",
        "\n",
        "for i in range(len(raw_data_train)):\n",
        "    sign_feat, sign_cls_token = get_sign_data_features(raw_data_train[i]['sign_data'])\n",
        "    eeg_data, eeg_features, eeg_cls_token = get_eeg_data_features(raw_data_train[i]['eeg_data'])\n",
        "    sign_cls_expanded = sign_cls_token.unsqueeze(0).expand(sign_feat.shape[0], -1)\n",
        "    sign_feat = torch.cat((sign_feat, sign_cls_expanded), dim=1)\n",
        "    eeg_cls_expanded = eeg_cls_token.unsqueeze(0).expand(eeg_data.shape[0], -1)\n",
        "    eeg_data = torch.cat([eeg_data, eeg_cls_expanded], dim=1)\n",
        "    raw_data_train[i]['sign_data'] = sign_feat\n",
        "    raw_data_train[i]['eeg_data'] = eeg_data\n",
        "\n",
        "for i in range(len(raw_data_test)):\n",
        "    sign_feat, sign_cls_token = get_sign_data_features(raw_data_test[i]['sign_data'])\n",
        "    eeg_data, eeg_features, eeg_cls_token = get_eeg_data_features(raw_data_test[i]['eeg_data'])\n",
        "    sign_cls_expanded = sign_cls_token.unsqueeze(0).expand(sign_feat.shape[0], -1)\n",
        "    sign_feat = torch.cat((sign_feat, sign_cls_expanded), dim=1)\n",
        "    eeg_cls_expanded = eeg_cls_token.unsqueeze(0).expand(eeg_data.shape[0], -1)\n",
        "    eeg_data = torch.cat([eeg_data, eeg_cls_expanded], dim=1)\n",
        "    raw_data_test[i]['sign_data'] = sign_feat\n",
        "    raw_data_test[i]['eeg_data'] = eeg_data\n",
        "\n",
        "sign_data_train = [d['sign_data'] for d in raw_data_train]\n",
        "eeg_data_train = [d['eeg_data'] for d in raw_data_train]\n",
        "labels_train = [d['label'] for d in raw_data_train]\n",
        "\n",
        "sign_data_test = [d['sign_data'] for d in raw_data_test]\n",
        "eeg_data_test = [d['eeg_data'] for d in raw_data_test]\n",
        "labels_test = [d['label'] for d in raw_data_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1ca5ebe",
      "metadata": {
        "id": "d1ca5ebe"
      },
      "outputs": [],
      "source": [
        "def sign_eeg_collate_fn(batch):\n",
        "    # Use your global fixed lengths\n",
        "    fixed_sign_len = max_seq_len_for_data\n",
        "    fixed_eeg_len = int(max_seq_len_for_data // 2)\n",
        "    sign_x = [item['sign_x_ts'] for item in batch]\n",
        "    eeg_x = [item['eeg_x_ts'] for item in batch]\n",
        "    labels = [item['labels'] for item in batch]\n",
        "    # Pad each sample individually to fixed length\n",
        "    sign_x_padded = torch.stack([\n",
        "        torch.nn.functional.pad(x, (0, 0, 0, fixed_sign_len - x.shape[0]), mode='constant', value=0)\n",
        "        for x in sign_x\n",
        "    ])\n",
        "    eeg_x_padded = torch.stack([\n",
        "        torch.nn.functional.pad(x, (0, 0, 0, fixed_eeg_len - x.shape[0]), mode='constant', value=0)\n",
        "        for x in eeg_x\n",
        "    ])\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    return {\n",
        "        'sign_x_ts': sign_x_padded,\n",
        "        'eeg_x_ts': eeg_x_padded,\n",
        "        'labels': labels\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c01a494",
      "metadata": {
        "id": "9c01a494"
      },
      "outputs": [],
      "source": [
        "input_data_train = {\n",
        "    'sign_data': sign_data_train,\n",
        "    'eeg_data': eeg_data_train,\n",
        "    # 'sign_attention_masks': sign_attention_masks_train,\n",
        "    # 'eeg_attention_masks': eeg_attention_masks_train,\n",
        "    'labels': labels_train,\n",
        "}\n",
        "input_data_test = {\n",
        "    'sign_data': sign_data_test,\n",
        "    'eeg_data': eeg_data_test,\n",
        "    # 'sign_attention_masks': sign_attention_masks_test,\n",
        "    # 'eeg_attention_masks': eeg_attention_masks_test,\n",
        "    'labels': labels_test,\n",
        "}\n",
        "# anomaly_train_dataset = AnomalyCNNDataset(input_data_train)\n",
        "# anomaly_test_dataset = AnomalyCNNDataset(input_data_test)\n",
        "# anomaly_train_loader = DataLoader(anomaly_train_dataset, batch_size=16, shuffle=True, collate_fn=sign_collate_fn)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False, collate_fn=eeg_collate_fn)\n",
        "sign_ts_dim_train = input_data_train['sign_data'][0].size(1)\n",
        "# sign_attention_masks_train = input_data_train['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_train = input_data_train['sign_data'][0].size(0)\n",
        "eeg_ts_dim_train = input_data_train['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_train = input_data_train['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_train = input_data_train['eeg_data'][0].size(0)\n",
        "\n",
        "sign_ts_dim_test = input_data_test['sign_data'][0].size(1)\n",
        "# sign_attention_masks_test = input_data_test['sign_attention_masks'][0].size(0)\n",
        "sign_seq_len_test = input_data_test['sign_data'][0].size(0)\n",
        "eeg_ts_dim_test = input_data_test['eeg_data'][0].size(1)\n",
        "# eeg_attention_masks_test = input_data_test['eeg_attention_masks'][0].size(0)\n",
        "eeg_seq_len_test = input_data_test['eeg_data'][0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a1ac3c",
      "metadata": {
        "id": "a4a1ac3c",
        "outputId": "e2699f7d-60cc-4a5d-ee98-0565e49a2d32"
      },
      "outputs": [],
      "source": [
        "sign_seq_len = sign_data_train[0].shape[0]\n",
        "sign_input_dim = sign_data_train[0].shape[1]\n",
        "eeg_seq_len = eeg_data_train[0].shape[0]\n",
        "eeg_input_dim = eeg_data_train[0].shape[1]\n",
        "latent_dim = 32\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_dataset = AnomalyCNNDataset(input_data_train)\n",
        "test_dataset = AnomalyCNNDataset(input_data_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=sign_eeg_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=sign_eeg_collate_fn)\n",
        "\n",
        "anomaly_cnn_model = SignEEGCNNAutoencoder(sign_input_dim, eeg_input_dim, max_seq_len_for_data, int(max_seq_len_for_data // 2), latent_dim).to(device)\n",
        "anomaly_model = train_validate_autoencoder(anomaly_cnn_model, train_loader, device=device, num_epochs=10, lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd0e7122",
      "metadata": {
        "id": "fd0e7122",
        "outputId": "8e7dc97a-fec7-4725-d018-2231f2fe190f"
      },
      "outputs": [],
      "source": [
        "anomaly_model.eval()\n",
        "all_scores = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        sign_x = batch['sign_x_ts'].to(device)\n",
        "        eeg_x = batch['eeg_x_ts'].to(device)\n",
        "        labels = batch['labels'].cpu().numpy()\n",
        "        sign_recon, eeg_recon = anomaly_model(sign_x, eeg_x)\n",
        "        # using max squared error per sample as anomaly score\n",
        "        sign_error = torch.amax((sign_recon - sign_x) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        eeg_error = torch.amax((eeg_recon - eeg_x) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        scores = sign_error + eeg_error\n",
        "        all_scores.extend(scores)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "all_scores = np.array(all_scores)\n",
        "all_labels = np.array(all_labels)\n",
        "mask = ~np.isnan(all_scores) & ~np.isnan(all_labels) # mask out all NaN values to avoid error in roc_curve\n",
        "all_scores = all_scores[mask]\n",
        "all_labels = all_labels[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726ff6e8",
      "metadata": {
        "id": "726ff6e8",
        "outputId": "c58f3e0d-dbf7-42ba-907f-5c75cd032808"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
        "roc_auc = roc_auc_score(all_labels, all_scores)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "threshold = thresholds[optimal_idx]\n",
        "preds = (all_scores > threshold).astype(int)\n",
        "\n",
        "acc = accuracy_score(all_labels, preds)\n",
        "prec = precision_score(all_labels, preds, zero_division=0)\n",
        "rec = recall_score(all_labels, preds, zero_division=0)\n",
        "f1 = f1_score(all_labels, preds, zero_division=0)\n",
        "\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels=[0,1]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(all_scores[all_labels==0], bins=50, alpha=0.5, label='Genuine')\n",
        "plt.hist(all_scores[all_labels==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
        "plt.legend()\n",
        "plt.title(\"Anomaly Scores Distribution\")\n",
        "plt.xlabel(\"Anomaly Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a6020a",
      "metadata": {
        "id": "96a6020a"
      },
      "source": [
        "## Anomaly Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219d1d03",
      "metadata": {
        "id": "219d1d03"
      },
      "outputs": [],
      "source": [
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# num_epochs = 10\n",
        "\n",
        "# anomaly_model = SignatureEEGTransformer(\n",
        "#     sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "#     eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "#     d_model=128, num_classes=1, num_heads=4, num_layers=4,\n",
        "#     sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        "# ).to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(anomaly_model.parameters(), lr=1e-5)\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # only one class, so only one logit output per sample\n",
        "\n",
        "# anomaly_test_dataset = SignatureEEGDataset(test_input_data, num_classes=1)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     anomaly_model.train()\n",
        "#     total_loss = 0\n",
        "#     for batch in tqdm(anomaly_train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "#         sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#         sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#         sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#         eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#         eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#         eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#         labels = torch.zeros(sign_x_ts.size(0), dtype=torch.float32).to(device)  # All genuine = 0\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         logits = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#         loss = loss_fn(logits.squeeze(1), labels)\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(anomaly_model.parameters(), max_norm=1.0)\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item() * labels.size(0)\n",
        "#     avg_loss = total_loss / len(anomaly_train_dataloader.dataset)\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "#     threshold = 0.5\n",
        "#     # Validation/Test at every epoch\n",
        "#     anomaly_model.eval()\n",
        "#     all_scores = []\n",
        "#     all_labels = []\n",
        "#     with torch.no_grad():\n",
        "#         for batch in anomaly_test_loader:\n",
        "#             sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#             sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#             sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#             eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#             eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#             eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#             labels = torch.tensor(batch['labels'], dtype=torch.float32).to(device)\n",
        "#             scores = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#             all_scores.extend(scores.cpu().numpy())\n",
        "#             all_labels.extend(labels.cpu().numpy())\n",
        "#     preds = (np.array(all_scores) > threshold).astype(int)\n",
        "#     roc = roc_auc_score(all_labels, all_scores)\n",
        "#     print(f\"Validation ROC AUC: {roc:.4f}\")\n",
        "#     print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels=[0,1]))\n",
        "#     print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))\n",
        "#     plt.hist(np.array(all_scores)[np.array(all_labels)==0], bins=50, alpha=0.5, label='Genuine')\n",
        "#     plt.hist(np.array(all_scores)[np.array(all_labels)==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155207fc",
      "metadata": {
        "id": "155207fc"
      },
      "outputs": [],
      "source": [
        "# # training loop for anomaly detection\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# num_epochs = 5\n",
        "\n",
        "# anomaly_model = SignatureEEGTransformer(\n",
        "#     sign_input_dim=sign_ts_dim, sign_cls_dim=sign_cls_dim,\n",
        "#     eeg_input_dim=eeg_ts_dim, eeg_cls_dim=eeg_cls_dim,\n",
        "#     d_model=128, num_classes=1, num_heads=4, num_layers=2,\n",
        "#     sign_max_seq_len=sign_seq_len, eeg_max_seq_len=eeg_seq_len\n",
        "# ).to(device)\n",
        "\n",
        "# optimizer = torch.optim.Adam(anomaly_model.parameters(), lr=1e-5)\n",
        "# loss_fn = nn.BCEWithLogitsLoss() # only one class, so only one logit output per sample\n",
        "\n",
        "# anomaly_model.train()\n",
        "# for epoch in range(num_epochs):\n",
        "#     total_loss = 0\n",
        "#     for batch in tqdm(anomaly_train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False):\n",
        "#         sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#         sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#         sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#         eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#         eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#         eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#         labels = torch.zeros(sign_x_ts.size(0), dtype=torch.float32).to(device)  # All genuine = 0\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         logits = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#         loss = loss_fn(logits.squeeze(1), labels) # logits size turned out to be [8,1] so we need to squeeze it to [8]\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(anomaly_model.parameters(), max_norm=1.0)\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item() * labels.size(0)\n",
        "#     avg_loss = total_loss / len(anomaly_train_dataloader.dataset)\n",
        "#     print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fbc0586",
      "metadata": {
        "id": "1fbc0586"
      },
      "outputs": [],
      "source": [
        "torch.save(anomaly_model.state_dict(), os.path.join(os.getenv(\"MODEL_PATH\"), f\"anomaly_detection_model_{datetime.now().strftime('%m%d%Y-%H%M%S')}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9159ba2b",
      "metadata": {
        "id": "9159ba2b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # testing loop for anomaly detection\n",
        "# files_mat_test, user_ids_test, test_labels = get_dataset_files_and_user_ids(data_category=constants.ALL, data_type=constants.TEST)\n",
        "# raw_test_data = get_sig_eeg_raw_data(files_mat_test, test_labels)\n",
        "\n",
        "# # Augment and preprocess test data (no augmentation, just features and padding)\n",
        "# for i in range(len(raw_test_data)):\n",
        "#     _, sign_cls_token = get_sign_data_features(raw_test_data[i]['sign_data'])\n",
        "#     _, eeg_cls_token = get_eeg_data_features(raw_test_data[i]['eeg_data'])\n",
        "#     # raw_test_data[i]['sign_data'] = sign_data_with_features\n",
        "#     raw_test_data[i]['sign_cls_token'] = sign_cls_token\n",
        "#     # raw_test_data[i]['eeg_data'] = eeg_data_with_features\n",
        "#     raw_test_data[i]['eeg_cls_token'] = eeg_cls_token\n",
        "\n",
        "# sign_max_seq_len_test = int(max_seq_len_for_data//2)\n",
        "# eeg_max_seq_len_test = int(max_seq_len_for_data // 4)\n",
        "\n",
        "# for i in range(len(raw_test_data)):\n",
        "#     sign_data = raw_test_data[i]['sign_data']\n",
        "#     eeg_data = raw_test_data[i]['eeg_data']\n",
        "#     sign_data, sign_attention_mask = attach_attention_tokens_and_padding(sign_data, sign_max_seq_len_test)\n",
        "#     eeg_data, eeg_attention_mask = attach_attention_tokens_and_padding(eeg_data, eeg_max_seq_len_test)\n",
        "#     raw_test_data[i]['sign_data'] = sign_data\n",
        "#     raw_test_data[i]['eeg_data'] = eeg_data\n",
        "#     raw_test_data[i]['sign_attention_mask'] = sign_attention_mask\n",
        "#     raw_test_data[i]['eeg_attention_mask'] = eeg_attention_mask\n",
        "\n",
        "# test_input_data = {\n",
        "#     'sign_data': [data['sign_data'] for data in raw_test_data],\n",
        "#     'eeg_data': [data['eeg_data'] for data in raw_test_data],\n",
        "#     'sign_attention_masks': [data['sign_attention_mask'] for data in raw_test_data],\n",
        "#     'eeg_attention_masks': [data['eeg_attention_mask'] for data in raw_test_data],\n",
        "#     'sign_cls_tokens': [data['sign_cls_token'] for data in raw_test_data],\n",
        "#     'eeg_cls_tokens': [data['eeg_cls_token'] for data in raw_test_data],\n",
        "#     'labels': [data['label'] for data in raw_test_data],\n",
        "# }\n",
        "\n",
        "# sign_ts_dim = test_input_data['sign_data'][0].size(1)\n",
        "# sign_cls_dim = test_input_data['sign_cls_tokens'][0].size(0)\n",
        "# sign_seq_len = test_input_data['sign_data'][0].size(0)\n",
        "# eeg_ts_dim = test_input_data['eeg_data'][0].size(1)\n",
        "# eeg_cls_dim = test_input_data['eeg_cls_tokens'][0].size(0)\n",
        "# eeg_seq_len = test_input_data['eeg_data'][0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a12e5f6c",
      "metadata": {
        "id": "a12e5f6c"
      },
      "outputs": [],
      "source": [
        "# anomaly_test_dataset = SignatureEEGDataset(test_input_data, num_classes=1)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc68ae78",
      "metadata": {
        "id": "bc68ae78"
      },
      "outputs": [],
      "source": [
        "# threshold = 0.5\n",
        "# anomaly_test_dataset = SignatureEEGDataset(test_input_data, num_classes=1)\n",
        "# anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# anomaly_model.eval()\n",
        "# all_scores = []\n",
        "# all_labels = []\n",
        "# with torch.no_grad():\n",
        "#     for batch in tqdm(anomaly_test_loader, desc=\"Testing\", leave=False):\n",
        "#         sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "#         sign_cls_token = batch['sign_cls_token'].to(device)\n",
        "#         sign_attention_mask = batch['sign_attention_mask'].to(device)\n",
        "#         eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "#         eeg_cls_token = batch['eeg_cls_token'].to(device)\n",
        "#         eeg_attention_mask = batch['eeg_attention_mask'].to(device)\n",
        "#         labels = torch.tensor(batch['labels'], dtype=torch.float32).to(device)\n",
        "#         scores = anomaly_model(sign_x_ts, sign_cls_token, eeg_x_ts, eeg_cls_token, sign_attention_mask, eeg_attention_mask)\n",
        "#         all_scores.extend(scores.cpu().numpy())\n",
        "#         all_labels.extend(labels.cpu().numpy())\n",
        "# preds = (np.array(all_scores) > threshold).astype(int)\n",
        "# print(\"ROC AUC:\", roc_auc_score(all_labels, all_scores))\n",
        "# print(classification_report(all_labels, preds, target_names=['Genuine', 'Anomaly'], labels = [0,1]))\n",
        "# print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53437dc",
      "metadata": {
        "id": "c53437dc"
      },
      "outputs": [],
      "source": [
        "# pp.pprint(list(zip(all_scores, all_labels, preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11217528",
      "metadata": {
        "id": "11217528"
      },
      "outputs": [],
      "source": [
        "# plt.hist(np.array(all_scores)[np.array(all_labels)==0], bins=50, alpha=0.5, label='Genuine')\n",
        "# plt.hist(np.array(all_scores)[np.array(all_labels)==1], bins=50, alpha=0.5, label='Anomaly')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ccedc4",
      "metadata": {
        "id": "d7ccedc4"
      },
      "source": [
        "# Sign + EEG in CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d8f0ea",
      "metadata": {
        "id": "72d8f0ea"
      },
      "outputs": [],
      "source": [
        "class SignatureEEGDatasetForCNN(Dataset):\n",
        "    def __init__(self, input_data, num_classes):\n",
        "        sign_data = input_data['sign_data']\n",
        "        eeg_data = input_data['eeg_data']\n",
        "        labels = input_data['labels']\n",
        "\n",
        "        self.sign_x_ts = sign_data\n",
        "\n",
        "        self.eeg_x_ts = eeg_data\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'sign_x_ts': self.sign_x_ts[idx],\n",
        "            'eeg_x_ts': self.eeg_x_ts[idx],\n",
        "            'labels': self.labels[idx],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1980decf",
      "metadata": {
        "id": "1980decf"
      },
      "outputs": [],
      "source": [
        "# def prepare_sign_eeg_for_cnn(input_data):\n",
        "#     sign_data = input_data['sign_data']\n",
        "#     eeg_data = input_data['eeg_data']\n",
        "#     sign_cls_tokens = input_data['sign_cls_tokens']\n",
        "#     eeg_cls_tokens = input_data['eeg_cls_tokens']\n",
        "#     labels = input_data['labels']\n",
        "\n",
        "#     sign_cnn_data = []\n",
        "#     eeg_cnn_data = []\n",
        "\n",
        "#     for s, s_cls, e, e_cls in zip(sign_data, sign_cls_tokens, eeg_data, eeg_cls_tokens):\n",
        "#         # Expand cls token to match sequence length\n",
        "#         s_cls_expanded = s_cls.unsqueeze(0).expand(s.shape[0], -1)\n",
        "#         e_cls_expanded = e_cls.unsqueeze(0).expand(e.shape[0], -1)\n",
        "#         # Concatenate along feature dimension\n",
        "#         sign_cnn_data.append(torch.cat([s, s_cls_expanded], dim=1))\n",
        "#         eeg_cnn_data.append(torch.cat([e, e_cls_expanded], dim=1))\n",
        "\n",
        "#     sign_cnn_data = torch.stack(sign_cnn_data)  # (num_samples, seq_len, sign_ts_dim + sign_cls_dim)\n",
        "#     eeg_cnn_data = torch.stack(eeg_cnn_data)    # (num_samples, seq_len, eeg_ts_dim + eeg_cls_dim)\n",
        "#     labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "#     return sign_cnn_data, eeg_cnn_data, labels\n",
        "\n",
        "# sign_cnn_data, eeg_cnn_data, cnn_labels = prepare_sign_eeg_for_cnn(input_data)\n",
        "# print(\"Sign CNN data shape:\", sign_cnn_data.shape)\n",
        "# print(\"EEG CNN data shape:\", eeg_cnn_data.shape)\n",
        "# print(\"Labels shape:\", cnn_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70236896",
      "metadata": {
        "id": "70236896"
      },
      "outputs": [],
      "source": [
        "class SignEEGCNN(nn.Module):\n",
        "    def __init__(self, sign_input_dim, eeg_input_dim, num_classes):\n",
        "        super(SignEEGCNN, self).__init__()\n",
        "        self.sign_conv = nn.Sequential(\n",
        "            nn.Conv1d(sign_input_dim, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2)\n",
        "        )\n",
        "        self.eeg_conv = nn.Sequential(\n",
        "            nn.Conv1d(eeg_input_dim, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2)\n",
        "        )\n",
        "        self.sign_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.eeg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(64 * 2, num_classes)\n",
        "\n",
        "    def forward(self, sign_x_ts, eeg_x_ts):\n",
        "        sign_x_ts = sign_x_ts.permute(0, 2, 1)\n",
        "        eeg_x_ts = eeg_x_ts.permute(0, 2, 1)\n",
        "\n",
        "        sign_features = self.sign_conv(sign_x_ts)\n",
        "        eeg_features = self.eeg_conv(eeg_x_ts)\n",
        "\n",
        "        sign_features = self.sign_pool(sign_features).squeeze(-1)\n",
        "        eeg_features = self.eeg_pool(eeg_features).squeeze(-1)\n",
        "        combined_features = torch.cat([sign_features, eeg_features], dim=1)\n",
        "\n",
        "        logits = self.fc(combined_features)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c8a043",
      "metadata": {
        "id": "86c8a043"
      },
      "outputs": [],
      "source": [
        "# training loop for CNN\n",
        "sign_cnn_data = sign_data\n",
        "eeg_cnn_data = eeg_data\n",
        "cnn_labels = torch.tensor(labels, dtype=torch.long)\n",
        "sign_cnn_data = torch.stack([x if isinstance(x, torch.Tensor) else torch.tensor(x) for x in sign_data])\n",
        "eeg_cnn_data = torch.stack([x if isinstance(x, torch.Tensor) else torch.tensor(x) for x in eeg_data])\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cnn_model = SignEEGCNN(sign_input_dim=sign_cnn_data.shape[2], eeg_input_dim=eeg_cnn_data.shape[2], num_classes=2).to(device)\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "sign_train, sign_test, eeg_train, eeg_test, labels_train, labels_test = train_test_split(\n",
        "    sign_cnn_data, eeg_cnn_data, cnn_labels, test_size=0.2, random_state=42, stratify=cnn_labels\n",
        ")\n",
        "\n",
        "train_dataset = SignatureEEGDatasetForCNN({\n",
        "    'sign_data': sign_train,\n",
        "    'eeg_data': eeg_train,\n",
        "    'labels': labels_train\n",
        "}, num_classes=2)\n",
        "test_dataset = SignatureEEGDatasetForCNN({\n",
        "    'sign_data': sign_test,\n",
        "    'eeg_data': eeg_test,\n",
        "    'labels': labels_test\n",
        "}, num_classes=2)\n",
        "\n",
        "cnn_dataset = SignatureEEGDatasetForCNN({\n",
        "    'sign_data': sign_cnn_data,\n",
        "    'eeg_data': eeg_cnn_data,\n",
        "    'labels': cnn_labels\n",
        "}, num_classes=2)\n",
        "cnn_dataloader = DataLoader(cnn_dataset, batch_size=8, shuffle=True)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    cnn_model.train()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    pbar = tqdm(enumerate(cnn_dataloader), total=len(cnn_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for batch_idx, batch in pbar:\n",
        "        sign_x_ts = batch['sign_x_ts'].to(device)\n",
        "        eeg_x_ts = batch['eeg_x_ts'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = cnn_model(sign_x_ts, eeg_x_ts)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(cnn_model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        pbar.set_postfix({\"Batch Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_loss = total_loss / len(all_labels) if all_labels else 0\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
        "    print(f\"{'Loss':<10}{'Accuracy':<12}{'Precision':<12}{'Recall':<10}{'F1-Score':<10}\")\n",
        "    print(f\"{avg_loss:<10.4f}{acc:<12.4f}{prec:<12.4f}{rec:<10.4f}{f1:<10.4f}\")\n",
        "    print(\"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c68df6",
      "metadata": {
        "id": "01c68df6"
      },
      "source": [
        "## EEG - Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008dad0f",
      "metadata": {
        "id": "008dad0f"
      },
      "outputs": [],
      "source": [
        "# # For debugging\n",
        "# def get_max_attention_token_len(attention_tokens):\n",
        "#     max_len = 0\n",
        "#     for item in attention_tokens:\n",
        "#         max_len = max(max_len, item.shape[0])\n",
        "#     return max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df4193d",
      "metadata": {
        "id": "3df4193d"
      },
      "outputs": [],
      "source": [
        "# print(get_max_attention_token_len(eeg_final_dataset['attention_masks']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e8fd1a",
      "metadata": {
        "id": "40e8fd1a"
      },
      "outputs": [],
      "source": [
        "# # print(normalized_sign_data_dict['000000000200894'][0])\n",
        "# # print(normalized_eeg_data_dict['000000000200894'][0])\n",
        "# # print(user_labels['000000000200894'][0])\n",
        "# eeg_data = get_eeg_data_features(eeg_data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e8e176",
      "metadata": {
        "id": "d9e8e176"
      },
      "outputs": [],
      "source": [
        "# sign_data_dict, eeg_data_dict, labels = get_sig_eeg_data_dicts(files_mat_appended, labels_appended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e11f5ec",
      "metadata": {
        "id": "7e11f5ec"
      },
      "outputs": [],
      "source": [
        "# # Single data\n",
        "# user_id = '002108410100048'\n",
        "# single_eeg_data = {}\n",
        "# single_eeg_data[user_id] = eeg_data_dict[user_id]\n",
        "\n",
        "# normalized_eeg_data_dict = normalize_eeg_data_dict(single_eeg_data)\n",
        "# eeg_data_with_features = get_eeg_data_features(normalized_eeg_data_dict)\n",
        "# eeg_final_data = eeg_attach_attention_tokens_and_labels(eeg_data_with_features, labels)\n",
        "# eeg_final_dataset = prepare_eeg_dataset_with_all_parts(eeg_final_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c911b8",
      "metadata": {
        "id": "89c911b8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4657fae",
      "metadata": {
        "id": "b4657fae"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(eeg_data_with_features['002108410100048']['data'][2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec789b9",
      "metadata": {
        "id": "bec789b9"
      },
      "outputs": [],
      "source": [
        "# max_len = get_eeg_max_seq_len(eeg_data_with_features)\n",
        "# print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab796cee",
      "metadata": {
        "id": "ab796cee"
      },
      "outputs": [],
      "source": [
        "# print(eeg_final_data['002108410100048']['labels'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1eaf4e",
      "metadata": {
        "id": "2d1eaf4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(eeg_final_dataset['labels'].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff475923",
      "metadata": {
        "id": "ff475923"
      },
      "source": [
        "# Misc - Trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e9aa8c",
      "metadata": {
        "id": "c0e9aa8c"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# x1 = torch.tensor([[1.0, 2.0],\n",
        "#                    [3.0, 1.0],\n",
        "#                    [0.0, 0.0]])\n",
        "\n",
        "# x2 = torch.tensor([[2.0, 1.0],\n",
        "#                    [0.0, 3.0],\n",
        "#                    [1.0, 1.0]])\n",
        "# distances = F.pairwise_distance(x1, x2)\n",
        "\n",
        "# print(\"Pairwise distances:\", distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c042f2",
      "metadata": {
        "id": "62c042f2"
      },
      "outputs": [],
      "source": [
        "# According to the paper: The instances corresponding to the last EEG activity for each subject were interpolated to match the length of the longest genuine instance for that subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d85c8021",
      "metadata": {
        "id": "d85c8021"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import numpy as np\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "\n",
        "# class SignatureEEGDataset(Dataset):\n",
        "#     def __init__(self, signature_data, eeg_data, labels):\n",
        "\n",
        "#         self.samples = []\n",
        "\n",
        "#         # Combine the data\n",
        "#         for user_id in signature_data:\n",
        "#             # Ensure we have matching signature, EEG, and label entries\n",
        "#             n_samples = len(signature_data[user_id])\n",
        "#             for i in range(n_samples):\n",
        "#                 signature = signature_data[user_id][i]\n",
        "#                 eeg = eeg_data[user_id][i]\n",
        "#                 label = labels[user_id][i]\n",
        "\n",
        "#                 # Convert to tensors\n",
        "#                 signature_tensor = torch.FloatTensor(signature)\n",
        "#                 eeg_tensor = torch.FloatTensor(eeg)\n",
        "#                 label_tensor = torch.LongTensor([label])\n",
        "\n",
        "#                 self.samples.append((signature_tensor, eeg_tensor, label_tensor))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.samples)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.samples[idx]\n",
        "\n",
        "# def collate_fn(batch):\n",
        "\n",
        "#     signatures, eegs, labels = zip(*batch)\n",
        "\n",
        "#     # Pad sequences to the same length\n",
        "#     signatures_padded = torch.nn.utils.rnn.pad_sequence(signatures, batch_first=True)\n",
        "#     eegs_padded = torch.nn.utils.rnn.pad_sequence(eegs, batch_first=True)\n",
        "\n",
        "#     labels = torch.cat(labels)\n",
        "\n",
        "#     return signatures_padded, eegs_padded, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae257955",
      "metadata": {
        "id": "ae257955"
      },
      "outputs": [],
      "source": [
        "# class SignatureEEGTransformer(nn.Module):\n",
        "#     def __init__(self, signature_dim=7, eeg_channels=10, d_model=128, nhead=4, num_layers=3, num_classes=2):\n",
        "#         super(SignatureEEGTransformer, self).__init__()\n",
        "\n",
        "#         # Signature embedding\n",
        "#         self.signature_embedding = nn.Linear(signature_dim, d_model)\n",
        "\n",
        "#         # EEG embedding\n",
        "#         self.eeg_embedding = nn.Linear(eeg_channels, d_model)\n",
        "\n",
        "#         # Positional encoding\n",
        "#         self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "#         # Transformer encoder\n",
        "#         encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
        "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "#         # Classifier\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Linear(d_model * 2, d_model),  # *2 because we concatenate signature and EEG features\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(d_model, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, signature, eeg):\n",
        "#         # Signature processing\n",
        "#         signature_embedded = self.signature_embedding(signature)\n",
        "#         signature_embedded = self.positional_encoding(signature_embedded)\n",
        "\n",
        "#         # EEG processing\n",
        "#         eeg_embedded = self.eeg_embedding(eeg)\n",
        "#         eeg_embedded = self.positional_encoding(eeg_embedded)\n",
        "\n",
        "#         # Transformer expects (seq_len, batch, features)\n",
        "#         signature_embedded = signature_embedded.permute(1, 0, 2)\n",
        "#         eeg_embedded = eeg_embedded.permute(1, 0, 2)\n",
        "\n",
        "#         # Process through transformer\n",
        "#         signature_features = self.transformer_encoder(signature_embedded)\n",
        "#         eeg_features = self.transformer_encoder(eeg_embedded)\n",
        "\n",
        "#         # Average over time dimension\n",
        "#         signature_features = signature_features.mean(dim=0)\n",
        "#         eeg_features = eeg_features.mean(dim=0)\n",
        "\n",
        "#         # Concatenate features\n",
        "#         combined_features = torch.cat([signature_features, eeg_features], dim=1)\n",
        "\n",
        "#         # Classify\n",
        "#         output = self.classifier(combined_features)\n",
        "\n",
        "#         return output\n",
        "\n",
        "# class PositionalEncoding(nn.Module):\n",
        "#     def __init__(self, d_model, max_len=5000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return x + self.pe[:x.size(0), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1805ef3b",
      "metadata": {
        "id": "1805ef3b"
      },
      "outputs": [],
      "source": [
        "# def train_model(signature_data, eeg_data, labels, epochs=20, batch_size=32):\n",
        "#     # Create dataset\n",
        "#     dataset = SignatureEEGDataset(signature_data, eeg_data, labels)\n",
        "\n",
        "#     # Split into train and validation\n",
        "#     train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "#     # Create dataloaders\n",
        "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "#     val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "#     # Initialize model\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     model = SignatureEEGTransformer().to(device)\n",
        "\n",
        "#     # Loss and optimizer\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "#     # Training loop\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         train_loss = 0.0\n",
        "\n",
        "#         for signatures, eegs, labels in train_loader:\n",
        "#             signatures, eegs, labels = signatures.to(device), eegs.to(device), labels.to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             outputs = model(signatures, eegs)\n",
        "#             loss = criterion(outputs, labels)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             train_loss += loss.item()\n",
        "\n",
        "#         # Validation\n",
        "#         model.eval()\n",
        "#         val_loss = 0.0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for signatures, eegs, labels in val_loader:\n",
        "#                 signatures, eegs, labels = signatures.to(device), eegs.to(device), labels.to(device)\n",
        "\n",
        "#                 outputs = model(signatures, eegs)\n",
        "#                 loss = criterion(outputs, labels)\n",
        "\n",
        "#                 val_loss += loss.item()\n",
        "#                 _, predicted = torch.max(outputs.data, 1)\n",
        "#                 total += labels.size(0)\n",
        "#                 correct += (predicted == labels).sum().item()\n",
        "\n",
        "#         print(f'Epoch {epoch+1}/{epochs}')\n",
        "#         print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
        "#         print(f'Val Loss: {val_loss/len(val_loader):.4f}')\n",
        "#         print(f'Val Accuracy: {100*correct/total:.2f}%')\n",
        "#         print('-' * 50)\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4996d7b",
      "metadata": {
        "id": "c4996d7b"
      },
      "outputs": [],
      "source": [
        "# model = train_model(normalized_sign_data_dict, normalized_eeg_data_dict, user_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa7e04c",
      "metadata": {
        "id": "1fa7e04c"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models\n",
        "\n",
        "# def prepare_data_with_masking(signature_data, eeg_data, labels_dict):\n",
        "#     \"\"\"\n",
        "#     Prepares data with dynamic padding and preserves original lengths for masking.\n",
        "#     Returns:\n",
        "#         - Padded sequences\n",
        "#         - Sequence length arrays (for masking)\n",
        "#         - Labels\n",
        "#     \"\"\"\n",
        "#     # Initialize lists\n",
        "#     X_signature, X_eeg = [], []\n",
        "#     len_signature, len_eeg = [], []\n",
        "#     y = []\n",
        "\n",
        "#     for user_id in labels_dict.keys():\n",
        "#         for i in range(len(labels_dict[user_id])):\n",
        "#             # Signature data\n",
        "#             sig = signature_data[user_id][i]\n",
        "#             X_signature.append(sig)\n",
        "#             len_signature.append(len(sig))\n",
        "\n",
        "#             # EEG data\n",
        "#             eeg = eeg_data[user_id][i]\n",
        "#             X_eeg.append(eeg)\n",
        "#             len_eeg.append(len(eeg))\n",
        "\n",
        "#             # Label\n",
        "#             y.append(labels_dict[user_id][i])\n",
        "\n",
        "#     # Pad sequences to max length in dataset\n",
        "#     max_len_sig = max(len_signature)\n",
        "#     max_len_eeg = max(len_eeg)\n",
        "\n",
        "#     X_signature_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "#         X_signature, maxlen=max_len_sig, dtype='float32', padding='post'\n",
        "#     )\n",
        "\n",
        "#     X_eeg_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "#         X_eeg, maxlen=max_len_eeg, dtype='float32', padding='post'\n",
        "#     )\n",
        "\n",
        "#     return (\n",
        "#         X_signature_pad, np.array(len_signature),\n",
        "#         X_eeg_pad, np.array(len_eeg),\n",
        "#         np.array(y)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0cc45c",
      "metadata": {
        "id": "6c0cc45c"
      },
      "outputs": [],
      "source": [
        "# def create_masked_model(signature_shape, eeg_shape):\n",
        "#     \"\"\"Creates a model with masking layers to ignore padding\"\"\"\n",
        "#     # Signature branch\n",
        "#     signature_input = layers.Input(shape=signature_shape, name='signature_input')\n",
        "#     signature_length = layers.Input(shape=(1,), name='signature_length', dtype='int32')\n",
        "\n",
        "#     sig = layers.Masking(mask_value=0.0)(signature_input)\n",
        "#     sig = layers.Conv1D(32, 5, activation='relu', padding='same')(sig)\n",
        "#     sig = layers.MaxPooling1D(2)(sig)\n",
        "#     sig = layers.Conv1D(64, 5, activation='relu', padding='same')(sig)\n",
        "#     sig = layers.MaxPooling1D(2)(sig)\n",
        "#     sig = layers.GlobalAveragePooling1D()(sig)\n",
        "\n",
        "#     # EEG branch\n",
        "#     eeg_input = layers.Input(shape=eeg_shape, name='eeg_input')\n",
        "#     eeg_length = layers.Input(shape=(1,), name='eeg_length', dtype='int32')\n",
        "\n",
        "#     eeg = layers.Masking(mask_value=0.0)(eeg_input)\n",
        "#     eeg = layers.Conv1D(32, 5, activation='relu', padding='same')(eeg)\n",
        "#     eeg = layers.MaxPooling1D(2)(eeg)\n",
        "#     eeg = layers.Conv1D(64, 5, activation='relu', padding='same')(eeg)\n",
        "#     eeg = layers.MaxPooling1D(2)(eeg)\n",
        "#     eeg = layers.GlobalAveragePooling1D()(eeg)\n",
        "\n",
        "#     # Combine branches\n",
        "#     combined = layers.concatenate([sig, eeg])\n",
        "#     combined = layers.Dense(128, activation='relu')(combined)\n",
        "#     outputs = layers.Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "#     # Model with length inputs\n",
        "#     model = models.Model(\n",
        "#         inputs=[signature_input, signature_length, eeg_input, eeg_length],\n",
        "#         outputs=outputs\n",
        "#     )\n",
        "\n",
        "#     model.compile(optimizer='adam',\n",
        "#                  loss='binary_crossentropy',\n",
        "#                  metrics=['accuracy'])\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7e44d0",
      "metadata": {
        "id": "bb7e44d0"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, X_sig, len_sig, X_eeg, len_eeg, y, batch_size=32):\n",
        "        self.X_sig = X_sig\n",
        "        self.len_sig = len_sig\n",
        "        self.X_eeg = X_eeg\n",
        "        self.len_eeg = len_eeg\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.y) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_sig = self.X_sig[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_len_sig = self.len_sig[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_eeg = self.X_eeg[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_len_eeg = self.len_eeg[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_y = self.y[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "\n",
        "        return [batch_sig, batch_len_sig, batch_eeg, batch_len_eeg], batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16ae07d",
      "metadata": {
        "id": "f16ae07d"
      },
      "outputs": [],
      "source": [
        "# def train_authentication_model(signature_data, eeg_data, labels_dict):\n",
        "#     # Prepare data\n",
        "#     X_signature, X_eeg, y = prepare_data(signature_data, eeg_data, labels_dict)\n",
        "\n",
        "#     # Split into train and test sets\n",
        "#     (X_signature_train, X_signature_test,\n",
        "#      X_eeg_train, X_eeg_test,\n",
        "#      y_train, y_test) = train_test_split(X_signature, X_eeg, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#     # Create model\n",
        "#     signature_shape = X_signature_train.shape[1:]\n",
        "#     eeg_shape = X_eeg_train.shape[1:]\n",
        "#     model = create_dual_input_model(signature_shape, eeg_shape)\n",
        "\n",
        "#     # Train model\n",
        "#     history = model.fit(\n",
        "#         [X_signature_train, X_eeg_train],\n",
        "#         y_train,\n",
        "#         epochs=50,\n",
        "#         batch_size=32,\n",
        "#         validation_data=([X_signature_test, X_eeg_test], y_test),\n",
        "#         callbacks=[\n",
        "#             tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "#             tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=3)\n",
        "#         ]\n",
        "#     )\n",
        "\n",
        "#     return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c9be06",
      "metadata": {
        "id": "44c9be06"
      },
      "outputs": [],
      "source": [
        "# 1. Prepare data\n",
        "X_sig, len_sig, X_eeg, len_eeg, norm_y = prepare_data_with_masking(signature_data, eeg_data, labels_dict)\n",
        "\n",
        "# 2. Split data\n",
        "(X_sig_train, X_sig_test,\n",
        " len_sig_train, len_sig_test,\n",
        " X_eeg_train, X_eeg_test,\n",
        " len_eeg_train, len_eeg_test,\n",
        " y_train, y_test) = train_test_split(X_sig, len_sig, X_eeg, len_eeg, norm_y, test_size=0.2)\n",
        "\n",
        "# 3. Create model\n",
        "model = create_masked_model(X_sig_train.shape[1:], X_eeg_train.shape[1:])\n",
        "\n",
        "# 4. Create generators\n",
        "train_gen = DataGenerator(X_sig_train, len_sig_train, X_eeg_train, len_eeg_train, y_train)\n",
        "val_gen = DataGenerator(X_sig_test, len_sig_test, X_eeg_test, len_eeg_test, y_test)\n",
        "\n",
        "# 5. Train\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e718c86",
      "metadata": {
        "id": "7e718c86"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_signature_test, X_eeg_test, y_test):\n",
        "    results = model.evaluate([X_signature_test, X_eeg_test], y_test)\n",
        "    print(f\"Test Loss: {results[0]:.4f}\")\n",
        "    print(f\"Test Accuracy: {results[1]:.4f}\")\n",
        "    print(f\"Test AUC: {results[2]:.4f}\")\n",
        "\n",
        "    # You can add more evaluation metrics as needed\n",
        "    y_pred = model.predict([X_signature_test, X_eeg_test])\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
